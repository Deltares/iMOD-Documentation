[
  {
    "objectID": "practical_snakemake.html",
    "href": "practical_snakemake.html",
    "title": " Snakemake Tips ",
    "section": "",
    "text": "Snakemake is a very useful and powerful tool to create reproducible workflows.\nUsually (or ideally...) our modelling workflows consist of a set of scripts or calls to executables that exchange intermediate files, in order to convert raw data to model output that can be analyzed. The graph of these workflows usually does not look like a straight pipeline, but more often like a chaotic network (a plate of spaghetti for larger workflows), because some files influence multiple steps. Quite often some of this input changes, or a certain script changes. Since we also often process large datasets, we do not want to re-run every step again with every change, but instead only re-run the necessary steps. Snakemake does this bookkeeping for us.\nBelow a graph created for an example workflow:\nYou can see that quite a lot of tasks in this example depend on the step create_3d_grid, in which a 3d grid is created that is used as model discretization. Changing something in this step means a lot of steps have to be redone, but not all of them (like downloading precipitation data). Therefore Snakemake automatically recognizes which scripts still have to be re-executed after a filechange.\nSnakemake is currently mainly used, and developed, in Academia by bioinformaticians. Because of this background, it has very cool features like support for parallel computation, both on local machines as well as high performance clusters. However, this background also means it can be hard to install on Windows and to navigate its' extensive documentation. This documentation tries to help installing snakemake and to furthermore provide you with the most useful commands for our iMOD workflows."
  },
  {
    "objectID": "practical_snakemake.html#option-1-recommended-way-install-deltaforge",
    "href": "practical_snakemake.html#option-1-recommended-way-install-deltaforge",
    "title": " Snakemake Tips ",
    "section": "Option 1: Recommended way: Install Deltaforge",
    "text": "Option 1: Recommended way: Install Deltaforge\nDeltaforge installs Snakemake and all its dependencies for you. Read the instructions to install Deltaforge here."
  },
  {
    "objectID": "practical_snakemake.html#option-2-install-via-condamamba",
    "href": "practical_snakemake.html#option-2-install-via-condamamba",
    "title": " Snakemake Tips ",
    "section": "Option 2: Install via conda/mamba",
    "text": "Option 2: Install via conda/mamba\nNote that Snakemake is located on the bioconda channel (remember snakemake's background in bioinformatics?). You can run the following commands in your terminal of choice to install snakemake with mamba.\n&gt; mamba install pygraphviz graphviz\n&gt; mamba install -c bioconda snakemake"
  },
  {
    "objectID": "practical_snakemake.html#configure-your-machine",
    "href": "practical_snakemake.html#configure-your-machine",
    "title": " Snakemake Tips ",
    "section": "Configure your machine",
    "text": "Configure your machine\nThen one dependency requires manual installation, namely Imagemagick. Ensure during the installation that Imagemagick is added to the Windows PATH variable.\nIn order to configure Graphviz, you then have to call once:\n&gt;dot -c\nOnce you have created a workflow, you can then call the following code to create a directional acyclic graph and save it as docs/dag.png:\n&gt;snakemake --rulegraph | dot -Tpng &gt; docs/dag.png"
  },
  {
    "objectID": "practical_snakemake.html#creating-a-workflow",
    "href": "practical_snakemake.html#creating-a-workflow",
    "title": " Snakemake Tips ",
    "section": "Creating a workflow",
    "text": "Creating a workflow\n\nRules\nIn order to specify the individual steps of your workflow in Snakemake, you must create a Snakefile in your repository. In this Snakefile, you define a set of rules, each rule specifying an individual step of your workflow. A rule looks as follows:\nrule plot_heads:\n input:\n     \"data/4-output/head.nc\",\n output:\n     \"reports/figures/head.png\"\n shell:\n     \"python src/5-visualize/visualize_heads.py {input} {output}\"\nSnakemake does not care what the rule does, it only wants to know which files are used as input, in this case the file located at ./data/4-output/head.nc, and what files are created as output, in this case ./reports/figures/head.png and what should be executed. The last line under \"shell\" defines what command should be executed. In this case a call is made to python to run the script with two arguments:\n&gt;python src/5-visualize/visualize_heads.py data/4-output/head.nc reports/figures/head.png\n\n\nScripts\nSnakemake has built-in support for Python scripts (as well as Julia and R scripts), so you don't have to call shell commands:\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n output:\n     head_png = \"reports/figures/head.png\"\n script:\n     \"src/5-visualize/visualize_heads.py\"\nIn this case the snakemake object is available within the script and lets you access input and output. The visualize_heads.py script could look as follows:\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\nhead_nc = snakemake.input.head_nc\nhead_png = snakemake.input.head_png\n\n#Read data\nhead = xr.open_dataset(head_nc)\n\n#Select and plot data\nhead.isel(time =- 1, x = 0).plot()\nplt.savefig(head_png)\nThis example script reads heads as a NetCDF, selects a crossection at the first column and the last timestep, consequently plots this and saves this figure to a png file.\nHowever, including the script keyword alone, does not mean that Snakemake will keep track of changes in the script and will re-execute a rule accordingly. Therefore, it is smart to include the script also under input. This will ensure Snakemake keeps track of changes in a script:\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n     script = \"src/5-visualize/visualize_heads.py\"\n output:\n     head_png = \"reports/figures/head.png\"\n script:\n     \"src/5-visualize/visualize_heads.py\"\n\n\nDefault rule\nSnakemake does not know what the final step is, so without any specifications it executes the first rule. It therefore is often convenient to specify an empty rule all first, which has the final output files as \"input\":\nrule all:\n input:\n   \"reports/figures/head.png\"\n\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n output:\n     head_png = \"reports/figures/head.png\"\n script:\n     \"src/5-visualize/visualize_heads.py\"\nWhen we then first cd into the repository and then call snakemake, Snakemake will run the complete workflow.\n\n\nParameters\nSometimes you just want to pass a number or string to a rule and not create a separate file for this. This can specified under the params keyword.\nrule all:\n input:\n   \"reports/figures/head.png\"\n\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n params:\n     times = \"2012-09-01\"\n output:\n     head_png = \"reports/figures/head.png\"\n script:\n     \"src/5-visualize/visualize_heads.py\"\nThis will pass the string \"2012-09-01\" to the python script, which can be accessed as snakemake.params.times in python."
  },
  {
    "objectID": "practical_snakemake.html#executing-workflows",
    "href": "practical_snakemake.html#executing-workflows",
    "title": " Snakemake Tips ",
    "section": "Executing workflows",
    "text": "Executing workflows\nSnakemake has a lot of options to execute workflows, here are the basic commands that are the most useful to know for a beginner. Executing workflows can be done by calling:\n&gt;snakemake\nThis will execute the first rule. To execute a specific rule, e.g. \"plot_heads\" (and all rules that still have to be executed to get to this rule):\n&gt;snakemake plot_heads\nWhen you change a rule, and want to re-execute all rules downstream of this rule, you can call:\n&gt;snakemake -R plot_heads"
  },
  {
    "objectID": "practical_snakemake.html#running-regular-python-code-in-the-snakefile",
    "href": "practical_snakemake.html#running-regular-python-code-in-the-snakefile",
    "title": " Snakemake Tips ",
    "section": "Running regular python code in the Snakefile",
    "text": "Running regular python code in the Snakefile\nWhen Snakemake is executed, it basically executes its' code as python code. This means you can just import packages of your environment and execute python code in your Snakefile. For example, you can add the following code in your Snakefile:\nimport pandas as pd\nSTART = \"2012-09-01\"\nEND = \"2020-09-01\" \nTIMES = pd.date_range(start=START, end=END, freq=\"A\")\nTIMES = TIMES.strftime(\"%Y-%m-%d\")\n\nrule all:\n input:\n   \"reports/figures/head.png\"\n\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n params:\n     times = TIMES\n output:\n     head_png = \"reports/figures/head.png\"\n script:\n     \"src/5-visualize/visualize_heads.py\"\nThis will create multiple timestamps, convert these to string and pass these to params."
  },
  {
    "objectID": "practical_snakemake.html#multiple-files",
    "href": "practical_snakemake.html#multiple-files",
    "title": " Snakemake Tips ",
    "section": "Multiple files",
    "text": "Multiple files\nOften the execution of steps either requires or produces multiple files that have a very similar makeup. For example iMOD can produce output files names head_l1.idf, head_l2.idf, head_l3.idf etc.\nSpecifying these all in the Snakefile requires too much manual labour and leads to a cluttered snakefile. Therefore, Snakemake has a builtin expand function which lets you expand a template string with wildcards into a list.\nSay our visualize_heads script produces figure for all days, named head_2012-09-01.png, head_2012-09-02.png etc.\nWe can specify all these figures with:\nimport pandas as pd\nSTART = \"2012-09-01\"\nEND = \"2020-09-01\" \nTIMES = pd.date_range(start=START, end=END, freq=\"A\")\nTIMES = TIMES.strftime(\"%Y-%m-%d\")\n\nrule all:\n input:\n   expand(\"reports/figures/head_{time}.png\", time=TIMES)\n\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n params:\n     times = TIMES\n output:\n     head_png = expand(\"reports/figures/head_{time}.png\", time=TIMES)\n script:\n     \"src/5-visualize/visualize_heads.py\"\nThis is very helpful, but sometimes model code produces so many files (&gt;10k), you do not even want to bother specifying all individual files that are created as output. For example, a parallel iMOD-WQ run with 30 layers, 300 timesteps, and run on 24 cores can produce 216,000 .IDFs per variable. Have fun specifying all of them beforehand!\nYou can instead therefore specify a directory that should be created as output. Snakemake then just checks if changes are made in the directory, using a hidden file named .snakemake_timestamp.\nModifying the previous example, this results in:\nimport pandas as pd\nSTART = \"2012-09-01\"\nEND = \"2020-09-01\" \nTIMES = pd.date_range(start=START, end=END, freq=\"A\")\nTIMES = TIMES.strftime(\"%Y-%m-%d\")\n\nrule all:\n input:\n   \"reports/figures/\"\n\nrule plot_heads:\n input:\n     head_nc = \"data/4-output/head.nc\",\n params:\n     times = TIMES\n output:\n     head_png = directory(\"reports/figures/\")\n script:\n     \"src/5-visualize/visualize_heads.py\"\nNote that we do not have to call directory() in order to specify input for rule all!"
  },
  {
    "objectID": "practical_snakemake.html#temporary-files",
    "href": "practical_snakemake.html#temporary-files",
    "title": " Snakemake Tips ",
    "section": "Temporary files",
    "text": "Temporary files\nSometimes, you do not even want to save certain intermediate files to save storage. For example, you run iMOD-wq, this creates .IDFs which you convert to NetCDF. Keeping both the .IDF as well as the NetCDF files requires double the storage, even though you will not use the .IDF after the NetCDF is written. For these cases, Snakemake has the temp function.\nFor example take this example where we call iMOD-WQ, which produces the directories conc and head. These folders contain a lot of .IDFs which we convert to a NetCDF, after which we do not need these folders anymore.\nrule all:\n   input:\n      \"data/4-output/scenario_1/head.nc\",\n      \"data/4-output/scenario_1/conc.nc\"\n\nrule idf_to_netcdf:\n   input:\n      head_dir = \"data/4-output/scenario_1/head\",\n      conc_dir = \"data/4-output/scenario_1/conc\",\n   output:\n      head_nc = \"data/4-output/scenario_1/head.nc\",\n      conc_nc = \"data/4-output/scenario_1/conc.nc\",\n   script:\n      \"src/4-analyze/idf_to_netcdf.py\"\n\nrule run_model:\n   input:\n      r\"data/4-output/scenario_1/model.run\" # The runfile is the model definition file.\n   output:\n      temp(directory(\"data/4-output/scenario_1/conc\")),\n      temp(directory(\"data/4-output/scenario_1/head\")),\n   shell:\n      r\".\\src\\3-model\\run_model.bat data\\4-output\\scenario_1&gt; .\\data\\4-output\\scenario_1\\std.out\"\nThe call temp() ensures all these .IDFs are removed after successful conversion!"
  },
  {
    "objectID": "practical_snakemake.html#parallel-execution",
    "href": "practical_snakemake.html#parallel-execution",
    "title": " Snakemake Tips ",
    "section": "Parallel execution",
    "text": "Parallel execution\nWhen modelling, you usually want to run the model a few times using different configurations. For example a simulation with a horizontal hydraulic conductivity of 10 m/d and one with a hydraulic conductivity of 25 m/d. In the rest of this section, I call these scenarios.\nThis basically means the same task has to be run multiple times, using different configurations, but similar files. These can be run independently from each other, in parallel! Wouldn't it be cool if Snakemake would be able to recognize this and run this in parallel?\nHa! It does!\nSnakemake lets you define groups, using a group keyword. Take for example this Snakefile which runs three scenarios and converts their output to a NetCDF, all in parallel. The group keyword sets which rules can be executed in parallel.\nscenarios = [1, 2, 3]\n\nrule all:\n   input:\n      expand(\"data/4-output/scenario_{scenario}/head.nc\", scenario = scenarios),\n      expand(\"data/4-output/scenario_{scenario}/conc.nc\", scenario = scenarios),\n\nrule idf_to_netcdf:\n   input:\n      head_dir = \"data/4-output/scenario_{scenario}/head\",\n      conc_dir = \"data/4-output/scenario_{scenario}/conc\",\n   group:\n      \"scenarios\"\n   output:\n      head_nc = \"data/4-output/scenario_{scenario}/head.nc\",\n      conc_nc = \"data/4-output/scenario_{scenario}/conc.nc\",\n   script:\n      \"src/4-analyze/idf_to_netcdf.py\"\n\nrule run_model:\n   input:\n      r\"data/4-output/scenario_{scenario}/model.run\" \n   group:\n      \"scenarios\"\n   output:\n      temp(directory(\"data/4-output/scenario_{scenario}/conc\")),\n      temp(directory(\"data/4-output/scenario_{scenario}/head\")),\n   shell:\n      r\".\\src\\3-model\\run_model.bat data\\4-output\\scenario_{wildcards.scenario}&gt; .\\data\\4-output\\scenario_{wildcards.scenario}\\std.out\"\nWe need the wildcards keyword under the shell command to expand scenario numbers before sending the string to the shell. Note that snakemake requires one rule that \"collects\" all separate groups, in this case the rule all.\nYou can then consequently run these tasks in parallel on three cores by calling:\n&gt;snakemake --cores 3"
  },
  {
    "objectID": "qgis_user_manual.html",
    "href": "qgis_user_manual.html",
    "title": "QGIS Plugin User Manual",
    "section": "",
    "text": "This part contains the user guide of the QGIS plugin.",
    "crumbs": [
      "iMOD Viewer",
      "QGIS Plugin User Manual"
    ]
  },
  {
    "objectID": "qgis_user_manual.html#description",
    "href": "qgis_user_manual.html#description",
    "title": "QGIS Plugin User Manual",
    "section": "",
    "text": "This part contains the user guide of the QGIS plugin.",
    "crumbs": [
      "iMOD Viewer",
      "QGIS Plugin User Manual"
    ]
  },
  {
    "objectID": "qgis_user_manual.html#configuration",
    "href": "qgis_user_manual.html#configuration",
    "title": "QGIS Plugin User Manual",
    "section": "Configuration",
    "text": "Configuration\n\nYou probably want to change the language settings in QGIS, if it defaults to Dutch, it’s Extra &gt; Opties &gt; Algemeen. Change it to to US settings (that’s generally the safest default). You will need to restart QGIS before this has effect.\n\n\n\n\n\nThe QGIS language settings\n\n\n\n\nStart up QGIS, go to Plugins &gt; Manage and Install plugins &gt; Installed. Make sure the iMOD plugin is ticked.\n\n\n\nThe QGIS plugin manager. Here you can install and activate plugins.\n\n\n\nIf the installation and configuration was successful, the plugin should be visible in your toolbar.\n\n\n\n\nThe iMOD plugin toolbar",
    "crumbs": [
      "iMOD Viewer",
      "QGIS Plugin User Manual"
    ]
  },
  {
    "objectID": "qgis_user_manual.html#functionality",
    "href": "qgis_user_manual.html#functionality",
    "title": "QGIS Plugin User Manual",
    "section": "Functionality",
    "text": "Functionality\nThe QGIS plugin currently consists of five widgets, of which the functionality will be described in the next section:\n\nOpen IPF\n3D Viewer\nTime Series\nCross section\nAdd NHI data\n\n\n Open IPF\nOpen IPF file and lets QGIS interpret it as a regular shapefile with points. Required to interpret timeseries in the Time Series widget, as well as to visualize borelogs in Cross section and 3D Viewer widget. To an IPF timeseries file it attaches two columns to the attribute table of the vector layer, namely a \"start time\" and \"end time\". This allows using the QGIS Temporal Controller Panel to browse through time, and see which points have data defined within a certain time frame.\n\nPress the \"...\" button to select a path to a file (as you would in other QGIS windows).\nPress \"Add\" to load the file into the QGIS explorer.\n\n\n\n\n\n\n\nWarning\n\n\n\nCurrently the IPF reader is not able to read every IPF file, as iMOD 5 supports quite a wide range of IPF files. For example, iMOD 5 supports both whitespace and comma separated files, whereas the QGIS plugin only supports comma separated IPF files. If the plugin is unable to read your IPF file, it is best to read the file with iMOD Python and consequently write it again. This can help, because the IPF reader in iMOD Python is a lot more flexible, but its writer always writes to a specific format. We plan to improve the flexibility of the plugin's IPF reader.\n\n\n\n\n\nThe Open IPF widget.\n\n\n\n\n\nThe temporal controller panel and map canvas of QGIS. The temporal controller panel is opened by clicking the clock in the \"map navigation\" toolbar.\n\n\n\n\n 3D Viewer\nThe 3D viewer widget creates a connection between QGIS and the iMOD 3D viewer. It allows you to make selections in QGIS and forward them to the 3D viewer. Note that there are two perquisites for the iMOD viewer to correctly render mesh data:\n\nThe mesh data needs to be stored in a UGRID file\nVertical axis is stored as variables top_layer_* and bottom_layer_*. The data belonging to each layer follows the following format head_layer_*, e.g. for a variable head.\n\nThis means that not all data that can be loaded in QGIS as mesh can be viewed in the 3D viewer. Currently only UGRID meshes and IPF borelog files are supported.\n\nUse the selection box at the top to select the mesh layer/ipf file you want to inspect in the 3D viewer.\nThe \"Extent\" group allows the user to manually set the bounding box by editing the numbers under \"North\", \"East\", \"South\", and \"West\", and more:\n\nThe \"Current Layer Extent\" button sets the bounding box to the extent of the layer selected in the QGIS explorer.\nThe \"Calculate from Layer\" box allows you to select a dataset loaded in the QGIS explorer to calculate the extent from.\n\"Map canvas extent\" sets the bounding box to the map canvas\n\nThe \"Select\" group contains a set of buttons to spatially select data to be forwarded to the 3D viewer\n\nThe \"Draw fence diagram\" button allows to draw lines on the map canvas which can be forwarded to the 3D viewer to draw a fence diagram. Press the button to start drawing mode. Left-click to start drawing a line; right-click to stop drawing the line.\nThe \"Clear fence diagram\" button clears all lines from the map canvas\nThe \"Draw extent\" buttons allows you to click and drag a box that allows you to set a bounding box. The iMOD viewer will only load the data within this boundary box, which can be useful when exploring specific areas in large datasets. Drawing an bounding box will update the \"Extent\" widget. Right-click to stop drawing the extent.\n\nThe \"View\" group contains a set of buttons to interact with the 3D viewer\n\n\"Start iMOD viewer\" starts the iMOD viewer and immediately loads the data selected in the widget.\n\"Load mesh data\" remove previous data from viewer and load new mesh data in it.\n\"Load fence diagram\" loads the lines drawn with \"Draw fence diagram\" to the viewer and renders a fence diagram.\n\"Load legend\" transfers legend in the QGIS map layer to fence diagram and/or mesh data in the 3D viewer for the selected variable in the QGIS map canvas.\n\n\n\n\n\nThe 3D viewer widget. It will be opened on the right-hand side of the screen.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe 3D Viewer widget does not forward any data to the iMOD 3D viewer, it only forwards the path to the data to load, and a command how to load it. As of now, the widget does not understand changes made by the user in the 3D viewer. It only supports \"one-way traffic\" towards the viewer.\n\n\n\n\n Time Series\nThe Time Series widget visualizes time series stored in IPF files or mesh data in a graph window. You can freely zoom and drag the graph in this window. Sometimes you lose your view of the lines by dragging too fast; so to reset your view, you can click on the small \"A\" in the bottom left corner of the graph window. The buttons in the widget change, depending on which data type is being selected.\n\nUse the box on the top left of the widget to select the ipf file or mesh data to plot.\n\"ID column\" box allows you to select the column of the attribute table that sets the point ID's to be plotted in the legend.\nThe \"Variable\" box sets the variable (or variables in case of IPFs) to be plotted.\nThe \"Layer\" box sets the layers of a mesh to be plotted. Multiple layers can be selected.\nThe \"Select points\" box allows selecting points in a dataset to plot.\n\n\nWhen selecting on a IPF, left-click and drag a box to select points. SHIFT + click to add points to the existing selection. Press CTRL + ALT + A to deselect all points. You can also click Deselect features from all layers in QGIS' selection toolbar. To stop selecting, click Pan Map in QGIS' Map Navigation toolbar, or close the Timeseries widget.\nWhen selecting on a mesh, left-click to select a point on a mesh to plot, right-click to stop selecting.\n\n\nThe \"update on selection checkbox\": when checked on, the widget automatically plots newly selected points for point data or plots data at the location of the cursor for mesh data.\nThe \"Line Color\" box allows you to set a color of a selected line. You can select a plotted line by clicking on it.\nThe \"Draw markers\" check box enables the drawing of markers on each data point. Recommended when there are not many datapoints to show and/or when the intervals between data points are not constant.\nThe \"Colors\" button opens up a new window that lets you select different colorramps.\nThe \"Export\" button allows you to export your plot to an image file (.png, .jpg etc.), a vector file (.svg for Inkscape), or a .csv to allow for plotting in different software.\n\n\n\n\nThe Time series widget and map canvas for points. Notice that the widget can handle irregular time series filled with gaps. The yellow points on the map canvas indicate the selected points.\n\n\n\n\n\nThe Time series widget and map canvas for a mesh. The red crosses indicate the location of the plotted time-series.\n\n\n\n\n\n\n\n\nNote\n\n\n\nA known issue with a multiple monitor setup is that the grid behind the plot might be plotted way off. See the known issues section for more info and how to fix this.\n\n\n\n\n Cross-section\nThe cross-section widget allows you to draw cross-sections of both mesh and raster data. Note that the widget expects that the vertical axis is stored as variables top_layer_* and bottom_layer_*. The data belonging to each layer follows the following format head_layer_*, e.g. for a variable head. For time dependent data, when the Temporal Controller Panel is turned on, the cross-section plot is automatically updated when a different moment in time is selected.\nThe cross-section widget consists of three component:\n\nThe top bar\nA styling table, specifying the styling and order of elements to plot.\nA graph window, in which the cross-section is plotted.\n\nThe functionality of each component is explained below.\n\n\nThe top bar\n\n\n\"Select location\" lets you draw a line on the map, along which a cross-section will be drawn. Left-click to start and to stop drawing a line. Right-click to stop the selection.\nWhen the \"Dynamic resolution\" checkbox option is switched on, the amount of points along which data is sampled for the plot is set to a fixed number and resolution varies. Turning this off and setting a very small resolution size might improve precision, but will definitely result in a performance loss.\nThe \"Search buffer\" box sets the tangential distance from which boreholes will will be selected.\nThe \"Plot\" button plots the data and styling selected in the styling table to the graph window.\nThe \"Export\" button allows you to export your plot to an image file (.png, .jpg etc.), a vector file (.svg for Inkscape), or a .csv to allow for plotting in different software.\n\n\n\n\nThe styling table\n\n\nThe top left selection box allows you to choose the dataset to plot.\nThe \"Variable\" box, you can select the variable to plot.\nThe \"Layer\" box lets you select individual layers to plot. By default all are plotted.\nThe \"As line(s)\" checkbox turns on an option to plot data as lines. Useful to plot layer tops or bottoms to show interfaces.\nThe \"Add\" button adds a dataset to the table.\n\n\n\n\nThe plot window\n\n\nRight-click the plotting window to set zoom options.\nYou can click the small \"A\" in the bottom left corner to reset zoom.\n\n\n\n\n\n\n\nThe \"Cross-section\" widget and map canvas. An example is shown in which layer ids are plotted as colors, and borelogs are plotted as bars.\n\n\n\n\n\n\n\n\nNote\n\n\n\nA known issue with a multiple monitor setup is that the grid behind the plot might be plotted way off. See the known issues section for more info and how to fix this.\n\n\n\n\n Add NHI-data\nOpens up a window to select data from the NHI portal to load directly in QGIS. The NHI is the Netherlands Hydrological Instrument . The NHI data provides datasets with different kinds of services:\n\na \"Web Map Service\" (WMS), which provides a map with a (fixed) legend.\na \"Web Feature Service\" (WFS), which provides features from vector data via the internet.\na \"Web Coverage Service\" (WCS), which provides raster data via the internet.\n\nYou can use the search bar to search for datasets of your liking.\n\n\n\nThe \"Add NHI window\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nExperience has shown that sometimes these services are hard to reach and data cannot be loaded.",
    "crumbs": [
      "iMOD Viewer",
      "QGIS Plugin User Manual"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html",
    "href": "coupler_metamod_technical.html",
    "title": "Technical Reference",
    "section": "",
    "text": "This document describes how MetaSWAP and MODFLOW6 are coupled. It is intended for groundwater modellers, who need to know which variables are exchanged between computational kernels and at which moment. For details of the inner workings of the code, we refer to the docstrings in the code.\nBelow is a flowchart showing the order in which one timestep is iteratively solved and when data is exchanged between MetaSWAP and MODFLOW6.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html#modflow-6-to-metaswap",
    "href": "coupler_metamod_technical.html#modflow-6-to-metaswap",
    "title": "Technical Reference",
    "section": "MODFLOW 6 to MetaSWAP",
    "text": "MODFLOW 6 to MetaSWAP\n\nHeads\nMODFLOW sets the heads in MetaSWAP, to be specific the hgwmodf variable. When multiple svats are coupled to one MODFLOW cell, each svat is given MODFLOW’s head. When multiple MODFLOW cells are coupled to one svat, the arithmetic average is taken.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html#metaswap-to-modflow",
    "href": "coupler_metamod_technical.html#metaswap-to-modflow",
    "title": "Technical Reference",
    "section": "MetaSWAP to MODFLOW",
    "text": "MetaSWAP to MODFLOW\nMetaSWAP provides a recharge, sets the storage, and extracts groundwater from deeper layers for sprinkling (if switched on).\n\nStorage\nq\n\n\nRecharge\nRecharge is provided by MetaSWAP to MODFLOW. MetaSWAP internally stores volumes that should be provided to MODFLOW, so these are converted to rates by dividing by the timestep length. When multiple svats are coupled to one MODFLOW cell, recharge rates are summed.\n\n\nSprinkling\nGroundwater extraction rates to set sprinkling are computed by MetaSWAP based on irrigation requirements. MetaSWAP internally stores volumes that should be provided to MODFLOW, so these are converted to rates by dividing by the timestep length. When multiple svats are coupled to one MODFLOW cell, extraction rates are summed.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html#metaswap",
    "href": "coupler_metamod_technical.html#metaswap",
    "title": "Technical Reference",
    "section": "MetaSWAP",
    "text": "MetaSWAP\n\nmod2svat.inp\nThe file format for this file is also described in the SIMGRO IO manual. It is as follows:\nnode_nr svat ly\n...\nWere node_nr is the MODFLOW6 node number (to be specific: the user node number), which replaces the MODFLOW 2005 CellID. svat is the MetaSWAP svat number and ly is the MODFLOW layer number. Note that the format for this file should be fixed to\nf\"{nodenr:10d}  {svat:10d}{ly:2d}\"\nwhere the number behind the colon indicated the number of characters, padded with whitespace. Note the two whitespaces between nodenr and svat.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html#modflow-6",
    "href": "coupler_metamod_technical.html#modflow-6",
    "title": "Technical Reference",
    "section": "MODFLOW 6",
    "text": "MODFLOW 6\n\n[filename].rch\nA dummy recharge file, of which the fluxes will be overridden. The location of the recharge cells is used to assign an recharge index by Modflow6. The file format of the .rch file is described here. To specify an uncoupled recharge as well, a second RCH package should be defined. How to define a second stress package is explained here. Please note that in the model name file the package name should correspond to the package name specified in the configuration file.\n\n\n[filename].wel\nA dummy well file, of which the fluxes will be overridden. The location of the wells is used to assign a well index by Modflow6. The file format of the .wel file is described here. To specify uncoupled extractions/injections as well, a second WEL package should be defined. How to define a second stress package is explained here. Please note that the package name in the model name file should correspond to the package name specified in the configuration file.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_metamod_technical.html#coupler",
    "href": "coupler_metamod_technical.html#coupler",
    "title": "Technical Reference",
    "section": "Coupler",
    "text": "Coupler\n\nnodenr2svat.dxc\nThis file takes care of mapping the MODFLOW node numbers to the MetaSWAP svats, which is required for coupling the heads and storages of both kernels, it thus excludes nodes connected where wells are for sprinkling. The file format is as follows:\nnode_nr svat ly\n...\nWhere node_nr is the MODFLOW6 node number (to be specific: the user node number), which replaces the MODFLOW 2005 CellID. svat is the MetaSWAP svat number and ly is the Modflow layer number.\n\n\nrchindex2svat.dxc\nThis file takes care of mapping the recharge cells to the MetaSWAP svats. The file format is as follows:\nrch_index svat ly\n...\nWhere rch_index is the MODFLOW6 RCH index number, which equals the row number of the data specified under period in the .rch file. svat is the MetaSWAP svat number and ly is the MODFLOW layer number.\n\n\nwellindex2svat.dxc\nThis file takes care of mapping MODFLOW wells to the MetaSWAP svats for sprinkling. The file format is as follows:\nwell_index svat ly\n...\nWhere well_index is the MODFLOW6 WEL index number, which equals the row number of the data specified under period in the .wel file. svat is the MetaSWAP svat number and ly is the MODFLOW layer number.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribametamod_technical.html",
    "href": "coupler_ribametamod_technical.html",
    "title": "Technical Reference",
    "section": "",
    "text": "This document describes the complete Ribasim - MetaSWAP - MODFLOW 6 coupling sequence, the operations performed by the individual components as well as the exchanges of data among the components.\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    Ribasim -&gt;&gt; MODFLOW 6: stage [t-1]\n    MODFLOW 6 -&gt;&gt; Ribasim: estimated RIV flux, active & passive  [t-1]\n\n    loop Ribasim-MetaSWAP subtimesteps [tsw]\n        Note over MetaSWAP: prepare surface water timestep tsw\n        MetaSWAP-&gt;&gt;Ribasim:  ponding runoff [tsw]\n        MetaSWAP-&gt;&gt;Ribasim:  estimated sprinkling [tsw]\n        Note over Ribasim: solve tsw\n        Ribasim -&gt;&gt; MetaSWAP: realized sprinkling [tsw]\n    end\n    Ribasim -&gt;&gt; MODFLOW 6: realized RIV, active [t]\n    MODFLOW 6 -&gt;&gt; MetaSWAP: head [t-1] \n    loop MODFLOW 6-MetaSWAP iterations (solving t)\n        Note over MetaSWAP: solve iter\n        MetaSWAP -&gt;&gt; MODFLOW 6: storage coefficient [iter]\n        MetaSWAP -&gt;&gt; MODFLOW 6: recharge flux [iter]\n        MetaSWAP -&gt;&gt; MODFLOW 6: groundwater sprinkling flux [iter]\n        Note over MODFLOW 6: solve iter\n        MODFLOW 6 -&gt;&gt; MetaSWAP: head [iter] \n    end\n\n\n\n\n\n\n\nThe exchanges between kernels can be summarized as follows:\n\n\nExchange the Ribasim subgrid stage from the previous timestep to actively coupled RIV en DRN packages.\n\n\nEstimated RIV and DRN flux, exchanged to Ribasim basins\n\n Ribasim-MetaSWAP sub-timestepping:\n\nRunoff from MetaSWAP exchanged to Ribasim basins\n\n\nIrrigation demand from MetaSWAP svats to Ribasim water users.\n\n\nIrrigation volume on svats based on realized volumes per water user\n\n\nFlux correction in the case that Ribasim basins are unable to meet the total infiltration demand.\n\n MODFLOW 6-MetaSWAP iterations:\n\nHead of MODFLOW 6 to MetaSWAP\n\n\nStorage coefficient from MetaSWAP sent to MODFLOW 6\n\n\nRecharge from MetaSWAP sent to MODFLOW 6 as a source term\n\n\nGroundwater sprinkling flux requested by MetaSWAP, extracted from MODFLOW 6\n\n\n\nSome remarks\n\nIf allocation is active in the Ribasim model, the demand-realisation cycle for irrigation is based on the user priority and the water availability. When inactive it is based on water availability alone.\n\nFor coupling surface water to Ribasim, only the RIV and DRN package can be used. Other packages like GHB are not supported and should not be present in coupled domain.\n\n\n\nActive versus passive coupling\nIn coupling Ribasim and MODFLO 6, a distinction exists between active and passive coupling. In a passive coupling fluxes on the MODFLOW 6 side are evaluated irrespective of the Ribasim waterlevels and contribute directly to the Ribasim basins. The Ribasim water levels are not required in this case, fluxes are simply regarded as “lateral” sources to the basin, hence configuration on the Ribasim side is minimal. The passive approach is justified for drainage packages showing little variation in terms of elevation over time (e.g. surface runoff, or ditches with negligible water depth). On the contrary, in the case of an active coupling fluxes depend (linearly) on the Ribasim water levels. This requires the stages in the MODFLOW 6 model to be set to the subgrid water levels of Ribasim prior to evaluation of the river fluxes.\nIn the case of river packages “over-infiltration” can cause Ribasim water levels can fall to zero, leaving a dry basin. Since in the passive situation, water levels are not taken into account, no feedback occurs that limits or impedes infiltration. The MODFLOW 6 model assumes infiltration to continue, whereas the coupled Ribasim basin already ran out of water. This raises a discrepancy in the water balance between both models. Therefore, passive couplings are unsuitable for river packages In active couplings, infiltration stops when the basin dries up and the water level reaches the bed elevation.\n\n\nEstimated sprinkling flux\nWithin the Ribasim context, the sprinkling flux is implemented as a water user. The sprinkling demand is exchanged to Ribasim through the user demand matrix. From the couplers perspective, this is a two-dimensional array in which every column represents a water user and every row corresponds with a priority. The array elements are water demands for the users (also for other water users beside sprinkling), each with their own set of priorities. Priorities play a role on the Ribasim side only if allocation is active. Within Ribasim, water users are defined as nodes in the network and in the coupler water users are mapped onto MetaSWAP svats. For every of those users, the water demand can be non-zero for a single priority only.\n\n\nRealized sprinkling flux and infiltration flux correction.\nBefore performing a Ribasim update, the surface water sprinkling amounts in MetaSWAP and the active infiltration or drainage in MODFLOW 6 have been evaluated under the assumption of an unlimited availability of surface water for these processes (steps 2 and 4) . After Ribasims timestep, the realized extraction is known in Ribasim and this information must somehow be communicated to MODFLOW 6 (step 6) and MetaSWAP (step 5) in order to maintain a correct overall water balance.\nFor the surface water sprinkling the following procedure is used to derive the realized fluxes for the MetaSWAP units.\n\nThe realized fraction \\(f_i\\) is derived of the realized sprinkling flux \\(R_i\\), compared to the requested flux \\(D_i\\) for Ribasim element \\(i\\). i.o.w. \\[\nf_i\\,=\\,\n\\begin{align}\n\\begin{cases}\n  R_i/D_i & D_i\\neq 0 \\\\\n  0 & D_i = 0\n\\end{cases}\n\\end{align}\n\\]\nThe real contribution of Ribasim element \\(i\\) to MetaSWAP element \\(j\\) was then \\(f_i A_{ij} M^*_j\\), where \\(M^*\\) denotes the MetaSWAP vector of demand fluxes and \\(A_{ij}\\) refers to an element of the couple matrix.\nSo, the total realized flux \\(M_j\\) received by MetaSWAP element \\(j\\) is then obtained by summation over \\(j\\): \\[\nM_j\\,=\\,\\sum\\limits_j f_i A_{ij} M^*_j\n\\],,, or in vector notation for all MetaSWAP elements: \\[\n\\hspace{1cm}\n\\mathbf{M}\\,=\\,(A^T\\mathbf{f})\\odot\\mathbf{M^*}\n\\]\n\nThe evaluation of the correction of the infiltration flux, for MODFLOW 6 proceeds in a similar fashion, except:\n\nNot the realized fraction \\(f_i\\), but its complement \\(1-f_i\\) is used to obtain the correction \\(C_j\\) on the infiltration flux.\nThis correction is only applied to the negative demands. The positive demands, associated with drainage, are always granted.\nThe correction amounts represent a lack of water already infiltrated into MODFLOW 6, which turned out not to be available at the end of the Ribasim timestep. Hence, this is corrected by means of a negative source term in MODFLOW 6 in the next groundwater timestep. \\[\n\\begin{align}\nC_j\\,=\\,\n\\begin{cases}\n\\sum\\limits_j (1-f_i) A_{ij} M^*_j  & M^*_j&lt;0 \\\\\n0 & M^*_j&gt;0\n\\end{cases}\n\\end{align}\n\\]\n\nThis must be taken into account into the realized fraction for a correct water balance. Therefore, the demand \\(D_i\\) to Ribasim element \\(i\\) is now plit into \\(D_{i-}\\) and, \\(D_{i+}\\), summing fluxes over the infiltrating and draining MODFLOW 6 elements respectively.\n\\[\nf_i\\,=\\,\n\\begin{align}\n\\begin{cases}\n    (R_i - D_{i+})/D_{i-} & D_{i-}\\neq 0 \\\\\n    0 & D_{i-} = 0\n\\end{cases}\n\\end{align}\n\\]\nThe correction \\(C_j\\) enters MODFLOW 6 as a negative right-hand side term, i.e. extraction.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "viewer.html",
    "href": "viewer.html",
    "title": " iMOD Viewer",
    "section": "",
    "text": "The iMOD Viewer consist of a standalone 3D viewer and a QGIS plugin.\n\nThe iMOD 3D Viewer is a 3D viewer for grids and datasets. It supports IDF files, UGRID files and Grb.disu files that contain an unstructured layered grid.\nThe 3D Viewer also supports viewing some non-grid objects like IPF files and Shapefiles.\nThe iMOD QGIS plugin aids exploring 4D geospatial data in QGIS.\nIts primary components are visualization of timeseries, both at points as well as on an unstructured grid, cross-section visualization, including borelogs, and connecting to the 3D Viewer.",
    "crumbs": [
      "iMOD Viewer",
      "{{< fa solid binoculars >}} iMOD Viewer"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": " Introduction",
    "section": "",
    "text": "The iMOD Suite provides tools to efficiently build and visualize groundwater models.\nDeltares is working to integrate and improve our groundwater software. Therefore iMOD is extended with a new iMOD Suite to link to the latest developments on the MODFLOW and on the changing requirements in the field of groundwatermodelling, most pressing currently the support of unstructured grids.\nWe created the new iMOD Suite to aid pre- and post-processing unstructured groundwater models. Furthermore, a second goal of this suite was to better connect to the latest developments in the data science ecosystem, by utilizing:\n\nExisting data format conventions (NetCDF, UGRID) instead of developing new ones, allowing more user flexibility to find the right tools for the right job.\nWidely used and tested software (QGIS) to which we add our extension, instead of creating complete programs ourselves.\nModern programming languages (C++ and Python) that allow connecting to a big and lively software ecoystem.\n\nThe iMOD Suite offers different modules which support modelling with MODFLOW 6 (including unstructured meshes):\n\niMOD Viewer: The iMOD Viewer consist of a standalone 3D viewer and a QGIS plugin. The iMOD QGIS Plugin allows visualisation of model input and output with tools for cross-sections, timeseries and link to the 3D viewer. It supports structured NetCDF, UGRID and IPF files. And the iMOD 3D Viewer for interactive 3D visualisation of unstructured input and output. Supports UGRID file format and IPF borelog files.\niMOD Python: A Python package to support MODFLOW groundwater modeling. It makes it easy to go from your raw data to a fully defined MODFLOW model, with the aim to make this workflow reproducible.\niMOD Coupler: Software that couples MODFLOW 6 to other computational cores. It currently supports a coupling to MetaSWAP, but additional computational cores are planned in the future.\n\n\n\n\nEasy plotting of 4 dimensional [t, z, y, x] data in the iMOD QGIS plugin. The example shows the chlorine concentrations computed by the NHI fresh-salt model.\n\n\n\n\n\nThe chlorine concentrations computed by the NHI-fresh-salt model for the province of Zeeland, plotted in the new iMOD 3D viewer. The top layer is made partly transparent, creating the pretty mist effect in the creek ridges."
  },
  {
    "objectID": "introduction.html#whats-included",
    "href": "introduction.html#whats-included",
    "title": " Introduction",
    "section": "",
    "text": "The iMOD Suite provides tools to efficiently build and visualize groundwater models.\nDeltares is working to integrate and improve our groundwater software. Therefore iMOD is extended with a new iMOD Suite to link to the latest developments on the MODFLOW and on the changing requirements in the field of groundwatermodelling, most pressing currently the support of unstructured grids.\nWe created the new iMOD Suite to aid pre- and post-processing unstructured groundwater models. Furthermore, a second goal of this suite was to better connect to the latest developments in the data science ecosystem, by utilizing:\n\nExisting data format conventions (NetCDF, UGRID) instead of developing new ones, allowing more user flexibility to find the right tools for the right job.\nWidely used and tested software (QGIS) to which we add our extension, instead of creating complete programs ourselves.\nModern programming languages (C++ and Python) that allow connecting to a big and lively software ecoystem.\n\nThe iMOD Suite offers different modules which support modelling with MODFLOW 6 (including unstructured meshes):\n\niMOD Viewer: The iMOD Viewer consist of a standalone 3D viewer and a QGIS plugin. The iMOD QGIS Plugin allows visualisation of model input and output with tools for cross-sections, timeseries and link to the 3D viewer. It supports structured NetCDF, UGRID and IPF files. And the iMOD 3D Viewer for interactive 3D visualisation of unstructured input and output. Supports UGRID file format and IPF borelog files.\niMOD Python: A Python package to support MODFLOW groundwater modeling. It makes it easy to go from your raw data to a fully defined MODFLOW model, with the aim to make this workflow reproducible.\niMOD Coupler: Software that couples MODFLOW 6 to other computational cores. It currently supports a coupling to MetaSWAP, but additional computational cores are planned in the future.\n\n\n\n\nEasy plotting of 4 dimensional [t, z, y, x] data in the iMOD QGIS plugin. The example shows the chlorine concentrations computed by the NHI fresh-salt model.\n\n\n\n\n\nThe chlorine concentrations computed by the NHI-fresh-salt model for the province of Zeeland, plotted in the new iMOD 3D viewer. The top layer is made partly transparent, creating the pretty mist effect in the creek ridges."
  },
  {
    "objectID": "introduction.html#comparison-with-imod-5",
    "href": "introduction.html#comparison-with-imod-5",
    "title": " Introduction",
    "section": "Comparison with iMOD 5",
    "text": "Comparison with iMOD 5\nThe proven technology and expertise of iMOD is consolidated within iMOD 5. iMOD 5 supports structured calculations with MODFLOW2005 and structured MODFLOW 6 and can be coupled to the unsaturated zone model MetaSWAP. The model input and output can be visualised in its fast interactive viewer. The documentation of iMOD 5 can be found here .\nImportant technological innovations will be developed in the new iMOD Suite, whereas iMOD 5 will be maintained the coming years, but will see no big new feature developments. Table 1 and Table 2 respectively provide comparisons between iMOD Suite and iMOD 5 for the components and supported MODFLOW6 packages.\n\n\n\nTable 1: Comparison between iMOD Suite & iMOD 5\n\n\n\n\n\n\n\n\n\n\n\niMOD Suite\niMOD 5\n\n\n\n\ncomputational kernels\nMODFLOW 2005, MODFLOW 6, SEAWAT, MT3DMS, MetaSWAP\nMODFLOW 2005, MODFLOW 6, SEAWAT, MT3DMS, MetaSWAP\n\n\nfile types\nNetCDF, UGRID, shp, tiff, idf, ipf, gen\nidf, ipf, isg, gen\n\n\ngrid types\nstructured & unstructured\nstructured & nested structured\n\n\nscripted pre-processing\niMOD Python\niMOD Batch\n\n\ninteractive pre-processing\n(QGIS)\niMOD GUI\n\n\nscripted 2D plot\niMOD Python\niMOD Batch\n\n\ninteractive 2D plot\niMOD QGIS plugin (& QGIS)\niMOD GUI\n\n\nscripted 3D plot\niMOD Python\n\n\n\ninteractive 3D plot\niMOD 3D Viewer\niMOD GUI\n\n\n\n\n\n\n\n\n\nTable 2: Supported MODFLOW6 flow packages in iMOD Suite & iMOD 5\n\n\n\n\n\n\n\n\n\n\n\nPackage\nDescription\niMOD Suite\niMOD 5\n\n\n\n\nDIS\nStructured Discretization\nx\nx\n\n\nDISV\nDiscretization by Vertices\nx\n\n\n\nDISU\nStructured Discretization\n\n\n\n\nIC\nInitial Conditions\nx\nx\n\n\nOC\nOutput Control\nx\nx\n\n\nNPF\nNode Property Flow\nx\nx\n\n\nHFB\nHorizontal Flow Barrier\nx\nx\n\n\nSTO\nStorage\nx\nx\n\n\nCSUB\nSkeletal Storage, Compaction, and Subsidence\n\n\n\n\nBUY\nBuoyancy\nx\n\n\n\nCHD\nConstant-Head\nx\nx\n\n\nWEL\nWell\nx\nx\n\n\nDRN\nDrain\nx\nx\n\n\nRIV\nRiver\nx\nx\n\n\nGHB\nGeneral-Head Boundary\nx\nx\n\n\nRCH\nRecharge\nx\nx\n\n\nEVT\nEvapotranspiration\nx\nx\n\n\nMAW\nMulti-Aquifer Well\n\n\n\n\nSFR\nStreamflow Routing\n\nx\n\n\nLAK\nLake\n\n\n\n\nUZF\nUnsaturated Zone Flow\nx\n\n\n\nMVR\nWater Mover"
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": " iMOD Python",
    "section": "",
    "text": "The iMOD Python package is designed to help you in your MODFLOW groundwater modeling efforts. It makes it easy to go from your raw data to a fully defined MODFLOW model, with the aim to make this process reproducible. Whether you want to build a simple 2D conceptual model, or a complex 3D regional model with millions of cells, iMOD Python scales automatically by making use of dask.\nBy building on top of popular Python packages like xarray, pandas, rasterio and geopandas, a lot of functionality comes for free.\nCurrently we support the creation of the following MODFLOW-based models:\n\nUSGS MODFLOW 6, currently only the Groundwater Flow packages\niMODFLOW\niMOD-WQ, which integrates SEAWAT (density-dependent groundwater flow) and MT3DMS (multi-species reactive transport calculations)\n\nDocumentation: https://deltares.github.io/imod-python/ This documentation includes a section \"How do I\" which can be used for common data conversions in imod-python or xarray. This section will be regular updated based on the different questions of users.\nSource code: https://github.com/Deltares/imod-python",
    "crumbs": [
      "iMOD Python",
      "{{< fa brands python >}} iMOD Python"
    ]
  },
  {
    "objectID": "coupler_metamod_config.html",
    "href": "coupler_metamod_config.html",
    "title": "Configuration",
    "section": "",
    "text": "The configuration file is necessary to describe the model and its dependencies. It is in the toml format and should have a .toml extension.\nNote that toml uses quote marks differently than python. Single quotes in toml ('') are interpreted similarly to how python would interpret a rawstring (r'' or r\"\"), whereas double quotes (\"\") are interpreted similarly to regular strings in python (\"\" or ''). This matters for paths on Windows, for which we advise to use single quotes.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "coupler_metamod_config.html#config-schema",
    "href": "coupler_metamod_config.html#config-schema",
    "title": "Configuration",
    "section": "Config schema",
    "text": "Config schema\n\nlog_level\n\n\n\n\n\n\ndescription\nThis setting determines the severity and therefore the verbosity of the log messages.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\ndefault\nINFO\n\n\nenum\nDEBUG, INFO, WARNING, ERROR, CRITICAL\n\n\n\n\ntiming\n\n\n\n\n\n\ndescription\nSpecifies whether the coupling should be timed. This option requires the log level to at least include INFO.\n\n\ntype\nbool\n\n\nrequired\nfalse\n\n\ndefault\nfalse\n\n\n\n\ndriver_type\n\n\n\n\n\n\ndescription\nSpecifies which driver should be used. Typically, this determines which hydrological kernels are coupled.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\nenum\nmetamod\n\n\n\n\ndriver.kernels.modflow6\n\ndll\n\n\n\n\n\n\ndescription\nThe path to the MODFLOW 6 library.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\ndll_dep_dir\n\n\n\n\n\n\ndescription\nThe path to the dependencies of MODFLOW 6.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\n\n\nwork_dir\n\n\n\n\n\n\ndescription\nThe working directory MODFLOW 6 expects. This is the directory where the simulation name file resides.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\n\ndriver.kernels.metaswap\n\ndll\n\n\n\n\n\n\ndescription\nThe path to the MetaSWAP library.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\ndll_dep_dir\n\n\n\n\n\n\ndescription\nThe path to the dependencies of MetaSWAP.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\n\n\nwork_dir\n\n\n\n\n\n\ndescription\nThe working directory MetaSWAP expects.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\n\ndriver.coupling\n\nmf6_model\n\n\n\n\n\n\ndescription\nSpecifies the MODFLOW 6 model name to which MetaSWAP will be coupled.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nmf6_msw_recharge_pkg\n\n\n\n\n\n\ndescription\nSpecifies the package name (specified in the Modflow 6 simulation name file) of the recharge package to which MetaSWAP will be coupled.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nmf6_msw_well_pkg\n\n\n\n\n\n\ndescription\nSpecifies the package name (specified in the Modflow 6 simulation name file) of the recharge package to which MetaSWAP will be coupled. This setting is only required if enable_sprinkling is set to true.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\n\n\nmf6_msw_node_map\n\n\n\n\n\n\ndescription\nPath to the file specifying the mapping between MODFLOW 6 cells and MetaSWAP svats.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nmf6_msw_recharge_pkg\n\n\n\n\n\n\ndescription\nPath to the file specifying the mapping between MODFLOW 6 recharge cells and MetaSWAP svats.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nmf6_msw_sprinkling_map_groundwater\n\n\n\n\n\n\ndescription\nPath to the file specifying the mapping between MODFLOW 6 wells and MetaSWAP svats.\n\n\ntype\nstr\n\n\nrequired\nfalse",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "coupler_ribametamod_config.html",
    "href": "coupler_ribametamod_config.html",
    "title": "Configuration",
    "section": "",
    "text": "The configuration file is necessary to describe the model and its dependencies. It is in the toml format and should have a .toml extension.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "coupler_ribametamod_config.html#config-schema",
    "href": "coupler_ribametamod_config.html#config-schema",
    "title": "Configuration",
    "section": "Config schema",
    "text": "Config schema\n\n\n\n\n\n\nname\n\n\ndescription\n\n\ntype\n\n\n default\n\n\nenum \n\n\n\n\n\n\n\n\nlog_level\n\n\nverbosity of logging\n\n\nstr\n\n\nINFO\n\n\nDEBUG, INFO, WARNING, ERROR, CRITICAL\n\n\n\n\n\n\ntiming\n\n\nprofiling active? if so, record timing\n\n\nboolean\n\n\nfalse\n\n\n\n\n\n\n\n\ndriver_type\n\n\nchosen coupler implementation. Typically associated with the set of coupled kernels\n\n\nstr\n\n\n\n\n\n\n\n\n\n\ndriver.kernels.modflow6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndll\n\n\npath to the MODFLOW 6 library file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\ndll_dep_dir\n\n\noptional path to the library’s dependencies\n\n\nstr\n\n\n[..]\n\n\n\n\n\n\n\n\nworkdir\n\n\npath to the MODFLOW 6 working directory holding the simulation name file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\ndriver.kernels.metaswap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndll\n\n\npath to the MetaSWAP library file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\ndll_dep_dir\n\n\noptional path to the library’s dependencies\n\n\nstr\n\n\n[..]\n\n\n\n\n\n\n\n\nworkdir\n\n\npath to the MetaSWAP working directory holding the parasim.inp name file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\ndriver.kernels.ribasim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndll\n\n\npath to the Ribasim library file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nconfig_file\n\n\npath to the Ribasim config file\n\n\nstr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndriver.coupling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmf6_model\n\n\nname of the MODFLOW 6 model (within the simulation) to couple\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nmf6_msw_node_map\n\n\nfile with MODFLOW 6 node to MetaSWAP svat mapping\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nmf6_msw_recharge_pkg\n\n\nname of MODFLOW 6 recharge package for coupling with MetaSWAP\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nmf6_msw_recharge_map\n\n\nfile with MODFLOW 6 recharge index to MetaSWAP svat mapping\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nmf6_msw_well_pkg\n\n\nname of MODFLOW 6 well package for coupling with MetaSWAP groundwater sprinkling\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nrib_msw_ponding_map_groundwater\n\n\nfile with Ribasim node index to MetaSWAP svat mapping for ponding\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nrib_msw_ponding_map_surface_water\n\n\nfile with Ribasim node index to MetaSWAP svat mapping for surface water sprinkling\n\n\nstr\n\n\n\n\n\n\n\n\n\n\nrib_msw_sprinkling_map_surface_water\n\n\nfile with Ribasim node index to MetaSWAP svat mapping for surface water sprinkling\n\n\nstr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmf6_active_river_packages\n\n\ndictionary of active MODFLOW 6 river packages with couple file\n\n\ndict\n\n\n\n\nmf6_passive_river_packages\n\n\ndictionary of passive MODFLOW 6 river packages with couple file\n\n\ndict\n\n\n\n\n\nmf6_active_river_packages\n\n\ndictionary of active MODFLOW 6 drainage packages with couple file\n\n\ndict\n\n\n\n\nmf6_passive_river_packages\n\n\ndictionary of passive MODFLOW 6 drainage packages with couple file\n\n\ndict\n\n\n\n\noutput_config_file\n\n\n.toml specifying kernel exchanges for which to record values to output files as timeseries\n\n\nstr",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "tutorial_wq.html",
    "href": "tutorial_wq.html",
    "title": "Conceptual fresh-salt model",
    "section": "",
    "text": "In this example we create an example fresh-salt groundwater model of a strip-shaped freshwater lens, which could be a very simple analogue of a barrier island.\nThe workflow consists of the following steps:\n\nCreating a model with an iMOD-python script\nRunning the model in a terminal with iMOD-WQ\nUse iMOD-python to post-process the model output (IDF) to a data format supported by QGIS (UGRID)\nViewing a cross-section in iMOD QGIS plugin\nUse the plugin to view the results in the iMOD 3D viewer",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#description",
    "href": "tutorial_wq.html#description",
    "title": "Conceptual fresh-salt model",
    "section": "",
    "text": "In this example we create an example fresh-salt groundwater model of a strip-shaped freshwater lens, which could be a very simple analogue of a barrier island.\nThe workflow consists of the following steps:\n\nCreating a model with an iMOD-python script\nRunning the model in a terminal with iMOD-WQ\nUse iMOD-python to post-process the model output (IDF) to a data format supported by QGIS (UGRID)\nViewing a cross-section in iMOD QGIS plugin\nUse the plugin to view the results in the iMOD 3D viewer",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#creating-a-model",
    "href": "tutorial_wq.html#creating-a-model",
    "title": "Conceptual fresh-salt model",
    "section": "Creating a model",
    "text": "Creating a model\nThe iMOD-python script below creates a simple 3D iMOD-WQ model.\nTo install iMOD-python, see these instructions.\nWe define a middle strip which has fresh recharge (rch) applied, and the sides have a fixed concentration (bnd = -1) of 35 (sconc = 35.) in the top layer. This creates freshwater lens along the strip.\nimport numpy as np\nimport xarray as xr\n\nimport imod\n\n\n# Discretization\nnrow = 40  # number of rows\nncol = 40  # number of columns\nnlay = 15  # number of layers\n\ndz = 10\ndx = 250\ndy = -dx\n\nx = np.arange(0.5 * dx, dx * ncol, dx)\ny = np.arange(-dy * ncol, 0.5 * -dy, dy)\n\n# setup ibound\nbnd = xr.DataArray(\n    data=np.full((nlay, nrow, ncol), 1.0),\n    coords={\n        \"y\": y,\n        \"x\": x,\n        \"layer\": np.arange(1, 1 + nlay),\n        \"dx\": dx,\n        \"dy\": dy,\n    },\n    dims=(\"layer\", \"y\", \"x\"),\n)\n\n# set constant heads\nbnd[0, :, 0:12] = -1\nbnd[0, :, 28:40] = -1\n\n# set up tops and bottoms\ntop1D = xr.DataArray(\n    np.arange(nlay * dz, 0.0, -dz), {\"layer\": np.arange(1, nlay + 1)}, (\"layer\")\n)\n\ntop3D = top1D * xr.full_like(bnd, 1.0)\nbot = top3D - dz\n\n# Defining the starting concentrations\nsconc = xr.DataArray(\n    data=np.full((nlay, nrow, ncol), 35.0),\n    coords={\n        \"y\": y,\n        \"x\": x,\n        \"layer\": np.arange(1, nlay + 1),\n        \"dx\": dx,\n        \"dy\": dy,\n    },\n    dims=(\"layer\", \"y\", \"x\"),\n)\n\nsconc[0, :, 13:27] = 0.0\n\n# Defining the recharge rates\nrch_rate = xr.DataArray(\n    data=np.full((nrow, ncol), 0.0),\n    coords={\"y\": y, \"x\": x, \"dx\": dx, \"dy\": dy},\n    dims=(\"y\", \"x\"),\n)\nrch_rate[:, 13:27] = 0.001\n\nrch_conc = xr.full_like(rch_rate, fill_value=0.0)\n\n\n# Finally, we build the model.\n\nm = imod.wq.SeawatModel(\"FreshwaterLens\")\nm[\"bas\"] = imod.wq.BasicFlow(\n    ibound=bnd, top=top3D.sel(layer=1), bottom=bot, starting_head=0.0\n)\nm[\"lpf\"] = imod.wq.LayerPropertyFlow(\n    k_horizontal=10.0, k_vertical=20.0, specific_storage=0.0\n)\nm[\"btn\"] = imod.wq.BasicTransport(\n    icbund=bnd, starting_concentration=sconc, porosity=0.35\n)\nm[\"adv\"] = imod.wq.AdvectionTVD(courant=1.0)\nm[\"dsp\"] = imod.wq.Dispersion(longitudinal=0.0, diffusion_coefficient=0.0)\nm[\"vdf\"] = imod.wq.VariableDensityFlow(density_concentration_slope=0.71)\nm[\"rch\"] = imod.wq.RechargeHighestActive(rate=rch_rate, concentration=0.0)\nm[\"pcg\"] = imod.wq.PreconditionedConjugateGradientSolver(\n    max_iter=150, inner_iter=30, hclose=0.0001, rclose=0.1, relax=0.98, damp=1.0\n)\nm[\"gcg\"] = imod.wq.GeneralizedConjugateGradientSolver(\n    max_iter=150,\n    inner_iter=30,\n    cclose=1.0e-6,\n    preconditioner=\"mic\",\n    lump_dispersion=True,\n)\nm[\"oc\"] = imod.wq.OutputControl(save_head_idf=True, save_concentration_idf=True)\nm.time_discretization(times=[\"1900-01-01T00:00\", \"2000-01-01T00:00\"])\n\n# Now we write the model, including runfile:\nm.write(\"FreshwaterLens\")\n# You can run the model using the command prompt and the iMOD-WQ executable",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#running-the-model",
    "href": "tutorial_wq.html#running-the-model",
    "title": "Conceptual fresh-salt model",
    "section": "Running the model",
    "text": "Running the model\nThis model requires the iMOD-WQ kernel, which is part of iMOD 5 and which you can download for free here after registering. It usually takes only a few minutes before a link is sent.\nOpen a terminal (cmd.exe is fine, but the cool kids use Powershell and call the following lines of code:\n./path/to/iMOD-WQ.exe ./FreshwaterLens.run\nThis will run the iMOD-WQ model, and should not take more than 10 seconds.\n\n\n\nIf everything worked well, iMOD WQ prints “Normal termination of iMOD-WQ”",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#convert-output-data",
    "href": "tutorial_wq.html#convert-output-data",
    "title": "Conceptual fresh-salt model",
    "section": "Convert output data",
    "text": "Convert output data\niMOD-WQ writes IDF files, a data format used in iMOD 5, which not many other software packages support. Therefore iMOD-python allows for reading these IDF files and converting them to other data formats in Python.\nIn this example we convert the output to a UGRID file, which can be read by QGIS.\nimport imod\nimport numpy as np\nimport xarray as xr\n\n# We assume that this script is located in the same directory\n# as in create_wq_input.py.\n# We provide a UNIX style global path\n# to select all IDF files in the conc directory.\nconc_path = \"./results/conc/*.IDF\"\nbottom_path = \"./FreshwaterLens/bas/bottom*.idf\"\ntop_path = \"./FreshwaterLens/bas/top.idf\"\n\n# Open the IDF files.\nconc = imod.idf.open(conc_path).compute()\nbottom = imod.idf.open(bottom_path).compute()\nsurface = imod.idf.open(top_path).compute()\n\n# Reconstruct vertical discretization\n# We need this as IDFs do not store vertical discretization\nsurface = surface.assign_coords(layer=1)\n\n## Create 3D array of tops\n### Roll bottom one layer downward: the bottom of a layer is top of next layer\ntop = bottom.roll(layer=1, roll_coords=False)\n### Remove layer 1\ntop = top.sel(layer=slice(2, None))\n### Add surface as layer 1\ntop = xr.concat([surface, top], dim=\"layer\")\n### Reorder dimensions\ntop = top.transpose(\"layer\", \"y\", \"x\")\n\n# Merge into dataset\nds = xr.merge([conc, top, bottom])\n\n# Create MDAL supported UGRID\n# NOTE: This requires iMOD-python v1.0(?)\nds_ugrid = imod.util.to_ugrid2d(ds)\n\n#%% Due to a bug in MDAL, we have to encode the times as floats\n# instead of integers\n# until this is fixed: https://github.com/lutraconsulting/MDAL/issues/348\nds_ugrid[\"time\"].encoding[\"dtype\"] = np.float64\n\nds_ugrid.to_netcdf(\"./results/output_ugrid.nc\")",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#viewing-the-results-in-qgis",
    "href": "tutorial_wq.html#viewing-the-results-in-qgis",
    "title": "Conceptual fresh-salt model",
    "section": "Viewing the results in QGIS",
    "text": "Viewing the results in QGIS\nStart QGIS and open the ./results/output_ugrid.nc file as a mesh.\n\n\n\nWhere to find the action to load a mesh layer\n\n\nYou can select the variable to plot on the map canvas by right-clicking the output_ugrid layer in the Layers panel, and then navigating to: Properties &gt; Symbology\nNext select which variable to plot in the group selection screen by clicking the color ramp next to the variable name, which will render the variable on the map canvas.\n\n\n\nWhere to find the group selection screen. Here you can select the variables to be plotted. The red circle indicates where the color ramp symbol can be found.\n\n\nColormaps can be set by navigating to the color selection menu\n\n\n\nThe color selection menu, here you can set the colormap that will be used, as well as adjusting its binning. In these example screenshots we use the colormap \"Spectral\".\n\n\nNext, open the iMOD plugin's cross-section tool  and draw a cross-section by clicking from Map and right-clicking to stop drawing. Then select conc as variable to be plotted, and click Add. Next click Plot.\nBy default the tool will plot with a green to blue gradient called Viridis, but we can change the gradient by clicking the dataset's gradient box under symbology in the table.\nThis opens up a color dialog, where we can select the color ramp. Clicking the small arrow next to the color gradient box in the dialog will allow selecting presets. We chose \"Spectral\" and also select \"Invert Color Ramp\" in the examples, but you can select whatever colormap you think is suitable!\n\n\n\nYou should see this if you followed precisely what we did.",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#viewing-the-results-in-the-imod-3d-viewer",
    "href": "tutorial_wq.html#viewing-the-results-in-the-imod-3d-viewer",
    "title": "Conceptual fresh-salt model",
    "section": "Viewing the results in the iMOD 3D Viewer",
    "text": "Viewing the results in the iMOD 3D Viewer\nAs a final step we will look at the results in the iMOD 3D Viewer. Click the 3D viewer symbol  in QGIS, which will open up the 3D viewer widget of the iMOD plugin.\nFirst, click the Draw Extent button to draw an extent to be plotted. This can be very useful for large datasets, to only look at a smaller zone of the data.\nSecond, click Start iMOD 3D viewer to start the iMOD 3D viewer. Third, click Load mesh data to load the mesh you selected in the QGIS widget to be opened in the 3D viewer.\nFourth, to plot the data, under the Imported files, expand the data selection tree, and under Layered datasets, selecting conc.\nFinally, you can migrate the colormap you used in QGIS by clicking Load legend.\n\n\n\nIf you followed the instructions, you should see this.",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "tutorial_wq.html#concluding",
    "href": "tutorial_wq.html#concluding",
    "title": "Conceptual fresh-salt model",
    "section": "Concluding",
    "text": "Concluding\nIn short, we wrote model input with iMOD-python, ran a model with iMOD-WQ, converted its output to UGRID with iMOD-python, and viewed the results in QGIS and the iMOD 3D viewer.",
    "crumbs": [
      "Tutorials",
      "Conceptual fresh-salt model"
    ]
  },
  {
    "objectID": "primod_api/index.html",
    "href": "primod_api/index.html",
    "title": "Primod API Reference",
    "section": "",
    "text": "Couple MetaSWAP and MODFLOW 6.\n\n\n\nMetaMod\nCouple MetaSWAP and MODFLOW 6.\n\n\nMetaModDriverCoupling\n\n\n\n\n\n\n\nCouple Ribasim and MODFLOW 6.\n\n\n\nRibaMod\nCouple Ribasim and MODFLOW 6.\n\n\nRibaModActiveDriverCoupling\n\n\n\nRibaModPassiveDriverCoupling\n\n\n\n\n\n\n\nCouple Ribasim, MetaSWAP and MODFLOW 6.\n\n\n\nRibaMetaMod\nCouple Ribasim, MetaSWAP and MODFLOW 6.\n\n\nRibaMetaDriverCoupling\nA dataclass representing one coupling scenario for the RibaMod driver.\n\n\nRibaModActiveDriverCoupling\n\n\n\nRibaModPassiveDriverCoupling\n\n\n\nMetaModDriverCoupling",
    "crumbs": [
      "iMOD Coupler",
      "Primod API Reference"
    ]
  },
  {
    "objectID": "primod_api/index.html#metamod",
    "href": "primod_api/index.html#metamod",
    "title": "Primod API Reference",
    "section": "",
    "text": "Couple MetaSWAP and MODFLOW 6.\n\n\n\nMetaMod\nCouple MetaSWAP and MODFLOW 6.\n\n\nMetaModDriverCoupling",
    "crumbs": [
      "iMOD Coupler",
      "Primod API Reference"
    ]
  },
  {
    "objectID": "primod_api/index.html#ribamod",
    "href": "primod_api/index.html#ribamod",
    "title": "Primod API Reference",
    "section": "",
    "text": "Couple Ribasim and MODFLOW 6.\n\n\n\nRibaMod\nCouple Ribasim and MODFLOW 6.\n\n\nRibaModActiveDriverCoupling\n\n\n\nRibaModPassiveDriverCoupling",
    "crumbs": [
      "iMOD Coupler",
      "Primod API Reference"
    ]
  },
  {
    "objectID": "primod_api/index.html#ribametamod",
    "href": "primod_api/index.html#ribametamod",
    "title": "Primod API Reference",
    "section": "",
    "text": "Couple Ribasim, MetaSWAP and MODFLOW 6.\n\n\n\nRibaMetaMod\nCouple Ribasim, MetaSWAP and MODFLOW 6.\n\n\nRibaMetaDriverCoupling\nA dataclass representing one coupling scenario for the RibaMod driver.\n\n\nRibaModActiveDriverCoupling\n\n\n\nRibaModPassiveDriverCoupling\n\n\n\nMetaModDriverCoupling",
    "crumbs": [
      "iMOD Coupler",
      "Primod API Reference"
    ]
  },
  {
    "objectID": "primod_api/MetaModDriverCoupling.html",
    "href": "primod_api/MetaModDriverCoupling.html",
    "title": "MetaModDriverCoupling",
    "section": "",
    "text": "MetaModDriverCoupling()\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nmf6_model\nstr\nThe model of the driver.\n\n\nmf6_recharge_package\nstr\nKey of Modflow 6 recharge package to which MetaSWAP is coupled.\n\n\nmf6_wel_package\nstr or None\nOptional key of Modflow 6 well package to which MetaSWAP sprinkling is coupled."
  },
  {
    "objectID": "primod_api/MetaModDriverCoupling.html#attributes",
    "href": "primod_api/MetaModDriverCoupling.html#attributes",
    "title": "MetaModDriverCoupling",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nmf6_model\nstr\nThe model of the driver.\n\n\nmf6_recharge_package\nstr\nKey of Modflow 6 recharge package to which MetaSWAP is coupled.\n\n\nmf6_wel_package\nstr or None\nOptional key of Modflow 6 well package to which MetaSWAP sprinkling is coupled."
  },
  {
    "objectID": "primod_api/MetaMod.html",
    "href": "primod_api/MetaMod.html",
    "title": "MetaMod",
    "section": "",
    "text": "MetaMod(self, msw_model, mf6_simulation, coupling_list)\nCouple MetaSWAP and MODFLOW 6.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsw_model\nMetaSwapModel\nThe MetaSWAP model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nwrite\nWrite MetaSWAP and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nMetaMod.write(directory, modflow6_dll, metaswap_dll, metaswap_dll_dependency, modflow6_write_kwargs=None)\nWrite MetaSWAP and Modflow 6 model with exchange files, as well as a .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nMetaMod.write_toml(directory, modflow6_dll, metaswap_dll, metaswap_dll_dependency, coupling_dict)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\ncoupling_dict\ndict[str, Any]\nDictionary with names of coupler packages and paths to mappings.\nrequired"
  },
  {
    "objectID": "primod_api/MetaMod.html#parameters",
    "href": "primod_api/MetaMod.html#parameters",
    "title": "MetaMod",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmsw_model\nMetaSwapModel\nThe MetaSWAP model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired"
  },
  {
    "objectID": "primod_api/MetaMod.html#methods",
    "href": "primod_api/MetaMod.html#methods",
    "title": "MetaMod",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nwrite\nWrite MetaSWAP and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nMetaMod.write(directory, modflow6_dll, metaswap_dll, metaswap_dll_dependency, modflow6_write_kwargs=None)\nWrite MetaSWAP and Modflow 6 model with exchange files, as well as a .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nMetaMod.write_toml(directory, modflow6_dll, metaswap_dll, metaswap_dll_dependency, coupling_dict)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\ncoupling_dict\ndict[str, Any]\nDictionary with names of coupler packages and paths to mappings.\nrequired"
  },
  {
    "objectID": "primod_api/RibaMetaDriverCoupling.html",
    "href": "primod_api/RibaMetaDriverCoupling.html",
    "title": "RibaMetaDriverCoupling",
    "section": "",
    "text": "RibaMetaDriverCoupling()\nA dataclass representing one coupling scenario for the RibaMod driver.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbasin_definition\ngpd.GeoDataFrame\nGeoDataFrame of basin polygons\n\n\nuser_demand_definition\ngpd.GeoDataFrame\nGeoDataFrame of user demand polygons"
  },
  {
    "objectID": "primod_api/RibaMetaDriverCoupling.html#attributes",
    "href": "primod_api/RibaMetaDriverCoupling.html#attributes",
    "title": "RibaMetaDriverCoupling",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nbasin_definition\ngpd.GeoDataFrame\nGeoDataFrame of basin polygons\n\n\nuser_demand_definition\ngpd.GeoDataFrame\nGeoDataFrame of user demand polygons"
  },
  {
    "objectID": "deltaforge_install.html",
    "href": "deltaforge_install.html",
    "title": "Install iMOD Python with Deltaforge",
    "section": "",
    "text": "Deltaforge is a python distribution which includes iMOD Python and all its dependencies. It is provided as an installer and makes installing iMOD Python easy. You can download the Deltaforge installer on the Deltares download portal.",
    "crumbs": [
      "iMOD Python",
      "Install iMOD Python with Deltaforge"
    ]
  },
  {
    "objectID": "deltaforge_install.html#what-is-deltaforge",
    "href": "deltaforge_install.html#what-is-deltaforge",
    "title": "Install iMOD Python with Deltaforge",
    "section": "",
    "text": "Deltaforge is a python distribution which includes iMOD Python and all its dependencies. It is provided as an installer and makes installing iMOD Python easy. You can download the Deltaforge installer on the Deltares download portal.",
    "crumbs": [
      "iMOD Python",
      "Install iMOD Python with Deltaforge"
    ]
  },
  {
    "objectID": "deltaforge_install.html#installation",
    "href": "deltaforge_install.html#installation",
    "title": "Install iMOD Python with Deltaforge",
    "section": "Installation",
    "text": "Installation\nTo install Deltaforge, double-click the executable, this will open the installation Wizard. You will be greeted with the welcome screen.\n\n\n\nThe welcome screen\n\n\nClick \"Next\", and then \"I agree\" in the license agreement.\n\n\n\nLicense agreement screen\n\n\nNext, you get to decide what type of installation you want. On your local machine it suffices to select Just me. If you are an admin of a server and you want to let others enjoy the Deltaforge installation as well, click All Users.\n\n\n\nThe installation type screen\n\n\nNext you get to decide where the python environment is installed. The default location is usually fine.\n\n\n\nThe location of the python installation\n\n\nFinally, some further configuration is possible. The screenshots contains the options we recommend.\n\n\n\nInstallation options with the recommended options selected.",
    "crumbs": [
      "iMOD Python",
      "Install iMOD Python with Deltaforge"
    ]
  },
  {
    "objectID": "deltaforge_install.html#using-deltaforge",
    "href": "deltaforge_install.html#using-deltaforge",
    "title": "Install iMOD Python with Deltaforge",
    "section": "Using Deltaforge",
    "text": "Using Deltaforge\nThe easiest way to start your environment is by pressing the Windows Key and start typing deltaforge. This will let you select the Deltaforge Prompt. Select this.\n\n\n\nThe Deltaforge Prompt should be findable in the Windows start menu\n\n\nThis will start a command prompt screen (cmd.exe), where at startup the Deltaforge python environment is activated.\n\n\n\nThe Deltaforge prompt. You can type mamba list to view all the packages installed.\n\n\nTo view all the packages installed in the environment you can type mamba list and press Enter. This will list all packages installed in the environment. If you want to start coding, you can type spyder, which will start Spyder, a Python scientific development environment.",
    "crumbs": [
      "iMOD Python",
      "Install iMOD Python with Deltaforge"
    ]
  },
  {
    "objectID": "practical.html",
    "href": "practical.html",
    "title": " Practical Tips",
    "section": "",
    "text": "Listed here are practical tips how to use the iMOD Suite in combination with other tools for very performant workflows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Consistent folder structures with Cookiecutter\n\n\nKickstart your projects with Cookiecutter\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Version control your projects\n\n\nUse Git and DVC to version control your model workflows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Snakemake Tips \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Handling messy data\n\n\nSome tips in dealing with messy data, or – God forbid – to avoid producing it yourself.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Parallel MODFLOW\n\n\nFix common issues when running iMODFLOW & iMOD-WQ codes with MPI.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Powershell profile error\n\n\nLearn how to fix the Powershell profile error which can hamper using Visual Studio Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n How to look like a pro\n\n\nSome general tips and tricks to make your editors and terminals look cool.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "viewer_known_issues.html",
    "href": "viewer_known_issues.html",
    "title": "Known Issues",
    "section": "",
    "text": "Known issues with the iMOD Viewer are listed over here.",
    "crumbs": [
      "iMOD Viewer",
      "Known Issues"
    ]
  },
  {
    "objectID": "viewer_known_issues.html#introduction",
    "href": "viewer_known_issues.html#introduction",
    "title": "Known Issues",
    "section": "",
    "text": "Known issues with the iMOD Viewer are listed over here.",
    "crumbs": [
      "iMOD Viewer",
      "Known Issues"
    ]
  },
  {
    "objectID": "viewer_known_issues.html#qgis-plugin",
    "href": "viewer_known_issues.html#qgis-plugin",
    "title": "Known Issues",
    "section": "QGIS plugin",
    "text": "QGIS plugin\n\nPlot axis off\nIn the QGIS plugin, a weird offset in the plot axis can occur when you use a multiple monitor setup. Both the Time series widget as well as the Cross-section widget can suffer from this.\n\n\n\nNotice the y-axis being moved too high and the x-axis being scaled weirdly.\n\n\nSo far we haven't been able to fix it in the code, so you can fix this as a user by either:\n\nMoving your QGIS application to the main window of your monitor setup\nIn Windows, navigate to Settings &gt; Display then under Rearrange your displays select the monitor you want to view QGIS on, and finally tick the box Make this my main display\n\n\n\nIPF reader does not support all IPF files\nCurrently the IPF reader is not able to read every IPF file, as iMOD 5 supports quite a wide range of IPF files. For example, iMOD 5 supports both whitespace and comma separated files, whereas the QGIS plugin only supports comma separated IPF files. If the plugin is unable to read your IPF file, it is best to read the file with iMOD Python and consequently write it again. This can help, because the IPF reader in iMOD Python is a lot more flexible, but its writer always writes to a specific format. We plan to improve the flexibility of the plugin's IPF reader.",
    "crumbs": [
      "iMOD Viewer",
      "Known Issues"
    ]
  },
  {
    "objectID": "viewer_known_issues.html#d-viewer",
    "href": "viewer_known_issues.html#d-viewer",
    "title": "Known Issues",
    "section": "3D Viewer",
    "text": "3D Viewer\n\nSupported Windows versions\nAt present, only Windows 10 is supported. Windows 8.1 and Windows 11 currently are not supported, and it has been confirmed that the 3D viewer does not function properly with these Windows versions.\n\n\nMSVCR100.dll missing\nYou might get an error at startup of the 3D viewer, such as: \"The code execution cannot proceed because MSVCR100.dll was not found. Reinstalling the program may fix the problem\"\nThis usually happens on a clean machine, which has not yet installed the Microsoft Visual C++ 2010 redistributable. You can download it here\nMake sure to check if you have a 32-bit or 64-bit Windows version on your system and consequently installing the right version of the redistributable. You can find this out pressing the Windows key (or clicking Start) and typing System Information. Click it, and look under \"System Type\". If it says x64-based PC, you have a 64-bit system.",
    "crumbs": [
      "iMOD Viewer",
      "Known Issues"
    ]
  },
  {
    "objectID": "coupler_metamod_example.html",
    "href": "coupler_metamod_example.html",
    "title": "Example",
    "section": "",
    "text": "This example illustrates how to setup a simple MetaSWAP model coupled to a Modflow 6 model model using the imod package and associated packages.\nOverview of steps made:\n\nCreate Modflow 6 model\nCreate MetaSWAP model\nWrite coupled models\n\nWe’ll start with the following imports:\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\nimport primod\nimport imod\nfrom imod import mf6, msw\n\n\n\nNext, we initiate the Modflow 6 groundwater model:\n\ngwf_model = mf6.GroundwaterFlowModel()\n\n\n\nWe’ll then define the Modflow 6 grid. It consists of 3 layers of 9 by 9 cells rasters.\n\nshape = nlay, nrow, ncol = 3, 9, 9\n\ndx = 10.0\ndy = -10.0\ndz = np.array([1.0, 2.0, 10.0])\nxmin = 0.0\nxmax = dx * ncol\nymin = 0.0\nymax = abs(dy) * nrow\ndims = (\"layer\", \"y\", \"x\")\n\nlayer = np.arange(1, nlay + 1)\ny = np.arange(ymax, ymin, dy) + 0.5 * dy\nx = np.arange(xmin, xmax, dx) + 0.5 * dx\ncoords = {\"layer\": layer, \"y\": y, \"x\": x}\n\nidomain = xr.DataArray(np.ones(shape, dtype=int), coords=coords, dims=dims)\n\ntop = 0.0\nbottom = top - xr.DataArray(\n    np.cumsum(layer * dz), coords={\"layer\": layer}, dims=\"layer\"\n)\n\n\ngwf_model[\"dis\"] = mf6.StructuredDiscretization(idomain=idomain, top=top, bottom=bottom)\n\n\n\n\n\n\nAssign the node property flow package, which specifies the hydraulic conductivities. The middle layer is an aquitard.\n\nk = xr.DataArray([10.0, 0.1, 10.0], {\"layer\": layer}, (\"layer\",))\nk33 = xr.DataArray([1.0, 0.01, 1.0], {\"layer\": layer}, (\"layer\",))\ngwf_model[\"npf\"] = mf6.NodePropertyFlow(\n    icelltype=0,\n    k=k,\n    k33=k33,\n    save_flows=True,\n)\n\n\n\n\nCells are set to non-convertible (convertible = 0). This is a requirement for MetaSWAP, because, once coupled, MetaSWAP is responsible for computing the storage coefficient instead of Modflow.\n\ngwf_model[\"sto\"] = mf6.SpecificStorage(\n    specific_storage=1e-3, specific_yield=0.0, transient=True, convertible=0\n)\n\n\n\n\n\n\ngwf_model[\"ic\"] = mf6.InitialConditions(start=0.5)\n\n\n\n\n\ngwf_model[\"oc\"] = mf6.OutputControl(save_head=\"last\", save_budget=\"last\")\n\n\n\n\n\n\nWe’ll create constant head cells at the most left and right columns of the grid, representing two ditches.\n\nhead = xr.full_like(idomain, np.nan, dtype=float)\nhead[0, :, 0] = -1.0\nhead[0, :, -1] = -1.0\n\ngwf_model[\"chd\"] = mf6.ConstantHead(\n    head, print_input=True, print_flows=True, save_flows=True\n)\n\nhead.isel(layer=0).plot()\n\n\n\n\n\n\n\n\n\n\n\nThe iMOD Coupler requires a dummy recharge package, and well package if MetaSWAP’s sprinkling is enabled. This to let Modflow 6 allocate the appropriate matrices needed in the exchange of states during model computation.\n\n\nWe’ll start off with the recharge package, which has no recharge cells at the location of our ditches.\n\nrecharge = xr.zeros_like(idomain.sel(layer=1), dtype=float)\nrecharge[:, 0] = np.nan\nrecharge[:, -1] = np.nan\n\ngwf_model[\"rch_msw\"] = mf6.Recharge(recharge)\n\nrecharge.plot()\n\n\n\n\n\n\n\n\n\n\n\nWe’ll create a dummy well package as well. imod.mf6.WellDisStructured needs its input data provided as long tables instead of grids to so therefore we’ll create 1d arrays by calling np.tile on the column indices, and np.repeat on the row indices.\n\nwel_layer = 3\n\nix = np.tile(np.arange(ncol) + 1, nrow)\niy = np.repeat(np.arange(nrow) + 1, ncol)\nrate = np.zeros(ix.shape)\nlayer = np.full_like(ix, wel_layer)\n\ngwf_model[\"wells_msw\"] = mf6.WellDisStructured(\n    layer=layer, row=iy, column=ix, rate=rate\n)\n\nInitiate a Modflow 6 simulation and attach the groundwater model to it.\n\nsimulation = mf6.Modflow6Simulation(\"test\")\nsimulation[\"GWF_1\"] = gwf_model\n\n# Define solver settings, we'll use a preset that is sufficient for this example.\n\nsimulation[\"solver\"] = mf6.SolutionPresetSimple(modelnames=[\"GWF_1\"])\n\nCreate time discretization, we’ll model 2 days.\n\nfreq = \"D\"\ntimes = pd.date_range(start=\"1/1/1971\", end=\"1/3/1971\", freq=freq)\n\nsimulation.create_time_discretization(additional_times=times)\n\ntimes\n\nDatetimeIndex(['1971-01-01', '1971-01-02', '1971-01-03'], dtype='datetime64[ns]', freq='D')\n\n\n\n\n\n\n\n\nThe next step is initiating a MetaSwapModel. Critical is setting the right path to MetaSWAP’s soil physical database, which contains the lookup table with the soil physical relationships. Without access to this database MetaSWAP cannot function. The full database can be downloaded here.\n\nmsw_model = msw.MetaSwapModel(unsaturated_database=\"./path/to/unsaturated/database\")\n\n# Create grid\n# ```````````\n#\n# We'll start off specifying the grids required for MetaSWAP. The x,y values\n# of this grid should be identical as the Modflow6 model, but it should\n# not have a layer dimension.\n\nmsw_grid = idomain.sel(layer=1, drop=True).astype(float)\n\nWe do not want MetaSWAP cells in the cells where the ditches are located in Modflow 6. We can specify where MetaSWAP cells are active with the “active” grid, which is a grid of booleans (i.e. True/False).\n\nactive = msw_grid.astype(bool)\nactive[..., 0] = False\nactive[..., -1] = False\n\nactive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 9, x: 9)&gt; Size: 81B\narray([[False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False]])\nCoordinates:\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArrayy: 9x: 9False True True True True True True ... True True True True True Falsearray([[False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False]])Coordinates: (2)y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (2)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))Attributes: (0)\n\n\nAnother crucial grid is the “area” grid. The area grid denotes the area in each cell, for each “subunit”. A subunit represent a separate landuse in the grid. We’ll create a grid with two separate land uses.\nEach grid which specifies parameters related to landuse (e.g. landuse, rootzone_depth, ponding depth) requires a subunit dimension. In contrast, grids specifying parameters not induced by landuse (e.g. soil type, elevation, precipitation) cannot contain a subunit dimension.\n\nsubunit = [0, 1]\n\ntotal_cell_area = abs(dx * dy)\nequal_area_per_subunit = total_cell_area / len(subunit)\n\ntotal_cell_area\n\n# Create a full grid equal to the msw_grid. And expand_dims() to broadcast this\n# grid along a new dimension, named \"subunit\"\narea = (\n    xr.full_like(msw_grid, equal_area_per_subunit, dtype=float)\n    .expand_dims(subunit=subunit)\n    .copy()  # expand_dims creates a view, so copy it to allow setting values.\n)\n\n# To the left we only have subunit 0\narea[0, :, :3] = total_cell_area\narea[1, :, :3] = np.nan\n\n# To the right we only have subunit 1\narea[0, :, -3:] = np.nan\narea[1, :, -3:] = total_cell_area\n\narea\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (subunit: 2, y: 9, x: 9)&gt; Size: 1kB\narray([[[100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan]],\n\n       [[ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.]]])\nCoordinates:\n  * subunit  (subunit) int64 16B 0 1\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArraysubunit: 2y: 9x: 9100.0 100.0 100.0 50.0 50.0 50.0 ... 50.0 50.0 50.0 100.0 100.0 100.0array([[[100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan]],\n\n       [[ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.]]])Coordinates: (3)subunit(subunit)int640 1array([0, 1])y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (3)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))subunitPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='subunit'))Attributes: (0)\n\n\n\n\nDefine a grid with landuse classes.\n\nlanduse = xr.full_like(area, 1, dtype=np.int16)\nlanduse[1, :, :] = 2\n\nlanduse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (subunit: 2, y: 9, x: 9)&gt; Size: 324B\narray([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2]]], dtype=int16)\nCoordinates:\n  * subunit  (subunit) int64 16B 0 1\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArraysubunit: 2y: 9x: 91 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2]]], dtype=int16)Coordinates: (3)subunit(subunit)int640 1array([0, 1])y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (3)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))subunitPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='subunit'))Attributes: (0)\n\n\n\n\n\nDefine soil type classes. These will be looked up in MetaSWAP’s giant lookup table for the national Staring series describing Dutch soils. The full database can be downloaded here. &lt;https://download.deltares.nl/metaswap&gt; In previous examples we set values in our DataArray using numpy indexing. But we can also use xarray’s where() method to set values.\n\nslt = xr.full_like(msw_grid, 1, dtype=np.int16)\n# Set all cells on the right half to 2.\nslt = slt.where((slt.x &lt; (xmax / 2)), 2)\n\nslt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 9, x: 9)&gt; Size: 162B\narray([[1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2]], dtype=int16)\nCoordinates:\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArrayy: 9x: 91 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 ... 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 2array([[1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2]], dtype=int16)Coordinates: (2)y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (2)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))Attributes: (0)\n\n\n\n\n\nTo finish specifying the landuse grid data, we’ll require a rootzone depth for each subunit, and a grid with surface elevations\n\nrootzone_depth = xr.full_like(area, 0.5)\nsurface_elevation = xr.full_like(msw_grid, 2.0)\n\nmsw_model[\"grid\"] = msw.GridData(\n    area=area,\n    landuse=landuse,\n    rootzone_depth=rootzone_depth,\n    surface_elevation=surface_elevation,\n    soil_physical_unit=slt,\n    active=active,\n)\n\n\n\n\nThere are four options to specify initial conditions, see this for page for an explanation —link-here—. In this case we opt for an initial pF value of 2.2.\n\nmsw_model[\"ic\"] = msw.InitialConditionsRootzonePressureHead(initial_pF=2.2)\n\n\n\n\nMeteorological information should be provided as grids with a time dimension.\n\nprecipitation = msw_grid.expand_dims(time=times[:-1])\nevapotranspiration = precipitation * 1.5\n\nmsw_model[\"meteo_grid\"] = msw.MeteoGrid(precipitation, evapotranspiration)\nmsw_model[\"mapping_prec\"] = msw.PrecipitationMapping(precipitation)\nmsw_model[\"mapping_evt\"] = msw.EvapotranspirationMapping(evapotranspiration)\n\n\n\n\n\nmsw_model[\"ponding\"] = msw.Ponding(\n    ponding_depth=xr.full_like(area, 0.0),\n    runon_resistance=xr.full_like(area, 1.0),\n    runoff_resistance=xr.full_like(area, 1.0),\n)\n\n\n\n\nScaling factors can be defined to adapt some parameters in the soil physical database. With this you can investigate the sensitivity of parameters in soil physical database. Furthermore, with this package you can specify the depth of the perched water table.\n\nmsw_model[\"scaling\"] = msw.ScalingFactors(\n    scale_soil_moisture=xr.full_like(area, 1.0),\n    scale_hydraulic_conductivity=xr.full_like(area, 1.0),\n    scale_pressure_head=xr.full_like(area, 1.0),\n    depth_perched_water_table=xr.full_like(msw_grid, 1.0),\n)\n\n\n\n\nSet the infiltration parameters. We set the resistances to -9999.0, which makes MetaSWAP ignore them.\n\nmsw_model[\"infiltration\"] = msw.Infiltration(\n    infiltration_capacity=xr.full_like(area, 1.0),\n    downward_resistance=xr.full_like(msw_grid, -9999.0),\n    upward_resistance=xr.full_like(msw_grid, -9999.0),\n    bottom_resistance=xr.full_like(msw_grid, -9999.0),\n    extra_storage_coefficient=xr.full_like(msw_grid, 0.1),\n)\n\n\n\n\nThe landuse option class constructs a lookup table which is used to map landuse indices to a set of parameters. In this example, 3 stands for potatoes. This means that for every cell in the landuse grid with a 3, the parameters for a crop with vegetation_index == 3 are associate, which in this case are potatoes.\n\nvegetation_index = [1, 2, 3]\nnames = [\"grassland\", \"maize\", \"potatoes\"]\n\nlanduse_index = [1, 2, 3]\ncoords = {\"landuse_index\": landuse_index}\n\nlanduse_names = xr.DataArray(data=names, coords=coords, dims=(\"landuse_index\",))\nvegetation_index_da = xr.DataArray(\n    data=vegetation_index, coords=coords, dims=(\"landuse_index\",)\n)\n\nBecause there are a lot of parameters to define, we’ll create a DataArray of ones (lu) to more easily broadcast all the different parameters.\n\nlu = xr.ones_like(vegetation_index_da, dtype=float)\n\nmsw_model[\"landuse_options\"] = msw.LanduseOptions(\n    landuse_name=landuse_names,\n    vegetation_index=vegetation_index_da,\n    jarvis_o2_stress=xr.ones_like(lu),\n    jarvis_drought_stress=xr.ones_like(lu),\n    feddes_p1=xr.full_like(lu, 99.0),\n    feddes_p2=xr.full_like(lu, 99.0),\n    feddes_p3h=lu * [-2.0, -4.0, -3.0],\n    feddes_p3l=lu * [-8.0, -5.0, -5.0],\n    feddes_p4=lu * [-80.0, -100.0, -100.0],\n    feddes_t3h=xr.full_like(lu, 5.0),\n    feddes_t3l=xr.full_like(lu, 1.0),\n    threshold_sprinkling=lu * [-8.0, -5.0, -5.0],\n    fraction_evaporated_sprinkling=xr.full_like(lu, 0.05),\n    gift=xr.full_like(lu, 20.0),\n    gift_duration=xr.full_like(lu, 0.25),\n    rotational_period=lu * [10, 7, 7],\n    start_sprinkling_season=lu * [120, 180, 150],\n    end_sprinkling_season=lu * [230, 230, 240],\n    interception_option=xr.ones_like(lu, dtype=int),\n    interception_capacity_per_LAI=xr.zeros_like(lu),\n    interception_intercept=xr.ones_like(lu),\n)\n\n\n\n\nCrop growth tables are specified as a two-dimensional array, with the day of year as one dimension, and the vegetation index on the other. In the vegetation factors, we’ll show how to bring some distinction between different crops.\nWe’ll start off specifying the coordinates:\n\nday_of_year = np.arange(1, 367)\nvegetation_index = np.arange(1, 4)\n\ncoords = {\"day_of_year\": day_of_year, \"vegetation_index\": vegetation_index}\n\nWe can use the coordinates to specify the soil cover of each plant. We’ll start with a grid of zeros\n\nsoil_cover = xr.DataArray(\n    data=np.zeros(day_of_year.shape + vegetation_index.shape),\n    coords=coords,\n    dims=(\"day_of_year\", \"vegetation_index\"),\n)\n\nThe simplest soil cover specification is a step function. In this case soil cover equals 1.0 for days 133 to 255 (mind Python’s 0-based index here), and for the rest of the days it equals zero.\n\nsoil_cover[132:254, :] = 1.0\n\nsoil_cover.sel(vegetation_index=1).plot()\n\n\n\n\n\n\n\n\nWe’ll simply triple the soil cover to get a leaf area index\n\nleaf_area_index = soil_cover * 3\n\nVegetation factors are used to convert the Makkink reference evapotranspiration to a potential evapotranspiration for a certain vegetation type. We’ll specify some simple crop schemes for the three crops as vegetation factors. Mind that the vegetation factor array has two dimensions: day_of_year and vegetation_index\n\nvegetation_names = [\"grass\", \"maize\", \"potatoes\"]\n\nvegetation_factor = xr.zeros_like(soil_cover)\n\nvegetation_factor[120:132, :] = [1.0, 0.5, 0.0]\nvegetation_factor[132:142, :] = [1.0, 0.7, 0.7]\nvegetation_factor[142:152, :] = [1.0, 0.8, 0.9]\nvegetation_factor[152:162, :] = [1.0, 0.9, 1.0]\nvegetation_factor[162:172, :] = [1.0, 1.0, 1.2]\nvegetation_factor[172:182, :] = [1.0, 1.2, 1.2]\nvegetation_factor[182:192, :] = [1.0, 1.3, 1.2]\nvegetation_factor[192:244, :] = [1.0, 1.2, 1.1]\nvegetation_factor[244:254, :] = [1.0, 1.2, 0.7]\nvegetation_factor[254:283, :] = [1.0, 1.2, 0.0]\n\n# Since grass is the reference crop, force all grass to 1.0\nvegetation_factor[:, 0] = 1.0\n\n\n# Assign vegetation names for the plot\nvegetation_factor.assign_coords(\n    vegetation_names=(\"vegetation_index\", vegetation_names)\n).plot.line(x=\"day_of_year\", hue=\"vegetation_names\")\n\n\n\n\n\n\n\n\nWe’ll leave the interception capacity at zero, and the other factors at one, and assign these to the AnnualCropFactors package.\n\nmsw_model[\"crop_factors\"] = msw.AnnualCropFactors(\n    soil_cover=soil_cover,\n    leaf_area_index=leaf_area_index,\n    interception_capacity=xr.zeros_like(soil_cover),\n    vegetation_factor=vegetation_factor,\n    interception_factor=xr.ones_like(soil_cover),\n    bare_soil_factor=xr.ones_like(soil_cover),\n    ponding_factor=xr.ones_like(soil_cover),\n)\n\n\n\n\n\nmsw_model[\"oc_idf\"] = msw.IdfMapping(area, -9999.0)\nmsw_model[\"oc_var\"] = msw.VariableOutputControl()\nmsw_model[\"oc_time\"] = msw.TimeOutputControl(time=times)\n\n\n\n\nMetaSWAP requires its own mapping of SVAT to MODFLOW cells, for internal use. We therefore provide the mf6.StructuredDiscretization and mf6.Well package to mf6.CouplerMapping.\n\nmsw_model[\"mod2svat\"] = msw.CouplerMapping(\n    modflow_dis=gwf_model[\"dis\"], well=gwf_model[\"wells_msw\"]\n)\n\nThe sprinkling package also requires the Modflow6 wells.\n\nmsw_model[\"sprinkling\"] = msw.Sprinkling(\n    max_abstraction_groundwater=xr.full_like(msw_grid, 100.0),\n    max_abstraction_surfacewater=xr.full_like(msw_grid, 100.0),\n    well=gwf_model[\"wells_msw\"],\n)\n\n\n\n\n\nThe MetaSWAP model and Modflow 6 simulation are provided to the MetaMod class, which takes care of connecting (= “mapping”) the two models. Make sure to provide the keys of the dummy Modflow 6 boundary conditions where MetaSWAP is coupled to, so iMOD Python knows where to look: It is technically possible to define multiple WEL and RCH packages in Modflow 6.\n\ndriver_coupling = primod.MetaModDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_recharge_package=\"rch_msw\",\n    mf6_wel_package=\"wells_msw\",\n)\n\nmetamod = primod.MetaMod(\n    msw_model=msw_model,\n    mf6_simulation=simulation,\n    coupling_list=[driver_coupling],\n)\n\nWe can write the coupled models by providing the following necessary paths to iMOD Coupler:\n\nmodflow 6 library\nmetaswap library\ndirectory with dependent libraries for metaswap\n\nYou can download the modflow and metaswap libraries (.dll’s) as part of the the last iMOD Coupler release for Windows for free. Please contact imod.support@deltares.nl if you require the libraries for Linux.\n\nmetamod_dir = imod.util.temporary_directory()\nmf6_dll = \"./path/to/mf6.dll\"\nmetaswap_dll = \"./path/to/metaswap.dll\"\nmetaswap_dll_dependency_dir = \"./path/to/metaswap/dll/dependency/directory\"\n\nmetamod.write(metamod_dir, mf6_dll, metaswap_dll, metaswap_dll_dependency_dir)\n\n\n\n\nIn order to run the models, make sure you install imod_coupler. You can find the installation instructions here.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Example"
    ]
  },
  {
    "objectID": "coupler_metamod_example.html#modflow-6-model",
    "href": "coupler_metamod_example.html#modflow-6-model",
    "title": "Example",
    "section": "",
    "text": "Next, we initiate the Modflow 6 groundwater model:\n\ngwf_model = mf6.GroundwaterFlowModel()\n\n\n\nWe’ll then define the Modflow 6 grid. It consists of 3 layers of 9 by 9 cells rasters.\n\nshape = nlay, nrow, ncol = 3, 9, 9\n\ndx = 10.0\ndy = -10.0\ndz = np.array([1.0, 2.0, 10.0])\nxmin = 0.0\nxmax = dx * ncol\nymin = 0.0\nymax = abs(dy) * nrow\ndims = (\"layer\", \"y\", \"x\")\n\nlayer = np.arange(1, nlay + 1)\ny = np.arange(ymax, ymin, dy) + 0.5 * dy\nx = np.arange(xmin, xmax, dx) + 0.5 * dx\ncoords = {\"layer\": layer, \"y\": y, \"x\": x}\n\nidomain = xr.DataArray(np.ones(shape, dtype=int), coords=coords, dims=dims)\n\ntop = 0.0\nbottom = top - xr.DataArray(\n    np.cumsum(layer * dz), coords={\"layer\": layer}, dims=\"layer\"\n)\n\n\ngwf_model[\"dis\"] = mf6.StructuredDiscretization(idomain=idomain, top=top, bottom=bottom)\n\n\n\n\n\n\nAssign the node property flow package, which specifies the hydraulic conductivities. The middle layer is an aquitard.\n\nk = xr.DataArray([10.0, 0.1, 10.0], {\"layer\": layer}, (\"layer\",))\nk33 = xr.DataArray([1.0, 0.01, 1.0], {\"layer\": layer}, (\"layer\",))\ngwf_model[\"npf\"] = mf6.NodePropertyFlow(\n    icelltype=0,\n    k=k,\n    k33=k33,\n    save_flows=True,\n)\n\n\n\n\nCells are set to non-convertible (convertible = 0). This is a requirement for MetaSWAP, because, once coupled, MetaSWAP is responsible for computing the storage coefficient instead of Modflow.\n\ngwf_model[\"sto\"] = mf6.SpecificStorage(\n    specific_storage=1e-3, specific_yield=0.0, transient=True, convertible=0\n)\n\n\n\n\n\n\ngwf_model[\"ic\"] = mf6.InitialConditions(start=0.5)\n\n\n\n\n\ngwf_model[\"oc\"] = mf6.OutputControl(save_head=\"last\", save_budget=\"last\")\n\n\n\n\n\n\nWe’ll create constant head cells at the most left and right columns of the grid, representing two ditches.\n\nhead = xr.full_like(idomain, np.nan, dtype=float)\nhead[0, :, 0] = -1.0\nhead[0, :, -1] = -1.0\n\ngwf_model[\"chd\"] = mf6.ConstantHead(\n    head, print_input=True, print_flows=True, save_flows=True\n)\n\nhead.isel(layer=0).plot()\n\n\n\n\n\n\n\n\n\n\n\nThe iMOD Coupler requires a dummy recharge package, and well package if MetaSWAP’s sprinkling is enabled. This to let Modflow 6 allocate the appropriate matrices needed in the exchange of states during model computation.\n\n\nWe’ll start off with the recharge package, which has no recharge cells at the location of our ditches.\n\nrecharge = xr.zeros_like(idomain.sel(layer=1), dtype=float)\nrecharge[:, 0] = np.nan\nrecharge[:, -1] = np.nan\n\ngwf_model[\"rch_msw\"] = mf6.Recharge(recharge)\n\nrecharge.plot()\n\n\n\n\n\n\n\n\n\n\n\nWe’ll create a dummy well package as well. imod.mf6.WellDisStructured needs its input data provided as long tables instead of grids to so therefore we’ll create 1d arrays by calling np.tile on the column indices, and np.repeat on the row indices.\n\nwel_layer = 3\n\nix = np.tile(np.arange(ncol) + 1, nrow)\niy = np.repeat(np.arange(nrow) + 1, ncol)\nrate = np.zeros(ix.shape)\nlayer = np.full_like(ix, wel_layer)\n\ngwf_model[\"wells_msw\"] = mf6.WellDisStructured(\n    layer=layer, row=iy, column=ix, rate=rate\n)\n\nInitiate a Modflow 6 simulation and attach the groundwater model to it.\n\nsimulation = mf6.Modflow6Simulation(\"test\")\nsimulation[\"GWF_1\"] = gwf_model\n\n# Define solver settings, we'll use a preset that is sufficient for this example.\n\nsimulation[\"solver\"] = mf6.SolutionPresetSimple(modelnames=[\"GWF_1\"])\n\nCreate time discretization, we’ll model 2 days.\n\nfreq = \"D\"\ntimes = pd.date_range(start=\"1/1/1971\", end=\"1/3/1971\", freq=freq)\n\nsimulation.create_time_discretization(additional_times=times)\n\ntimes\n\nDatetimeIndex(['1971-01-01', '1971-01-02', '1971-01-03'], dtype='datetime64[ns]', freq='D')",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Example"
    ]
  },
  {
    "objectID": "coupler_metamod_example.html#metaswap-model",
    "href": "coupler_metamod_example.html#metaswap-model",
    "title": "Example",
    "section": "",
    "text": "The next step is initiating a MetaSwapModel. Critical is setting the right path to MetaSWAP’s soil physical database, which contains the lookup table with the soil physical relationships. Without access to this database MetaSWAP cannot function. The full database can be downloaded here.\n\nmsw_model = msw.MetaSwapModel(unsaturated_database=\"./path/to/unsaturated/database\")\n\n# Create grid\n# ```````````\n#\n# We'll start off specifying the grids required for MetaSWAP. The x,y values\n# of this grid should be identical as the Modflow6 model, but it should\n# not have a layer dimension.\n\nmsw_grid = idomain.sel(layer=1, drop=True).astype(float)\n\nWe do not want MetaSWAP cells in the cells where the ditches are located in Modflow 6. We can specify where MetaSWAP cells are active with the “active” grid, which is a grid of booleans (i.e. True/False).\n\nactive = msw_grid.astype(bool)\nactive[..., 0] = False\nactive[..., -1] = False\n\nactive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 9, x: 9)&gt; Size: 81B\narray([[False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False]])\nCoordinates:\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArrayy: 9x: 9False True True True True True True ... True True True True True Falsearray([[False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False],\n       [False,  True,  True,  True,  True,  True,  True,  True, False]])Coordinates: (2)y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (2)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))Attributes: (0)\n\n\nAnother crucial grid is the “area” grid. The area grid denotes the area in each cell, for each “subunit”. A subunit represent a separate landuse in the grid. We’ll create a grid with two separate land uses.\nEach grid which specifies parameters related to landuse (e.g. landuse, rootzone_depth, ponding depth) requires a subunit dimension. In contrast, grids specifying parameters not induced by landuse (e.g. soil type, elevation, precipitation) cannot contain a subunit dimension.\n\nsubunit = [0, 1]\n\ntotal_cell_area = abs(dx * dy)\nequal_area_per_subunit = total_cell_area / len(subunit)\n\ntotal_cell_area\n\n# Create a full grid equal to the msw_grid. And expand_dims() to broadcast this\n# grid along a new dimension, named \"subunit\"\narea = (\n    xr.full_like(msw_grid, equal_area_per_subunit, dtype=float)\n    .expand_dims(subunit=subunit)\n    .copy()  # expand_dims creates a view, so copy it to allow setting values.\n)\n\n# To the left we only have subunit 0\narea[0, :, :3] = total_cell_area\narea[1, :, :3] = np.nan\n\n# To the right we only have subunit 1\narea[0, :, -3:] = np.nan\narea[1, :, -3:] = total_cell_area\n\narea\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (subunit: 2, y: 9, x: 9)&gt; Size: 1kB\narray([[[100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan]],\n\n       [[ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.]]])\nCoordinates:\n  * subunit  (subunit) int64 16B 0 1\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArraysubunit: 2y: 9x: 9100.0 100.0 100.0 50.0 50.0 50.0 ... 50.0 50.0 50.0 100.0 100.0 100.0array([[[100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan],\n        [100., 100., 100.,  50.,  50.,  50.,  nan,  nan,  nan]],\n\n       [[ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.],\n        [ nan,  nan,  nan,  50.,  50.,  50., 100., 100., 100.]]])Coordinates: (3)subunit(subunit)int640 1array([0, 1])y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (3)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))subunitPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='subunit'))Attributes: (0)\n\n\n\n\nDefine a grid with landuse classes.\n\nlanduse = xr.full_like(area, 1, dtype=np.int16)\nlanduse[1, :, :] = 2\n\nlanduse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (subunit: 2, y: 9, x: 9)&gt; Size: 324B\narray([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2]]], dtype=int16)\nCoordinates:\n  * subunit  (subunit) int64 16B 0 1\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArraysubunit: 2y: 9x: 91 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ... 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2array([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n       [[2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2]]], dtype=int16)Coordinates: (3)subunit(subunit)int640 1array([0, 1])y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (3)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))subunitPandasIndexPandasIndex(Index([0, 1], dtype='int64', name='subunit'))Attributes: (0)\n\n\n\n\n\nDefine soil type classes. These will be looked up in MetaSWAP’s giant lookup table for the national Staring series describing Dutch soils. The full database can be downloaded here. &lt;https://download.deltares.nl/metaswap&gt; In previous examples we set values in our DataArray using numpy indexing. But we can also use xarray’s where() method to set values.\n\nslt = xr.full_like(msw_grid, 1, dtype=np.int16)\n# Set all cells on the right half to 2.\nslt = slt.where((slt.x &lt; (xmax / 2)), 2)\n\nslt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 9, x: 9)&gt; Size: 162B\narray([[1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2]], dtype=int16)\nCoordinates:\n  * y        (y) float64 72B 85.0 75.0 65.0 55.0 45.0 35.0 25.0 15.0 5.0\n  * x        (x) float64 72B 5.0 15.0 25.0 35.0 45.0 55.0 65.0 75.0 85.0xarray.DataArrayy: 9x: 91 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 ... 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 2array([[1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2],\n       [1, 1, 1, 1, 2, 2, 2, 2, 2]], dtype=int16)Coordinates: (2)y(y)float6485.0 75.0 65.0 ... 25.0 15.0 5.0array([85., 75., 65., 55., 45., 35., 25., 15.,  5.])x(x)float645.0 15.0 25.0 ... 65.0 75.0 85.0array([ 5., 15., 25., 35., 45., 55., 65., 75., 85.])Indexes: (2)yPandasIndexPandasIndex(Index([85.0, 75.0, 65.0, 55.0, 45.0, 35.0, 25.0, 15.0, 5.0], dtype='float64', name='y'))xPandasIndexPandasIndex(Index([5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0], dtype='float64', name='x'))Attributes: (0)\n\n\n\n\n\nTo finish specifying the landuse grid data, we’ll require a rootzone depth for each subunit, and a grid with surface elevations\n\nrootzone_depth = xr.full_like(area, 0.5)\nsurface_elevation = xr.full_like(msw_grid, 2.0)\n\nmsw_model[\"grid\"] = msw.GridData(\n    area=area,\n    landuse=landuse,\n    rootzone_depth=rootzone_depth,\n    surface_elevation=surface_elevation,\n    soil_physical_unit=slt,\n    active=active,\n)\n\n\n\n\nThere are four options to specify initial conditions, see this for page for an explanation —link-here—. In this case we opt for an initial pF value of 2.2.\n\nmsw_model[\"ic\"] = msw.InitialConditionsRootzonePressureHead(initial_pF=2.2)\n\n\n\n\nMeteorological information should be provided as grids with a time dimension.\n\nprecipitation = msw_grid.expand_dims(time=times[:-1])\nevapotranspiration = precipitation * 1.5\n\nmsw_model[\"meteo_grid\"] = msw.MeteoGrid(precipitation, evapotranspiration)\nmsw_model[\"mapping_prec\"] = msw.PrecipitationMapping(precipitation)\nmsw_model[\"mapping_evt\"] = msw.EvapotranspirationMapping(evapotranspiration)\n\n\n\n\n\nmsw_model[\"ponding\"] = msw.Ponding(\n    ponding_depth=xr.full_like(area, 0.0),\n    runon_resistance=xr.full_like(area, 1.0),\n    runoff_resistance=xr.full_like(area, 1.0),\n)\n\n\n\n\nScaling factors can be defined to adapt some parameters in the soil physical database. With this you can investigate the sensitivity of parameters in soil physical database. Furthermore, with this package you can specify the depth of the perched water table.\n\nmsw_model[\"scaling\"] = msw.ScalingFactors(\n    scale_soil_moisture=xr.full_like(area, 1.0),\n    scale_hydraulic_conductivity=xr.full_like(area, 1.0),\n    scale_pressure_head=xr.full_like(area, 1.0),\n    depth_perched_water_table=xr.full_like(msw_grid, 1.0),\n)\n\n\n\n\nSet the infiltration parameters. We set the resistances to -9999.0, which makes MetaSWAP ignore them.\n\nmsw_model[\"infiltration\"] = msw.Infiltration(\n    infiltration_capacity=xr.full_like(area, 1.0),\n    downward_resistance=xr.full_like(msw_grid, -9999.0),\n    upward_resistance=xr.full_like(msw_grid, -9999.0),\n    bottom_resistance=xr.full_like(msw_grid, -9999.0),\n    extra_storage_coefficient=xr.full_like(msw_grid, 0.1),\n)\n\n\n\n\nThe landuse option class constructs a lookup table which is used to map landuse indices to a set of parameters. In this example, 3 stands for potatoes. This means that for every cell in the landuse grid with a 3, the parameters for a crop with vegetation_index == 3 are associate, which in this case are potatoes.\n\nvegetation_index = [1, 2, 3]\nnames = [\"grassland\", \"maize\", \"potatoes\"]\n\nlanduse_index = [1, 2, 3]\ncoords = {\"landuse_index\": landuse_index}\n\nlanduse_names = xr.DataArray(data=names, coords=coords, dims=(\"landuse_index\",))\nvegetation_index_da = xr.DataArray(\n    data=vegetation_index, coords=coords, dims=(\"landuse_index\",)\n)\n\nBecause there are a lot of parameters to define, we’ll create a DataArray of ones (lu) to more easily broadcast all the different parameters.\n\nlu = xr.ones_like(vegetation_index_da, dtype=float)\n\nmsw_model[\"landuse_options\"] = msw.LanduseOptions(\n    landuse_name=landuse_names,\n    vegetation_index=vegetation_index_da,\n    jarvis_o2_stress=xr.ones_like(lu),\n    jarvis_drought_stress=xr.ones_like(lu),\n    feddes_p1=xr.full_like(lu, 99.0),\n    feddes_p2=xr.full_like(lu, 99.0),\n    feddes_p3h=lu * [-2.0, -4.0, -3.0],\n    feddes_p3l=lu * [-8.0, -5.0, -5.0],\n    feddes_p4=lu * [-80.0, -100.0, -100.0],\n    feddes_t3h=xr.full_like(lu, 5.0),\n    feddes_t3l=xr.full_like(lu, 1.0),\n    threshold_sprinkling=lu * [-8.0, -5.0, -5.0],\n    fraction_evaporated_sprinkling=xr.full_like(lu, 0.05),\n    gift=xr.full_like(lu, 20.0),\n    gift_duration=xr.full_like(lu, 0.25),\n    rotational_period=lu * [10, 7, 7],\n    start_sprinkling_season=lu * [120, 180, 150],\n    end_sprinkling_season=lu * [230, 230, 240],\n    interception_option=xr.ones_like(lu, dtype=int),\n    interception_capacity_per_LAI=xr.zeros_like(lu),\n    interception_intercept=xr.ones_like(lu),\n)\n\n\n\n\nCrop growth tables are specified as a two-dimensional array, with the day of year as one dimension, and the vegetation index on the other. In the vegetation factors, we’ll show how to bring some distinction between different crops.\nWe’ll start off specifying the coordinates:\n\nday_of_year = np.arange(1, 367)\nvegetation_index = np.arange(1, 4)\n\ncoords = {\"day_of_year\": day_of_year, \"vegetation_index\": vegetation_index}\n\nWe can use the coordinates to specify the soil cover of each plant. We’ll start with a grid of zeros\n\nsoil_cover = xr.DataArray(\n    data=np.zeros(day_of_year.shape + vegetation_index.shape),\n    coords=coords,\n    dims=(\"day_of_year\", \"vegetation_index\"),\n)\n\nThe simplest soil cover specification is a step function. In this case soil cover equals 1.0 for days 133 to 255 (mind Python’s 0-based index here), and for the rest of the days it equals zero.\n\nsoil_cover[132:254, :] = 1.0\n\nsoil_cover.sel(vegetation_index=1).plot()\n\n\n\n\n\n\n\n\nWe’ll simply triple the soil cover to get a leaf area index\n\nleaf_area_index = soil_cover * 3\n\nVegetation factors are used to convert the Makkink reference evapotranspiration to a potential evapotranspiration for a certain vegetation type. We’ll specify some simple crop schemes for the three crops as vegetation factors. Mind that the vegetation factor array has two dimensions: day_of_year and vegetation_index\n\nvegetation_names = [\"grass\", \"maize\", \"potatoes\"]\n\nvegetation_factor = xr.zeros_like(soil_cover)\n\nvegetation_factor[120:132, :] = [1.0, 0.5, 0.0]\nvegetation_factor[132:142, :] = [1.0, 0.7, 0.7]\nvegetation_factor[142:152, :] = [1.0, 0.8, 0.9]\nvegetation_factor[152:162, :] = [1.0, 0.9, 1.0]\nvegetation_factor[162:172, :] = [1.0, 1.0, 1.2]\nvegetation_factor[172:182, :] = [1.0, 1.2, 1.2]\nvegetation_factor[182:192, :] = [1.0, 1.3, 1.2]\nvegetation_factor[192:244, :] = [1.0, 1.2, 1.1]\nvegetation_factor[244:254, :] = [1.0, 1.2, 0.7]\nvegetation_factor[254:283, :] = [1.0, 1.2, 0.0]\n\n# Since grass is the reference crop, force all grass to 1.0\nvegetation_factor[:, 0] = 1.0\n\n\n# Assign vegetation names for the plot\nvegetation_factor.assign_coords(\n    vegetation_names=(\"vegetation_index\", vegetation_names)\n).plot.line(x=\"day_of_year\", hue=\"vegetation_names\")\n\n\n\n\n\n\n\n\nWe’ll leave the interception capacity at zero, and the other factors at one, and assign these to the AnnualCropFactors package.\n\nmsw_model[\"crop_factors\"] = msw.AnnualCropFactors(\n    soil_cover=soil_cover,\n    leaf_area_index=leaf_area_index,\n    interception_capacity=xr.zeros_like(soil_cover),\n    vegetation_factor=vegetation_factor,\n    interception_factor=xr.ones_like(soil_cover),\n    bare_soil_factor=xr.ones_like(soil_cover),\n    ponding_factor=xr.ones_like(soil_cover),\n)\n\n\n\n\n\nmsw_model[\"oc_idf\"] = msw.IdfMapping(area, -9999.0)\nmsw_model[\"oc_var\"] = msw.VariableOutputControl()\nmsw_model[\"oc_time\"] = msw.TimeOutputControl(time=times)\n\n\n\n\nMetaSWAP requires its own mapping of SVAT to MODFLOW cells, for internal use. We therefore provide the mf6.StructuredDiscretization and mf6.Well package to mf6.CouplerMapping.\n\nmsw_model[\"mod2svat\"] = msw.CouplerMapping(\n    modflow_dis=gwf_model[\"dis\"], well=gwf_model[\"wells_msw\"]\n)\n\nThe sprinkling package also requires the Modflow6 wells.\n\nmsw_model[\"sprinkling\"] = msw.Sprinkling(\n    max_abstraction_groundwater=xr.full_like(msw_grid, 100.0),\n    max_abstraction_surfacewater=xr.full_like(msw_grid, 100.0),\n    well=gwf_model[\"wells_msw\"],\n)",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Example"
    ]
  },
  {
    "objectID": "coupler_metamod_example.html#coupler-mapping",
    "href": "coupler_metamod_example.html#coupler-mapping",
    "title": "Example",
    "section": "",
    "text": "The MetaSWAP model and Modflow 6 simulation are provided to the MetaMod class, which takes care of connecting (= “mapping”) the two models. Make sure to provide the keys of the dummy Modflow 6 boundary conditions where MetaSWAP is coupled to, so iMOD Python knows where to look: It is technically possible to define multiple WEL and RCH packages in Modflow 6.\n\ndriver_coupling = primod.MetaModDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_recharge_package=\"rch_msw\",\n    mf6_wel_package=\"wells_msw\",\n)\n\nmetamod = primod.MetaMod(\n    msw_model=msw_model,\n    mf6_simulation=simulation,\n    coupling_list=[driver_coupling],\n)\n\nWe can write the coupled models by providing the following necessary paths to iMOD Coupler:\n\nmodflow 6 library\nmetaswap library\ndirectory with dependent libraries for metaswap\n\nYou can download the modflow and metaswap libraries (.dll’s) as part of the the last iMOD Coupler release for Windows for free. Please contact imod.support@deltares.nl if you require the libraries for Linux.\n\nmetamod_dir = imod.util.temporary_directory()\nmf6_dll = \"./path/to/mf6.dll\"\nmetaswap_dll = \"./path/to/metaswap.dll\"\nmetaswap_dll_dependency_dir = \"./path/to/metaswap/dll/dependency/directory\"\n\nmetamod.write(metamod_dir, mf6_dll, metaswap_dll, metaswap_dll_dependency_dir)",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Example"
    ]
  },
  {
    "objectID": "coupler_metamod_example.html#running-the-models",
    "href": "coupler_metamod_example.html#running-the-models",
    "title": "Example",
    "section": "",
    "text": "In order to run the models, make sure you install imod_coupler. You can find the installation instructions here.",
    "crumbs": [
      "iMOD Coupler",
      "MetaSWAP - MODFLOW 6",
      "Example"
    ]
  },
  {
    "objectID": "tutorial_Netherlands_mesh.html",
    "href": "tutorial_Netherlands_mesh.html",
    "title": "Load the data",
    "section": "",
    "text": "In this example, we’ll work with an unstructured grid. We’ll create a very simple unstructured model of the Netherlands from scratch. We’ll use a digital elevation model (DEM) to set as drain level to simulate overland flow. To this we add constant recharge.\nLet’s start with importing the required packages. These are iMOD Python, xarray, and xugrid.\nimport imod\nimport xarray as xr\nimport xugrid as xu",
    "crumbs": [
      "Tutorials",
      "Load the data"
    ]
  },
  {
    "objectID": "tutorial_Netherlands_mesh.html#write-model",
    "href": "tutorial_Netherlands_mesh.html#write-model",
    "title": "Load the data",
    "section": "Write model",
    "text": "Write model\n\ntmpdir = imod.util.temporary_directory()\n\nmodeldir = tmpdir / \"reference\"\nsimulation.write(modeldir)\n\nNow run our simulation:\n\n# mf6_path = \"path/to/mf6.exe\" \n\n# If you installed Modflow6 in your PATH environment variable, you can use the\n# following argument:\nmf6_path = \"mf6\"\n\nsimulation.run(mf6_path)\n\nLet’s look at the results:\n\nhead = simulation.open_head().load().isel(time=-1, layer=0)\n# calculate ground water below surface level.\ngroundwater_depth = elevation - head\n# Plot\ngroundwater_depth.ugrid.plot()\n\n\n\n\n\n\n\n\niMOD Python also supports partitioning a simulation, for parallel computation. It offers convenience functions to split existing simulations. For this we require a label array first.\n\nfrom imod.mf6.multimodel.partition_generator import get_label_array\n\nlabel_array = get_label_array(simulation, npartitions=4)\n\nlabel_array.ugrid.plot()\n\n\n\n\n\n\n\n\nLet’s split our simulation with the label array.\n\nsimulation_split = simulation.split(label_array)\n\nNow write the split simulation and run it\n\nmodeldir = tmpdir / \"partitioned\"\nsimulation_split.write(modeldir)\nsimulation_split.run(mf6_path)\n\nAnd plot the results. Note that iMOD Python takes care of merging the 4 partitioned models into one single head grid.\n\nhead_merged = simulation_split.open_head()[\"head\"].isel(time=-1, layer=0)\n# plot\nhead_merged.ugrid.plot(vmin=-20, vmax=90)",
    "crumbs": [
      "Tutorials",
      "Load the data"
    ]
  },
  {
    "objectID": "coupler_architecture.html",
    "href": "coupler_architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "The purpose of iMOD Coupler is to couple hydrological kernels. iMOD Coupler itself is written in Python, but the kernels are written in either Julia or Fortran. The most common way of interacting with libraries written in different languages is by letting them expose a C interface and compiling them as shared libraries.\nWhile not technically required, these libraries are expected to follow a variation of the Basic Model Interface or BMI. This describes a standardized way of controlling a modelling framework. It also allows to utilize the xmipy package, which wraps the C API into a Python API. On top of that, it is often convenient to add functions specific to the kernels. This is why Ribasim and MODFLOW 6 get a XmiWrapper subclass, that is called ribasim_api and modflow_api respectively.\nflowchart BT\n    libribasim.dll--&gt; xmipy_r[xmipy]\n    libmf6.dll --&gt; xmipy_m[xmipy]\n    xmipy_r --&gt; ribasim_api \n    xmipy_m --&gt; modflow_api \n    ribasim_api --&gt;  imodc[iMOD Coupler]\n    modflow_api --&gt;  imodc\nMost input data needs to be pre-processed in order to be suitable for the hydrological kernels. In the case of Ribasim this is handled by Ribasim Python, in the case of MODFLOW 6 it is handled by iMOD Python. However, the input data for the iMOD Coupler needs to be pre-processed as well. Coupling tables describe how the coupling takes place. In order to generate them, input data from all kernels are needed. The primod package wraps the functionality of the kernel pre-processors and generates the coupling data for iMOD Coupler.\nflowchart BT\n    ribasim_python[Ribasim Python] --&gt; primod\n    imod-python[iMOD Python] --&gt; primod\n    primod --&gt; ribasim[Ribasim]\n    primod --&gt; |couple tables|imodc\n    primod --&gt; MetaSWAP\n    primod --&gt; modflow6[MODFLOW 6]\n    ribasim --&gt; imodc[\"iMOD Coupler\"]\n    MetaSWAP --&gt; imodc[\"iMOD Coupler\"]\n    modflow6 --&gt; imodc",
    "crumbs": [
      "iMOD Coupler",
      "Architecture"
    ]
  },
  {
    "objectID": "coupler_architecture.html#drivers",
    "href": "coupler_architecture.html#drivers",
    "title": "Architecture",
    "section": "Drivers",
    "text": "Drivers\nCoupling Ribasim and MODFLOW 6 is only one of multiple coupling configurations. Each configuration is handled by an iMOD Coupler driver. A driver is a Python module under imod_coupler/drivers. At the minimum, it includes a subclass of the abstract class Driver as well as its own config under the [[driver.coupling]] namespace. A driver itself also includes a BMI interface, executing it then looks like this:\nself.initialize()\n\nwhile self.get_current_time() &lt; self.get_end_time():\n    self.update()\n\nself.finalize()\n\nLogging of exchanged values\nAn integral task of an iMOD Coupler driver is to support the exchange of values between hydrological kernels. Values exchanged by the coupler for a specific variable can optionally be written to file during the simulation for inspection. These values are written as timeseries to separate files per variable. In the initialization stage of the simulation a dictionary-like structure (ExchangeCollector class) is created which holds a collection of labelled ExchangeLogger instances. The initialization of an ExchangeLogger creates a netcdf file with dimensions time and id, a variable time with dimension (time) and a variable xchg with dimensions (time, id). The time dimension is the unlimited dimension.",
    "crumbs": [
      "iMOD Coupler",
      "Architecture"
    ]
  },
  {
    "objectID": "coupler_architecture.html#continuous-integration",
    "href": "coupler_architecture.html#continuous-integration",
    "title": "Architecture",
    "section": "Continuous Integration",
    "text": "Continuous Integration\nWe took great care to set up a pipeline to ensure that iMOD Coupler continues to work with the newest version of its dependencies. This is especially important since we access internal state of the kernels when coupling them. It can happen very easily that kernel developers change something that break assumptions of the coupler.\nAt the time of this writing, there are three kernels handled by iMOD Coupler:\n\nRibasim,\nMODFLOW 6, and\nMetaSWAP.\n\nOn TeamCity, the three kernels will be compiled to shared libraries and iMOD Coupler will be compiled to an executable. These binaries are then collected in a zip file, called the iMOD Collector. The iMOD Collector is checked on our testbench and can be downloaded by users.\n\n\n\n\n\nflowchart BT\n    ribasim[Ribasim] --&gt; imod_collector[iMOD Collector]\n    modflow[MODFLOW 6] --&gt; imod_collector\n    metaswap[MetaSWAP] --&gt; imod_collector\n    imodc[iMOD Coupler] --&gt; imod_collector\n    imod_collector --&gt; testbench[Testbench Coupler]",
    "crumbs": [
      "iMOD Coupler",
      "Architecture"
    ]
  },
  {
    "objectID": "practical_messy_data.html",
    "href": "practical_messy_data.html",
    "title": " Handling messy data",
    "section": "",
    "text": "Generally, you want to do cleanup, analysis, etc. in (Python) scripts -- reason being that it's reproducible:\n\nThere's something that describes step by step how something was done;\nYou can easily redo something when you find a mistake, get a new version of the data, etc.\n\nA general source of messy data is Excel -- after all, many people can work with Excel, in their own (perfidious) ways. Treat this as your immutable external data. However, convert the individual spreadsheets to CSV (or TSV if you like).\nThis has multiple benefits:\n\nData becomes more explicitly visible: separated tables, instead of somewhat hidden spreadsheets;\nData is much faster to read by most software: Excel files are a complicated format of zipped XML files. This is useful to store equations, formatting, etc., but not to just store the data;\nExcel file reader are not required: most software can easily read plain text like CSV, xsls files (zipped XML) not so much.\n\nIt's okay to make this a manual step: open the data with Excel, Save As, and store in your external data."
  },
  {
    "objectID": "practical_messy_data.html#dont-use-excel-files",
    "href": "practical_messy_data.html#dont-use-excel-files",
    "title": " Handling messy data",
    "section": "",
    "text": "Generally, you want to do cleanup, analysis, etc. in (Python) scripts -- reason being that it's reproducible:\n\nThere's something that describes step by step how something was done;\nYou can easily redo something when you find a mistake, get a new version of the data, etc.\n\nA general source of messy data is Excel -- after all, many people can work with Excel, in their own (perfidious) ways. Treat this as your immutable external data. However, convert the individual spreadsheets to CSV (or TSV if you like).\nThis has multiple benefits:\n\nData becomes more explicitly visible: separated tables, instead of somewhat hidden spreadsheets;\nData is much faster to read by most software: Excel files are a complicated format of zipped XML files. This is useful to store equations, formatting, etc., but not to just store the data;\nExcel file reader are not required: most software can easily read plain text like CSV, xsls files (zipped XML) not so much.\n\nIt's okay to make this a manual step: open the data with Excel, Save As, and store in your external data."
  },
  {
    "objectID": "practical_messy_data.html#avoid-alphabetical-or-numeric-codes",
    "href": "practical_messy_data.html#avoid-alphabetical-or-numeric-codes",
    "title": " Handling messy data",
    "section": "Avoid alphabetical or numeric codes",
    "text": "Avoid alphabetical or numeric codes\nThe following labels are obviously require a lot of additional information to become meaningful:\n\nA, B, C ...\nA1, B1, B2, ...\n1.1, 1.2, 1.3, 2.1, ...\n\nTry to avoid using such labels to describe data sources, scenario names, filenames, etc. Not only do they require (more) description to make sense, they're much harder to memorize compared to (more) verbose labels:\n\nnational_dataset, provincial_dataset, local_dataset\nlow_recharge, high_recharge\n\nAnd harder to memorize means: more mix-ups, more mistakes, time lost.\nJust like in scripting or programming: readability beats ease of writing."
  },
  {
    "objectID": "viewer_install_msi.html",
    "href": "viewer_install_msi.html",
    "title": "Install iMOD Viewer with the Deltares setup",
    "section": "",
    "text": "To install the iMOD Viewer components (3D Viewer & QGIS plugin), download the installer on the Deltares download portal. If the subscription worked correctly, you will receive a download link via e-mail within only a few minutes.\n\n\n\n\n\n\nWarning\n\n\n\nThe QGIS plugin of course requires QGIS. You can download the standalone QGIS setup on the QGIS website We recommend downloading a QGIS version &gt;= 3.28 here. After downloading the QGIS setup, run it.\n\n\nUnzip the zipfile, which includes the viewer installer. Double click the .msi file.\nThis will open up the first screen of the setup wizard.\n\n\n\nThe starting screen.\n\n\nClick Next here, which will open up the next screen, which is the license screen.\n\n\n\nThe license screen\n\n\nTick the \"I accept\" tickbox, and click Next.\nThis will open up the installation selection screen.\n\n\n\nInstallation selection type.\n\n\nYou can select a Minimal or Complete installation here, by clicking the respective buttons.\nNote that the QGIS plugin, which comes only with a Complete install, is required to use all features of the iMOD viewer. These are:\n\nDrawing fence diagrams\nLoading only a sub section of the map (useful for large files)\nAccess to more legends.\n\nAfter selecting the preferred installation type, you still have to click Next before installation continues.\nThis will open the install screen.\n\n\n\nThe wizard install screen\n\n\nClick Install and after installation is complete, click Finalize. You should now be ready to go.\nThe installer will also create a program shortcut to the pdf with documentation. If you open the Windows Start window and type \"iMOD Suite User Manual\" it should pop up.\n\n\n\nA program shortcut should created by the installer to the User Manual.",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer with the Deltares setup"
    ]
  },
  {
    "objectID": "python_install.html",
    "href": "python_install.html",
    "title": "Install",
    "section": "",
    "text": "The recommended way of installing iMOD Python is by running the Deltaforge installer. Read the Deltaforge installation instructions here.\nFor other ways to install iMOD Python, see its documentation.\niMOD Python has no point release schedule, but instead has a \"rolling release\", where the package is frequently updated. For the quickest access to the latest changes, do a development install.",
    "crumbs": [
      "iMOD Python",
      "Install"
    ]
  },
  {
    "objectID": "coupler_release.html",
    "href": "coupler_release.html",
    "title": "Release process",
    "section": "",
    "text": "The imod_coupler repository contains multiple components, at the time of this writing the pre-processing package primod and imod_coupler itself. The components are currently only guaranteed to work together if they are built at the same time. Therefore we release iMOD Coupler as a collection of all the components at once. For maximum interoperability it is suggested to only release all components together, and not individually.\nFor these releases we use Calender Versioning, which makes it clear in which month the release was made.",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_release.html#pre-release-checks",
    "href": "coupler_release.html#pre-release-checks",
    "title": "Release process",
    "section": "Pre-release checks",
    "text": "Pre-release checks\nBefore starting the release process, ensure that all tests are passing and that all features intended for the release are complete and merged into the main branch.",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_release.html#update-version-numbers-of-the-components-as-needed",
    "href": "coupler_release.html#update-version-numbers-of-the-components-as-needed",
    "title": "Release process",
    "section": "Update version numbers of the components as needed",
    "text": "Update version numbers of the components as needed\nDetermine the new version number like 2023.1.0, filling in the current year, a bumped MINOR number for normal releases and a bumped MICRO number for non-breaking, hotfix releases. This follows YYYY.MINOR.MICRO from calver.\nThe components are only guaranteed to work together if they are built at the same time. To clearly communicate this, component versions need to have synchronized version numbers. This means that both version numbers should be updated even if only one component has been changed.\nUpdate the version numbers in the repository to the new version number. Update the following two locations:\n\nimod_coupler/__init__.py\npre-processing/primod/__init__.py\n\nNow submit a pull request which updates the version numbers of the components as needed.\n\nCreate a new branch and switch to it, for example: git switch --create new-release.\nCreate a new commit with the updated version number\nPush to remote\nCreate a Pull Request\nMerge the Pull Request into main",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_release.html#create-a-new-release",
    "href": "coupler_release.html#create-a-new-release",
    "title": "Release process",
    "section": "Create a new release",
    "text": "Create a new release\nCreate a new tag like v2023.1.0 by prepending v to the calver version number.\nThis can be done by executing:\ngit tag &lt;tagname&gt;\nThen push the tags:\ngit push --tags\nThis will trigger a workflow on TeamCity that will publish a new release on GitHub as soon as it is finished. You can follow the progress here. It also auto-generates a changelog. You’ll probably want to curate that by rearranging the most important changes for users to the top in the form of Keep a Changelog. The possibly long list of generated release notes can put below an “All changes” collapsed item as such:\n&lt;details&gt;\n&lt;summary&gt;\nAll changes\n&lt;/summary&gt;\n\n# Put Github flavored markdown here\n\n&lt;/details&gt;",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_release.html#release-primod-on-pypi",
    "href": "coupler_release.html#release-primod-on-pypi",
    "title": "Release process",
    "section": "Release primod on PyPI",
    "text": "Release primod on PyPI\nTo be able to do pip install primod , primod needs to be released on the Python Package Index. First, make sure that you have a PyPI account. Then create a new API token and store it in a secure location.\nRun the following to start the process:\npixi run publish-primod",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_release.html#announce-release",
    "href": "coupler_release.html#announce-release",
    "title": "Release process",
    "section": "Announce release",
    "text": "Announce release\nAnnounce the release in appropriate channels.",
    "crumbs": [
      "iMOD Coupler",
      "Release process"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html",
    "href": "coupler_ribametamod_preprocessing.html",
    "title": "Pre-processing",
    "section": "",
    "text": "This document describes how to set up a coupled Ribasim-MetaSWAP-MODFLOW 6 model. The primod Python package is used for setting up a coupled model. It uses the three models, updateds modelinput, derives the exchange relationships, and writes:\nThe derivation of exchange connections between the models is automatic, and based on the spatial information provided for both models.\nAs primod is a Python package, all three models must be represented in Python:\nThe combination of the three models is represented by the RibaMetaMod class of primod.\nThe Modflow6Simulation and Ribasim Model can be initialised from a TOML file with associated data. The MetaSwapModel does not support this yet. Initialising this model can be scripted.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html#coupling-and-model-requirements",
    "href": "coupler_ribametamod_preprocessing.html#coupling-and-model-requirements",
    "title": "Pre-processing",
    "section": "Coupling and model requirements",
    "text": "Coupling and model requirements\nThe RibaMetaMod class includes three separate couplings.\n\nMODFLOW 6 and MetaSWAP\nThis coupling is equal to the MetaMod driver and requires the following MODFLOW packages:\n\nRecharge for the exchange of the flux from the unstaurated zone.\n\nWel for the optional exchange of irrigation from groundwater\n\nThis coupling requires the following MetaSWAP packages:\n\nSprinkling to define the maximum irrigation rate.\nLanduseOptions to specify the irrigation regime.\n\n\n\nMODFLOW 6 and Ribasim\nThis coupling is equal to the one of RibaMod and requires the following MODFLOW packages for exchangeing stage (active) and flux (active and passive):\n\nRiver\nDrainage\n\nThese packages can be used interchangeably\nThis coupling has the following requirement on the Ribasim model:\n\nThe Basins need to be set up with a subgrid for active coupling.\n\n\nConsistency between MODFLOW 6 and Ribasim subgrid\n\nDuring the coupling, water levels should not be set below the bed elevation of the boundary. For drainage packages, this is the drainage elevation provided in the MODFLOW 6 input; for river packages, this is the bottom elevation provided in the MODFLOW 6 input.\n\n\nThere is potential for inconsistency here, as Ribasim also describes a bed elevation: the lowest level of the subgrid piecewise interpolation table:\n\nIn case the MODFLOW 6 bed elevation is higher than the subgrid elevation, infiltration will stop before the Ribasim basin is empty.\nIn case the MODFLOW 6 bed elevation is lower than the subgridelevation, infiltration will proceed even when the Ribasim basin is empty. In this case primod will raise an error\n\n\n\nRibasim and MetaSWAP\nThis coupling is used for routing runoff at the subsurface to the Ribasim basins. This coupling requires the following MetaSWAP package:\n\nPonding to define the ponding level at which runoff is generated.\n\nOptionally the irrigation from surface water can be coupled to the UserDemand in Ribasim. In that case the sprinkling realized in MetaSWAP, depends on the water availability for the UserDemand in Ribasim. This coupling requires the following MetaSWAP packages:\n\nSprinkling to define the maximum irrigation rates.\nLanduseOptions to specify the irrigation regime.\n\nThis coupling has the following requirements on the Ribasim model:\n\nThere should be User_demand defined with one priority per coupled water user. For this priority there should be a rate defined &gt; 0.0. This specified rate will be replaced with the coupled MetaSWAP demands.\n\nIf Allocation is active in the Ribasim model, The demand-realization cycle is based on the user priority and the water availability. When it’s inactive its based on water availability alone.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html#coupling-and-model-extents",
    "href": "coupler_ribametamod_preprocessing.html#coupling-and-model-extents",
    "title": "Pre-processing",
    "section": "Coupling and model extents",
    "text": "Coupling and model extents\n\nThe start and end times of the Ribasim, MetaSWAP and MODFLOW 6 simulations must align. primod will raise an error otherwise.\nSpatial extents of the models need not coincide:\n\nPart of the Ribasim basins may be located outside of the MODFLOW 6 and MetaSWAP simulation window. Uncoupled basins will proceed with the regular drainage and irrigation terms define in the model.\nNot every MODFLOW 6 River and Drainage boundary needs to be linked with Ribasim. Boundaries outside of any basin polygon will simply use the regular file input.\nNot every MetaSWAP SVAT need to be linked with Ribasim. For uncoupled SVATS, runoff is not routed via the surface water and irrigation from surface water is unlimited.\nThe MetaSWAP model does not need to be active in the complete MODFLOW 6 simulation window. Uncoupled MODFLOW 6 nodes can have an additional RCH and EVT package.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html#abbreviated-examples-of-coupling",
    "href": "coupler_ribametamod_preprocessing.html#abbreviated-examples-of-coupling",
    "title": "Pre-processing",
    "section": "Abbreviated examples of coupling",
    "text": "Abbreviated examples of coupling\nThe following abbreviated example for coupling Runoff:\n\nReads a Ribasim model\nTakes a MetaSWAP model\nReads a MODFLOW 6 simulation\nReads a basin definition associated with the Ribasim model\nDefines a driver coupling: which river and drainage packages are coupled\nSets up a coupled model\nWrites the coupled model\n\nimport ribasim\nimport geopandas as gpd\nimport imod\nimport primod\n\n\nribasim_model = ribasim.Model.read(\"ribasim/ribasim.toml\")\nmetaswap_model = metaswap_model_from_script\nmf6_simulation = imod.mf6.Modflow6Simulation.from_file(\"modflow/GWF_1.toml\")\n\nbasin_definition = gpd.read_file(\"ribasim_network.gpkg\", layer=\"basin_areas\")\n\n# Active coupling Ribasim - MODFLOW\ndriver_coupling_ribamod_active = primod.RibaModActiveDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_packages=[\"riv-1\"],\n    basin_definition=basin_definition,\n)\n# coupling Ribasim - MetaSWAP\ndriver_coupling_ribameta = primod.RibaMetaDriverCoupling(\n    ribasim_basin_definition=basin_definition,\n)\n# coupling MODFLOW 6 - MetaSWAP\ndriver_coupling_metamod = primod.MetaModDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_recharge_package=\"rch_msw\",\n    mf6_wel_package=\"well_msw\",\n)\n# generate coupled model\nribametamod_model = primod.RibaMetaMod(\n    ribasim_model=ribasim_model,\n    mf6_simulation=mf6sim,\n    coupling_list=[driver_coupling_ribamod_active, driver_coupling_ribameta,driver_coupling_metamod],\n)\n\nribametamod_model.write(\n   directory=\"coupled-ribametamod-simulation\",\n   modflow6_dll=r\"c:\\bin\\imod_coupler\\modflow6\\libmf6.dll\",\n   ribasim_dll=r\"c:\\bin\\imod_coupler\\ribasim\\bin\\libribasim.dll\",\n   ribasim_dll_dependency=r\"c:\\bin\\imod_coupler\\ribasim\\bin\",\n)\nFor including the optional coupling of irrigation from surface water, the following addition can be done:\n# read additional water-user definition polygon\nwater_users_definition = gpd.read_file(\"ribasim_network.gpkg\", layer=\"water_user_areas\")\n\n# add water-user definition to the RibaMetaDriverCoupling\ndriver_coupling_ribameta = primod.RibaMetaDriverCoupling(\n    ribasim_basin_definition=basin_definition,\n    ribasim_user_demand_definition=water_users_definition,\n)\n\n# proceed as previous example",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html#exchange-derivation",
    "href": "coupler_ribametamod_preprocessing.html#exchange-derivation",
    "title": "Pre-processing",
    "section": "Exchange derivation",
    "text": "Exchange derivation\nThe exchanges are derived based on spatial overlap of the models. In general all couplings with ribasim are based on a spatial overlap of the basin and/or water user definition polygons. The coupling between MODFLOW 6 6 and MetaSWAP is based on overlapping grid based coordinates. The coupling based on polygon definitions is done in the following way:\n\nRasterize the basin and/or Water users definition polygons (provided as a geopandas.GeoDataFrame) to the MODFLOW 6 or MetaSWAP model grid.\nOverlay the grid-based variable on the rasterized basin definition, and derive for each gridcel the basin index.\nIdentify the indices of the coupled MODFLOW 6 or MetaSWAP gridcel.\nStore the basin indices and gridcel indices in a table.\n\n\nRibasim and MODFLOW\n\nFor the flux exchange, the Overlay is based on the river conductance. The indices are based on the package level. For the stage exchange, the mapping is based on the x and y locations of the subgrid elements. For every river conductance gridcell the neirest subgrid element is found.\n\nRibasim and MetaSWAP\n\nFor Runoff exchange the overlay is based on the basin definition and all active SVATS. For the irrigation of surface water, the Overlay is based on the water user definition and all SVATS for which irrigation from surface water is active.\n\nMODFLOW 6 and MetaSWAP\n\nThe grid-based recharge, storage and well exchange is based on overlapping xy-coordinates. The optional 1-N coupling between MODFLOW 6 and MetaSWAP is based on the subunit coordinate in the MetaSWAP model.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribametamod_preprocessing.html#modifications-to-the-models",
    "href": "coupler_ribametamod_preprocessing.html#modifications-to-the-models",
    "title": "Pre-processing",
    "section": "Modifications to the models",
    "text": "Modifications to the models\n\nRibasim\n\nThe primod.RibaMod class makes the following alteration to the Ribasim input before writing the Ribasim model:\n\n\n\nfor basins coupled to MODFLOW 6, the “infiltration and drainage” columns are set to NaN / Null (nodata) in the Basin / Static or Basin / Time tables. This ensures that Ribasim does not overwrite the exchange flows while running coupled with MODFLOW 6.\n\nCoupled basins should entirely fall within the MODFLOW 6 domain. The portion outside the MODFLOW 6 domain is excluded from infiltration and drainage.\n\nModflow 6\n\nFor all actively coupled RIV packages an API-package is added to the simulation. This package is used to apply the flux correction. In a water-balance from the MODFLOW 6 output, this package output should be added RIV output\n\nMetaSWAP\n\nCurrently no modifications are made in the MetaSWAP model",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MetaSWAP - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": " Tutorials",
    "section": "",
    "text": "The iMOD-suite consists of several components, and combining these in different ways allows for different workflows. This “mix-and-match” capability benefits user flexibility, but it can be a bit daunting at start.\nTherefore, we have compiled a set of tutorials to help you get started and give you an overview of the Suite’s capabilities.\nTo download and install the iMOD Suite, follow the instructions here. To download the tutorial material, you can follow this link.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbeyfeale\n\n\nComponents: QGIS and iMOD plugin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConceptual fresh-salt model\n\n\nComponents: iMOD Python, iMOD WQ, QGIS plugin, 3D Viewer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDommel\n\n\nComponents: iMOD 3D Viewer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModifying an existing Modflow 6 model in iMOD Python\n\n\nIn this tutorial, you will learn how to use iMOD Python for building, running and analysing your MODFLOW 6 model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnstructured grid model\n\n\nIn this example, we’ll work with unstructured grid. We’ll create a very simple unstructured model of the Netherlands from scratch.\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Tutorials",
      "{{< fa solid book >}} Tutorials"
    ]
  },
  {
    "objectID": "practical_cookiecutter.html",
    "href": "practical_cookiecutter.html",
    "title": " Consistent folder structures with Cookiecutter",
    "section": "",
    "text": "Cookiecutter enables creating templated folder structures and files to kickstart your projects. At Deltares, we created such a template.\nUsing the same project template in an organization has the following advantages:\nThe iMOD Gitlab group contains multiple applications of the Deltares Project template."
  },
  {
    "objectID": "practical_cookiecutter.html#install",
    "href": "practical_cookiecutter.html#install",
    "title": " Consistent folder structures with Cookiecutter",
    "section": "Install",
    "text": "Install\nTo install Cookiecutter, run the following command:\npip install cookiecutter"
  },
  {
    "objectID": "practical_cookiecutter.html#kickstart-project",
    "href": "practical_cookiecutter.html#kickstart-project",
    "title": " Consistent folder structures with Cookiecutter",
    "section": "Kickstart project",
    "text": "Kickstart project\nThen to create a new project:\ncookiecutter gl:deltares/imod/cookiecutter-reproducible-project\nThis will create the following folder and file structure:\n.\n├── AUTHORS.md\n├── LICENSE\n├── README.md\n├── bin                 &lt;- Your compiled model code can be stored here (not tracked by git)\n├── config              &lt;- Configuration files, e.g., for doxygen or for your model if needed\n├── data                \n│   ├── 1-external      &lt;- Data external to the project.\n│   ├── 2-interim       &lt;- Intermediate data that has been altered.\n│   ├── 3-input         &lt;- The processed data sets, ready for modeling.\n│   ├── 4-output        &lt;- Data dump from the model.\n│   └── 5-visualization &lt;- Post-processed data, ready for visualisation.\n├── docs                &lt;- Documentation, e.g., doxygen or scientific papers (not tracked by git)\n├── notebooks           &lt;- Jupyter notebooks\n├── reports             &lt;- For a manuscript source, e.g., LaTeX, Markdown, etc., or any project reports\n│   └── figures         &lt;- Figures for the manuscript or reports\n└── src                 &lt;- Source code for this project\n    ├── 0-setup         &lt;- Install necessary software, dependencies, pull other git projects, etc.\n    ├── 1-prepare       &lt;- Scripts and programs to process data, from 1-external to 2-interim.\n    ├── 2-build         &lt;- Scripts to create model specific input from 2-interim to 3-input. \n    ├── 3-model         &lt;- Scripts to run model and convert or compress model results, from 3-input to 4-output.\n    ├── 4-analyze       &lt;- Scripts to post-process model results, from 4-output to 5-visualization.\n    └── 5-visualize     &lt;- Scripts for visualisation of your results, from 5-visualization to ./report/figures."
  },
  {
    "objectID": "python_getting_started.html",
    "href": "python_getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "import imod\n\n# read and write IPF files to pandas DataFrame\ndf = imod.ipf.read('wells.ipf')\nimod.ipf.save('wells-out.ipf', df)\n\n# get all calculated heads in a xarray DataArray\n# with dimensions time, layer, y, x\nda = imod.idf.open('path/to/results/head_*.idf')\n\n# create a groundwater model\n# abridged example, see examples for the full code\ngwf_model = imod.mf6.GroundwaterFlowModel()\ngwf_model[\"dis\"] = imod.mf6.StructuredDiscretization(\n    top=200.0, bottom=bottom, idomain=idomain\n)\ngwf_model[\"chd\"] = imod.mf6.ConstantHead(\n    head, print_input=True, print_flows=True, save_flows=True\n)\nsimulation = imod.mf6.Modflow6Simulation(\"ex01-twri\")\nsimulation[\"GWF_1\"] = gwf_model\nsimulation.time_discretization(times=[\"2000-01-01\", \"2000-01-02\"])\nsimulation.write(modeldir)",
    "crumbs": [
      "iMOD Python",
      "Getting started"
    ]
  },
  {
    "objectID": "tutorial_Dommel.html",
    "href": "tutorial_Dommel.html",
    "title": "Dommel",
    "section": "",
    "text": "In this tutorial, you will learn the following:\n\nBasic usage of the iMOD 3D Viewer\nView a shapefile in the 3D viewer\nView a grid with timeseries in the 3D viewer",
    "crumbs": [
      "Tutorials",
      "Dommel"
    ]
  },
  {
    "objectID": "tutorial_Dommel.html#description",
    "href": "tutorial_Dommel.html#description",
    "title": "Dommel",
    "section": "",
    "text": "In this tutorial, you will learn the following:\n\nBasic usage of the iMOD 3D Viewer\nView a shapefile in the 3D viewer\nView a grid with timeseries in the 3D viewer",
    "crumbs": [
      "Tutorials",
      "Dommel"
    ]
  },
  {
    "objectID": "tutorial_Dommel.html#objective",
    "href": "tutorial_Dommel.html#objective",
    "title": "Dommel",
    "section": "Objective",
    "text": "Objective\nIn this tutoral we will explore the iMOD 3D Viewer, based on data of the Dommel, a catchment in south of the Netherlands. This viewer is developed because QGIS does not support 3D viewing. It can display your geological data (layers and borehole data) but also data variation through time like chloride concentrations.\nThere are 2 options to start the 3D Viewer. One option is to select layers in QGIS and select the 3D Viewer icon on the iMOD toolbar . The selected layers are opened in the 3D Viewer. The other option is to start the 3D Viewer directly. In this short Tutorial we’ll pursue the second option.",
    "crumbs": [
      "Tutorials",
      "Dommel"
    ]
  },
  {
    "objectID": "tutorial_Dommel.html#tutorial",
    "href": "tutorial_Dommel.html#tutorial",
    "title": "Dommel",
    "section": "Tutorial",
    "text": "Tutorial\n\nLaunch the iMOD 3D Viewer from your START menu or your desktop. Search for “imod6.exe”.\nMaximize the program window for a better view.\n\nWe display some data from Brabant, a province in The Netherlands. (In case you missed the download instructions for the Tutorial data, visit the start page iMOD Suite Tutorial).\nLet’s first import an overlay file showing the surface water elements.\n\nIn the main menu choose “Data”, select “Open overlay” and open the shape file “…\\iMod-Suite-Tutorial_01\\data\\1-external\\Brabant-data\\riv_brabant.shp”.\nSelect the new layer in the overview and click the “draw-selected-layer” button ().\n\nNow we’ll open a dataset containing Heads calculated with a MODFLOW model. This NetCDF file contains for each model layer the top, the bottom and a timeseries of calculated heads.\n\nIn the main menu choose “Data”, select “Open grid file” and open the shape file “..\\iMod-Suite-Tutorial_01\\data\\1-external\\Brabant-data\\Calculated-Heads.nc”.\nSelect both layers in the overview and click the “draw-selected-layer” button ().\nClick on the “&gt;” sign left from the layer “Calculated-Heads“ and you’ll see a subset with “All Layer” and “Layered Datasets”.\nClick on the “&gt;” sign left from both the section “All Layer” and “Layered Datasets”.\n\nYour screen might look like Figure 1\n\n\n\n\n\n\nFigure 1: Top view of dataset “Calculated-Heads” and river overlay in the 3D viewer\n\n\n\nLet’s now experience with the viewer controls.\n\nSpin the mouse wheel forward to zoom in and spin backwards to zoom out. On a laptop, move two fingers up and down on the touchpad.\nIn case you lost control on your display view, click in the toolbar Viewer Controls on the “zoom-to-extent” button () to return to the initial view.\nCombine the Shift button + right mouse and move the camera horizontally/vertically with each mouse move (or finger on your touch pad).\nCombine the Ctrl button + right mouse and rotate the camera around its lens with a mouse move (or finger on your touch pad).\nGo back to the initial view with the “zoom-to-extent” button ().\nHold the right mouse button while moving the mouse and the camera moves around the grid.\n\nThe imported data is a nice example of an unstructured grid.\n\nZoom in to the upper left part of the grid. Notice that the grid is built from triangles, concentrated around the rivers.\nSwitch the dataset on and off with a click on the () button in file overview, left of the layer. See the underlying rivers.\n\nIn your display the vertical thickness of the dataset is perhaps rather small. Let’s increase the vertical exaggeration.\n\nIn the upper right corner, switch off the “automatic exaggeration of the z-axis”.\nNow increase the value to 50.0 and the view will change automatically.\n\nSome final experience with the other viewer controls.\n\nUse the buttons () to reposition your camera to another fixed position to the grid.\nClick the button “Toggle Sliders”() to activate the sliders for the X, Y and Z direction.\nExperiment with the sliders, both left and right \n\nThe colors in the display by default referred to the Elevation of the layers. Let’s now color the layers by calculated Head.\n\nIn the list of imported files select “Calculated-Heads”.\nFrom the subset “layered Datasets” double click on the element “data”.\n\nWait a few seconds and the name turns bold and the colors in the display change.\n\nSelect the name “data” and click your right mouse button to open a pop-up window.\nSelect “Edit legend” to open the “Legend editor” (see figure below).\n\nSelect PIYG for Color scale.\nCheck the Percentiles box.\nClick on OK and the window will close. The colors in your display change automatically.\n\nThe imported file doesn’t contain one single head, but a timeseries of calculated heads ranging from 01/01/2018 – 01/02/2018. Now let’s use the Time Slider to display the data through time. \n\nFirst click the button “Back(+y)” for a nice 3D view.\nClick the button () to start the animation. It is a large dataset to the view in the display only changes slowly.\nStop the animation with the button ().\nPlay around with the slider.\n\nThat’s all for now. You can save your session if you like.\n\nFrom the main menu choose “File” and select “Save As…” to save the session as an *.imod file.\nClose the 3D viewer via menu “File” and select Quit”.\n\nThank you for your patience and attention.\n\n\n\n\n\n\nFigure 2: iMOD 3D Viewer - Legend Editor",
    "crumbs": [
      "Tutorials",
      "Dommel"
    ]
  },
  {
    "objectID": "practical_look_like_a_pro.html",
    "href": "practical_look_like_a_pro.html",
    "title": " How to look like a pro",
    "section": "",
    "text": "These are some general tips and tricks to make your editors and terminals look cool. They are not going to greatly improve your workflow, but they will make things look cool and thus make your working more enjoyful. Please do this in your own time."
  },
  {
    "objectID": "practical_look_like_a_pro.html#powershell-themes",
    "href": "practical_look_like_a_pro.html#powershell-themes",
    "title": " How to look like a pro",
    "section": "Powershell themes",
    "text": "Powershell themes\nThere are themes available for Powershell which you can use to make your boring terminal look cooler. These will also be used by Windows Terminal and VSCode after some extra configuration.\n\n\n\nFigure 1: Look at all the colors on top! It contains the current git branch, as well as which Spotify song I'm currently listening to. Remember to only listen to cool music if you want to look cool!\n\n\n\nStep 1: Installing new fonts\nAll these cool extra icons like the play button and the folder symbol in Figure 1 require extra icons not contained in your standard monotype font. To unlock them, you have to install \"Nerd fonts\".\n\n\n\nFigure 2: It is cool to be a nerd these days.\n\n\nIn the following examples, I will use CascadiaCode NerdFont, which you can download zipped via this link\nUnzip its' contents, and install Caskaydia Cove Nerd Font Complete Mono Windows Compatible.ttf, by right-clicking the file and install for all users. You know it has to be good with such a long filename!\n\n\nStep 2: Configure software to use Nerd Font\nWe first have to configure your editor/terminal to use the Nerd Font, otherwise all the icons will be shown as ￿, which spoils the fun.\nIn Windows Terminal, press CTRL+, , which opens the Settings window. Next, navigate to Windows Powershell &gt; Appearance. And under Fonts, select CaskaydiaCove NF, if you installed the font I suggested.\n\n\n\nimage\n\n\nIn VSCode, also press CTRL+, to open the Settings window. Navigate to Text Editor &gt; Font and under Font Family type CaskaydiaCove NF in front.\n\n\n\nimage\n\n\nIn Powershell, you can right click window bar and navigate to Properties &gt; Font and under Font, you can select CaskaydiaCove NF.\n\n\nStep 3: Install Git for Windows\nIf you want your themes to integrate with Git, you can install Git for Windows .\nI have not tested if the themes worked without Git for Windows, so I recommend installing it.\nI also wrote a guide on how to use Git by the way.\n\n\nStep 4: Install themes for Powershell\nNow open up a Powershell instance as administrator, and run the following lines of code:\nInstall-Module posh-git -Scope CurrentUser\nInstall-Module oh-my-posh -Scope CurrentUser -RequiredVersion 2.0.412\nUpdate-Module -Name oh-my-posh -AllowPrerelease -Scope CurrentUser\nInstall-Module -Name PSReadLine -Scope CurrentUser -Force -SkipPublisherCheck\nThis will probably throw you some warnings if you really want to install this stuff, but let's trust the good people at Microsoft.\n\n\nStep 5: Configure Powershell\nBecause we want Powershell to automatically use new cool themes, we will configure our Powershell profile. Call notepad $PROFILE and paste the following lines of text:\nImport-Module posh-git\nImport-Module oh-my-posh\nSet-PoshPrompt -Theme cinnamon\nIf everything worked, if you open up a new Powershell terminal, it will look like Figure 1. If you see any squares as ￿, you have to check if Step 2 went OK.\n\n\nStep 6: Being a unique individual\nA cool person decides what is cool him/herself of course. To get a list of all available themes, you can call Get-PoshThemes.\n\n\n\nWowzers!\n\n\nThis provide a nice demo reel of available themes.\nIf you find something you like, you can set it as your default theme by repeating Step 5, and changing the last line, e.g.: Set-PoshPrompt -Theme powerline.\n\n\nBonus: Get a headache with retro effects\nWindows Terminal has retro effects available. Again press CTRL+,, go to Windows Powershell &gt; Appearance. And click Retro terminal effects.\nThis will make your terminal more headache inducing:\n\n\n\nArgh!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "If you have questions on using iMOD Suite or want to report a bug, you can send an email to imod.support@deltares.nl.\n\n\n\nBelow is the list of repositories that contain the source code of the individual components. You can raise issues, or suggest changes, here.\n\niMOD Documentation Github\niMOD QGIS plugin Github\niMOD 3D Viewer Github\niMOD Python Github"
  },
  {
    "objectID": "about.html#get-involved",
    "href": "about.html#get-involved",
    "title": "About",
    "section": "",
    "text": "If you have questions on using iMOD Suite or want to report a bug, you can send an email to imod.support@deltares.nl.\n\n\n\nBelow is the list of repositories that contain the source code of the individual components. You can raise issues, or suggest changes, here.\n\niMOD Documentation Github\niMOD QGIS plugin Github\niMOD 3D Viewer Github\niMOD Python Github"
  },
  {
    "objectID": "about.html#history",
    "href": "about.html#history",
    "title": "About",
    "section": "History",
    "text": "History\nDevelopments on iMOD started in 2006, with the aim to make groundwater modelling with MODFLOW easier. iMOD developed into a full fletched GUI, which could be used to build and analyse groundwater models from start to finish. Focus of the software always has been on large groundwater models, for which the software was so successful that most regional groundwater models owned by water boards in Netherlands, plus the Dutch National model (LHM), run on iMOD. In 2014, in Deltares’ move to make their software open source, the Fortran code of iMOD was shared and in 2015 the compiled executables became freely available. In many international projects (for example in India, New Orleans, Colombia, Germany, and Switzerland) this was one of the reasons to adopt iMOD as the modelling software. iMOD’s capabilities of simulating large groundwater models were pushed further in 2017 when iMOD and its custom computational kernels iMODFLOW and iMOD-WQ, could be run in parallel. Developments on the GUI continued up to 2020, when it became apparent that the approach up to that point had a few drawbacks:\n\nWith the release of Modflow 6, computations on unstructured grids were possible. This created a demand for supporting all types of unstructured grids. iMOD, however, could not support these grids (except multi-model structured subgrids).\nIt was difficult to connect iMOD to the ever changing software and data science ecosystem, because of the use of Fortran and iMOD’s custom data formats. For example, Python has a larger ecosystem, allowing users to easily incorporate all kinds of packages into their workflows.\n\nTherefore, in 2021, the iMOD Suite was released. This suite consists of a Python package, a QGIS plugin, and a 3D viewer. It therefore supports reproducible workflows for unstructured groundwater models and relies more on standard filetypes such as NetCDF, UGRID, and shapefiles.\nThe classic iMOD GUI and its batch functionality is consolidated under the name iMOD 5, and will be maintained for the coming years. During this transition period it is easy to use iMOD 5 in combination with iMOD Suite. New developments will land in iMOD Suite.\n\n\n\n\n\n\nflowchart TB\n  subgraph 2006\n  A{iMOD 1.0}\n  X{{Start development}}\n  end\n  A --&gt; B{iMOD 2.0}\n  subgraph 2014\n  B\n  Y{{Fortran code \\n available as open source}}\n  end\n  B --&gt; C{iMOD 3.0}\n  subgraph 2015\n  C\n  Z{{Executables freely \\n available}}\n  end\n  C --&gt; D{iMOD 4.0}\n  subgraph 2017\n  D\n  XX{{parallel Solver Pks}}\n  end\n  D --&gt; E{iMOD 5.0}\n  subgraph 2019\n  E\n  XY{{iMOD Water Quality \\n and MODFLOW6}}\n  end\n  E --&gt; F{iMOD 5.2}\n  subgraph 2020\n  F\n  XZ{{BMI coupling \\n Modflow6-MetaSWAP}}\n  end\n  F --&gt; G{iMOD Suite}\n  F --&gt; H{iMOD 5.3}\n  subgraph 2021\n  G\n  YX{{Tooling in Python, QGIS \\n C++. Unstructured grids}}\n  end\n  subgraph 2021 \n  H\n  end\n  H --&gt; I{iMOD 5.5}\n  G --&gt; J{iMOD Suite}\n  subgraph 2023\n  I\n  end\n  subgraph 2023 \n  J\n  YY{{Model input validation, \\n CPT plotting in QGIS, \\n Backwards \\n compatibility iMOD 5}}\n  end"
  },
  {
    "objectID": "about.html#trainings",
    "href": "about.html#trainings",
    "title": "About",
    "section": "Trainings",
    "text": "Trainings\n\nDelft Software Days\nTwice a year, there is an iMOD day, where users can hear the latest iMOD developments and get training in the latest features. These are a great opportunity to get to know fellow users and the developers. Trainings will be announced on the Delft Software Days website and via the iMOD mailing list, so keep an eye out on those.\nIn 2021, the Delft Software Days were not held in person but recorded as webinars, which can be viewed online. Note that due to privacy settings, you might need follow the link below the video to view it on the Deltares Vimeo page.\n\niMOD User Day 2021 from Deltares on Vimeo.\n\n\nPast trainings iMOD Suite\n2023-02: National University of Singapore, Singapore\n\n2022-11: Deltares Campus, Delft\n\n2022-06: Trinity college, Dublin"
  },
  {
    "objectID": "about.html#publications-using-imod-suite",
    "href": "about.html#publications-using-imod-suite",
    "title": "About",
    "section": "Publications using iMOD Suite",
    "text": "Publications using iMOD Suite\n\n\nDelsman, Joost R., Tobias Mulder, Betsy Romero Verastegui, Huite Bootsma, Pieter Zitman, Sebastian Huizer, and Gualbert H. P. Oude Essink. 2023. “Reproducible Construction of a High-Resolution National Variable-Density Groundwater Salinity Model for the Netherlands.” Environmental Modelling & Software, 105683. https://doi.org/https://doi.org/10.1016/j.envsoft.2023.105683.\n\n\nEngelen, J. van, G H P Oude Essink, and M F P Bierkens. 2022. “Sustainability of fresh groundwater resources in fifteen major deltas around the world.” Environmental Research Letters 17 (12): 125001. https://doi.org/10.1088/1748-9326/aca16c.\n\n\nEngelen, Joeri van, Marc F. P. Bierkens, Joost R. Delsman, and Gualbert H. P. Oude Essink. 2020. “Factors Determining the Natural Fresh-Salt Groundwater Distribution in Deltas.” Water Resources Research 57 (1). https://doi.org/10.1029/2020WR027290.\n\n\nEngelen, Joeri van, Jarno Verkaik, Jude King, Eman R. Nofal, Marc F. P. Bierkens, and Gualbert H. P. Oude Essink. 2019. “A three-dimensional palaeohydrogeological reconstruction of the groundwater salinity distribution in the Nile Delta Aquifer.” Hydrology and Earth System Sciences 23: 5175–98. https://doi.org/10.5194/hess-2019-151.\n\n\nKing, Jude, Tobias Mulder, Gualbert Oude Essink, and Marc F. P. Bierkens. 2021. “Joint estimation of groundwater salinity and hydrogeological parameters using variable-density groundwater flow, salt transport modelling and airborne electromagnetic surveys.” Advances in Water Resources 160 (December): 104118. https://doi.org/10.1016/j.advwatres.2021.104118.\n\n\nSeibert, Stephan L., Janek Greskowiak, Friederike Bungenstock, Holger Freund, Martina Karle, Rena Meyer, Gualbert H. P. Oude Essink, Joeri van Engelen, and Gudrun Massmann. 2023. “Paleo-Hydrogeological Modeling to Understand Present-Day Groundwater Salinities in a Low-Lying Coastal Groundwater System (Northwestern Germany).” Water Resources Research 59 (4): 1–24. https://doi.org/https://doi.org/10.1029/2022WR033151.\n\n\nThomas, Ariel T., Aaron Micallef, Shuangmin Duan, and Zhihui Zou. 2023. “Characteristics and Controls of an Offshore Freshened Groundwater System in the Shengsi Region, East China Sea.” Frontiers in Earth Science 11. https://doi.org/10.3389/feart.2023.1198215."
  },
  {
    "objectID": "coupler_ribamod_technical.html",
    "href": "coupler_ribamod_technical.html",
    "title": "Technical Reference",
    "section": "",
    "text": "This document describes how Ribasim and MODFLOW6 are coupled. It is intended for groundwater modellers, who need to know which variables are exchanged between computational kernels and at which moment. For details of the inner workings of the code, we refer to the docstrings in the code.\nThe following sequence diagram show the current sequential coupling scheme for a single MODFLOW 6 stress period.\nsequenceDiagram\n    autonumber\n    Ribasim -&gt;&gt; MODFLOW6: exchange stage [T-1]\n    Note over MODFLOW6: solve T\n    MODFLOW6 -&gt;&gt; Ribasim: RIV flux [T-1]\n    Note over Ribasim: solve T",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#modflow6-to-ribasim",
    "href": "coupler_ribamod_technical.html#modflow6-to-ribasim",
    "title": "Technical Reference",
    "section": "MODFLOW6 to Ribasim",
    "text": "MODFLOW6 to Ribasim\n\nFlows\nThe computed drainage and infiltration flows to and from River and Drainage packages are aggregated on basin level and set as:\n\ninfiltration: a flow from the surface water to the groundwater (positive).\ndrainage: a flow from the groundwater to the surface (positive).\n\nThese are set as the infiltration and drainage forcing on the Ribasim basins.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#ribasim-to-modflow-6",
    "href": "coupler_ribamod_technical.html#ribasim-to-modflow-6",
    "title": "Technical Reference",
    "section": "Ribasim to MODFLOW 6",
    "text": "Ribasim to MODFLOW 6\n\nLevels\nRibasim sets the stage of River packages, and the drainage elevation of Drainage packages in MODFLOW6.\nThe levels of the basins are not set directly in MODFLOW6. The levels are interpolated using the “subgrid” functionality of Ribasim, which can be used to e.g. create sloping water levels within a single basin.\nFor simplicity of the coupling, the subgrid functionality is also used in case of a 1:1 basin-boundary coupling.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#modflow6",
    "href": "coupler_ribamod_technical.html#modflow6",
    "title": "Technical Reference",
    "section": "MODFLOW6",
    "text": "MODFLOW6\nNo specific files are required. The MODFLOW6 model must contain River or Drainage packages which represent the surface water.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#ribasim",
    "href": "coupler_ribamod_technical.html#ribasim",
    "title": "Technical Reference",
    "section": "Ribasim",
    "text": "Ribasim\nNo specific files are required. The Basin / Subgrid table must be defined. For preprocessing with primod, the metadata columns meta_x, meta_y must be included in this table to indicate the spatial location of each subgrid element.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#coupler",
    "href": "coupler_ribamod_technical.html#coupler",
    "title": "Technical Reference",
    "section": "Coupler",
    "text": "Coupler\nThese files provide the mappings from the MODFLOW boundary indices to the Ribasim basin indices. For actively coupled system (see below), it also includes subgrid indices.\nThe files are identified by the MODFLOW6 package name.\nNote that the exchange files are tab-separated and use 0-based indices. They also include a header.\n\nPassive coupling\n\n[package-name].tsv\nbasin_index     bound_index\n{basin_index0}  {bound_index0}\n{basin_index1}  {bound_index1}\n...\n\n\n\nActive coupling\n\n[package-name].tsv\nbasin_index     bound_index      subgrid_index\n{basin_index0}  {bound_index0}   {subgrid_index0}\n{basin_index1}  {bound_index1}   {subgrid_index1}\n...",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "coupler_ribamod_technical.html#active-versus-passive-coupling",
    "href": "coupler_ribamod_technical.html#active-versus-passive-coupling",
    "title": "Technical Reference",
    "section": "Active versus passive coupling",
    "text": "Active versus passive coupling\nIn coupling Ribasim to MODFLOW 6, we make a distinction between active and passive coupling.\nIn passive coupling, MODFLOW 6 computes drainage and infiltration flows. These are added to the water balance of the Ribasim basins. The water levels computed by Ribasim are not set back into MODFLOW 6. This type of coupling is convenient for boundaries that show little variation in terms of drainage elevation over time (e.g. surface runoff, or ditches with negligible water depth). A passive coupling requires little in terms of parametrization of the Ribasim model: all flows are simply added as a sort of “lateral” flow into the basin.\nIn the active coupling, Ribasim does set the water levels of the MODFLOW 6 model.\nThe passive coupling should generally only be applied to coupling to Drainage packages, not River packages: in case of “over-infiltration”, the water levels in Ribasim will drop, potentially resulting in a dry basin. However, since the water levels are not set in MODFLOW 6, no feedback can occur, and the MODFLOW 6 model will keep infiltrating water that is not available. This creates a discrepancy between the water balances of both models.\nIn the active coupling, large infiltration flows would result in lower water levels, and infiltration stops when the basin dries up and the River stage reaches the bed elevation.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Technical Reference"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html",
    "href": "tutorial_Abbeyfeale.html",
    "title": "Abbeyfeale",
    "section": "",
    "text": "In this tutorial, you will learn the following:\n\nBasic usage of QGIS\nDraw a cross-section in the iMOD QGIS plugin\nView time series in the iMOD QGIS plugin\nRun a Python script in a shell",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html#description",
    "href": "tutorial_Abbeyfeale.html#description",
    "title": "Abbeyfeale",
    "section": "",
    "text": "In this tutorial, you will learn the following:\n\nBasic usage of QGIS\nDraw a cross-section in the iMOD QGIS plugin\nView time series in the iMOD QGIS plugin\nRun a Python script in a shell",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html#objective",
    "href": "tutorial_Abbeyfeale.html#objective",
    "title": "Abbeyfeale",
    "section": "Objective",
    "text": "Objective\nIn this Tutorial you learn the basics of iMOD-Suite. Therefore, we load and analyze a few file types. The files describe geohydrologic datasets for an area in the town of Abbeyfeale, Ireland. For this area we will develop a simple groundwater model using Python. Therefore, we start a command prompt for Python. From that command prompt you will run 7 prepared Python scripts. Each script handles a single step in the MODFLOW 6 modelling process: the preprocessing of basic data, the creation of MODFLOW 6 input files, running of the MODFLOW6 model and analyzing the results. The files created with each step are analyzed in QGIS.",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html#introduction-schematization-ground-water-model-abbeyfeale",
    "href": "tutorial_Abbeyfeale.html#introduction-schematization-ground-water-model-abbeyfeale",
    "title": "Abbeyfeale",
    "section": "Introduction: schematization ground water model Abbeyfeale",
    "text": "Introduction: schematization ground water model Abbeyfeale\nAbbeyfeale is a historic market town in the County Limerick, Ireland. The local authorities are worried about the effects of drier summers on groundwater levels. A simple groundwater model can provide them with a quantification of the expected groundwater level decline. Geology: much of Ireland can be considered as relatively glacial subsoil (typically &lt; 15 m thick) overlying very hard old fractured rock. For basic models this can be represented as one layer for the subsoil and one layer for bedrock.\n\n\n\n\n\n\nFigure 1: Village of Abbeyfeale and the components of the simplified Abbeyfeale model",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html#getting-started",
    "href": "tutorial_Abbeyfeale.html#getting-started",
    "title": "Abbeyfeale",
    "section": "Getting Started",
    "text": "Getting Started\n\nLaunch QGIS from your START menu, your desktop or click on …\\QGIS3.24.0\\bin\\qgis-bin.exe.\n\n\n\nIntermezzo QGIS language Perhaps your QGIS was installed in another language than English. Because the Tutorial refers to the English version, let’s change than to English.\n\nFrom the main menu click on Settings and select Options. (e.g. in Dutch Extra and Opties)\nIn the new window go to the General section on the left.\nFrom the drop-down menu “User interface translation” select American English and click on OK.\nClose QGIS and open it again to activate your language change.\n\n\n\nWe start with the creation of a new QGIS project.\n\nFrom the main menu click on Project and select New.\n\nFor navigation purposes, let us load the universal topography of Open Street Map (OSM).\n\nCheck on the left site if the panel “Browser” is available. If not, select View from the main menu, go to Panels and select Browser Panel.\nThe Browser panel contains the group XYZ Tiles. From that group double click on the item OpenStreetMap. This layer is now added to the panel Layers. To display this dataset an internet connection is needed. So if that is the situation, you will see the world map in the display.\n\nThe data we use in this part of the training is from Ireland, so next we select the appropriate projection. (In case you missed the download instructions for the Tutorial data, visit the start page iMOD Suite Tutorial).\n\n\nFrom the main menu click on Project and select Properties.\nIn the Properties window select the category CRS, search for “EPSG:2157” and you find “IRENET95 / Irish Transverse Mercator”. Select this option and click the Apply button, followed by the OK button to close the window.\n\nLet us now open a series of basic files in QGIS. We start with a digital elevation map.\n\nGo to Layer in the main menu, select Add Layer and pick the option Add Raster Layer.\nIn the section Source click on the  button and select the file “…\\iMOD-Suite-Tutorial_01\\data\\1-external\\topography\\Abbeyfeale DTM.tif”. GeoTIFF is a common file format.\nClick the Add button and the layer is added to the panel Layers.\nClick Close to leave the window.\nIn the panel Layers select the layer “Abbeyfeale DTM” and click the  button to zoom in to the layer.\n\nWe see the contours of a river, but the legend is gray only by default. Let’s change that.\n\nDouble click on the layer “Abbeyfeale DTM”. The window “Layer Properties” opens.\nSelect the group Symbology.\nFrom the dropdown menu Render Type select the type Singleband pseudocolor.\nBe sure a Color Ramp is selected as well.\nMake sure the dropdown menu Interpolation shows Linear and the dropdown menu Mode shows Continuous.\nClick Apply to change the colors and OK to close the window.\nYou can zoom in and out with the scroll button on your mouse or navigate with the buttons in the main menu: \n\nYour screen might look like Figure 2\n\n\n\n\n\n\nFigure 2: DTM in QGIS with the topography of OpenStreetMap Cross as background\n\n\n\nLet us save this project to be able to return to is later or in case of a crash of QGIS.\n\nGo to Project in the main menu, select Save As and select a folder and a file name for your project, e.g. “…\\iMOD-Suite-Tutorial_01\\tutorial1.qgz”\n\nDo you like to see the values of the DTM under you mouse? You need a QGIS plugin “Value Tool”. Many additional helpful tools are available as QGIS plugin, just like the Deltares iMOD Plugin.\n\nGo to Plugins from the main menu and select Manage and Install Plugins…  and a window opens.\nOn the left, select the group All to see all available plugins.\nSearch for “iMOD” and see that the iMOD plugin is successfully installed.\nCheck if version 0.2.3 is installed. If not, click the button to Upgrade the iMOD Plugin.\nSearch for “Value Tool”, install it and Close the Plugins window.\n\n\n\n\n\n\n\n\n\nFigure 3: iMOD plugin toolbar\n\n\n\nThe tool is now visible as a panel on the left and as the Value Tool button () in a panel on the top of QGIS.\n\nHover over the DTM and in the “Value Tool” panel you see the value at your mouse location.\n\n\n\n\n\n\n\nFigure 4: Example panel Value Tool\n\n\n\nNext step is to load a polygon file representing the recharge zones in the project area.\n\nGo to Layer in the main menu, select Add Layer and pick the option Add Vector Layer.\nIn the section Source click on the  button and select the file “…\\iMOD-Suite-Tutorial_01\\data\\1-external\\recharge\\clipped_recharge.shp”. The ESRI Shapefile is a common file format.\nClick the Add button and the layer is added to the panel Layers.\nClick Close to leave the window.\n\nWe see the contours of zones with a single color. Let’s change that.\n\nDouble click on the layer “clipped_recharge”. The window “Layer Properties” opens.\nSelect the group Symbology.\nFrom the upper dropdown menu select Categorized.\nFrom the dropdown Value select RECH_MM_YR.\nFrom the dropdown Color ramp select Viridis.\nClick on the button Classify to create the legend.\nClick Apply to change the colors and OK to close the window.\n\nThere is also an ESRI Shapefile with the rivers in the project area. Feel free to download that file (“…\\iMOD-Suite-Tutorial_01\\data\\1-external\\rivers\\WATER_RivNetRoutes.shp”) in the same way.\nAfter loading raster and polygon layers, let us now load a point file with boreholes. This time, the file format (*.IPF) is not a common file standard but developed by Deltares because the file includes associated borelog information. We must load the IPF file with the iMOD plugin.\n\nOne of the QGIS toolbars is the iMOD Toolbar. There you find al the iMOD plugin tools. Click on the Open IPF button () and a window will open.\nClick on the  button and select the IPF “…\\iMOD-Suite-Tutorial_01\\data\\1-external\\boreholes\\BOREHOLES.IPF”.\nClick the Add button and the IPF file is added in the panel Layers.\n\nNOTE: If the points appear to be somewhere else on the map, e.g. Africa, make sure both your project and your layer have the correct CRS (EPSG:2157).\n\nCheck if the project CRS on the lower right corner still is . Otherwise double click this area and change the EPSG.\nCheck if the layer CSR is correct and therefor double click on the BOREHOLES layer.\nIn the window Layer Properties go to the section Source.\nIn the dropdown menu “Assigned Coordinate Reference System (CRS)” select EPSG:2157.\n\n\nRight-click layer BOREHOLES in the Layers panel and click “Show labels”. This will label the points with the borelog identifier.\n\nThe bore log for each borehole can only be displayed in a cross-section. Therefore, we activate the iMOD cross-section tool.\n\nOn the iMOD Toolbar select the Cross section button () to start the iMOD Cross Section tool. In the empty cross-section we can add a selection of (geological) layers. For now, we only select the boreholes.\nOn the iMOD Toolbar click on the button Select location and draw your cross-section line from north to south following the 6 central borehole locations. Add points to the line with your left mouse button and close the line with the right button. You can remove and redraw the line by clicking the Select location button again.\nIn the field Search buffer increase the buffer along the line to 1000m. Now a yellow shade is visible around your line selecting all the available points within.\nFrom the dropdown menu on the left of this toolbar, select the layer BOREHOLES if not selected already. From the borelog we want to plot the variable LITHOLOGY, which is already selected in the Variable dropdown menu (it is the only available variable).\nClick the button Add to add this layer to the cross-section manager below.\nClick the button Plot to draw this layer in the cross section.\n\nTo complete the cross section, let us also add the digital elevation map to the cross-section manager.\n\nFrom the dropdown menu now select the layer Abbeyfeale DTM. We do not need to select a Variable\nClick the button Add to add this layer to the cross-section manager below.\nClick the button Plot to draw both layers in the cross section.\n\nYour screen might look like Figure 5 although the colors are different than in your screen. Feel free to use the column Symbology to change the legend.\nNOTE: If no lines appear on your screen, make sure you have set your project CRS to EPSG:2157 (see earlier step).\n\n\n\n\n\n\nFigure 5: Cross section with borelogs and DEM\n\n\n\nFor now, we leave QGIS and the iMOD Plugin to return later.\n\nSave your QGIS project (Ctrl+S) and keep the QGIS application open.",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "tutorial_Abbeyfeale.html#imod-python",
    "href": "tutorial_Abbeyfeale.html#imod-python",
    "title": "Abbeyfeale",
    "section": "iMOD Python",
    "text": "iMOD Python\nThis is the moment where we start with Python. With the help of the iMOD Python package you will create a simple MODFLOW6 model and run it.\n\nAll input we use for this simple model is available in your tutorial folder “…\\iMOD-Suite-Tutorial_01\\data\\1-external\\..”“. There you find the spatial data we loaded to QGIS, and there is a CSV file containing all single parameter values: “parameters.csv”.\nAll steps, from the preparation of the model input to visualization of the results, are available in separate Python scripts. You find the scripts for each phase in the folder and subfolders within “..\\iMOD-Suite-Tutorial_01\\src\\..”\n\n\nClick on the windows START button and type Deltaforge prompt. Click on the app and a black DOS window will start. [for Python experts: with this prompt a python environment is activated containing the iMOD python package as well as Snakemake (workflow manager)].\n\nFrom this DOS window we will run the different python scripts (*.py files). For the scripts to work properly, we need to navigate to the correct folder location.\n\nIn the DOS window type the letter of the drive you work on (e.g. C: or D:) and press ENTER.\nNavigate to the correct main tutorial folder with CD (change directory). E.g. “CD c:\\imod\\training\\iMOD-Suite-Tutorial_01” and press ENTER.\n\nTIP: After copying your path, you can paste your path in the prompt window with CTRL+V.\nNow we run 4 scripts to convert basic data into an interim model format (NetCDF), ready to create MODFLOW6 input files. \n\nScript 1 – template\n\nThis script opens the DTM file, uses its extent for the model boundary and sets the cell size to 40m.\n\nIn the Deltaforge prompt type the command: Python src\\1-prepare\\1-create-template-grid.py and press ENTER.\n\n\nResults 1: The result is a raster file (NetCDF format) describing the mask of our model (extent and cell size) as well as our DTM scaled up to the size of the model mask.\n\nOptional step. Load the topography_raster.nc file into QGIS. The file is in the folder “…\\iMOD-Suite-Tutorial_01\\data\\2-interim”.\n\n\nScript 2 – River\n\nThis script opens a shape file with river elements. It rasterizes it to the project cell size and adds a default river depth (1 m) and bottom resistance.\n\nIn the Deltaforge prompt type the command: Python src\\1-prepare\\2-create-river-system.py and press ENTER.\n\nResults 2: The result is a raster file (NetCDF format) for the river data, containing data for the parameters Stage, Bottom and Conductance.\n\nLoad the file “..\\iMOD-Suite-Tutorial_01\\data\\2-interim\\river_raster.nc” into QGIS via the menu Layer &gt; Add Layer &gt; Add Raster Layer. From the interim window you see that the NC files contains 3 river parameters.\nClick on the button Add Layers and click Close to close the Data Source Manager.\n\n\nScript 3 – Recharge\n\nThis script opens the shape file with recharge zones (polygons) containing the recharge in mm per year. The recharge zones are rasterized to the project extent and cell size. Finally the script adds a seasonal forcing (sine function) resulting in a time series of daily recharge values for 1 year.\n\nIn the Deltaforge prompt type the command: Python src\\1-prepare\\3-create-recharge.py and press ENTER.\n\nResults 3: The result is a mesh file (NetCDF format) for the recharge data, containing data for 365 days. This NC file must be loaded as mesh in stead of a raster.\n\nFrom the menu Layer &gt; Add layer &gt; Add Mesh Layer… load the file “…\\iMOD-Suite-Tutorial_01\\data\\2-interim\\recharge_mesh.nc” into QGIS. From the panel Layer you can see that the file is a timeseries because a small clock symbol is visible .\n\nThere are 2 ways to visualize this recharge over time:\n\nanimation over time;\ntimeseries at location.\n\nLet’s now activate the panels for both methods.\n\nFor the animation over time, activate the Temporal Control Panel with the clock button  on the Map Navigation Toolbar ().\nFor timeseries at location activate the Timeseries panel with the Timeseries button ( ) on the iMOD Toolbar.\n\nYour display should look similar with Figure 6, except for the red line below.\n\nIn the Temporal Controller panel click the green play button (). Navigation buttons appear.\nIncrease the Step from 1 to 14 days and start the animation with a click on the Play button ().\nIn the iMOD time series panel be sure the layer RECHARGE_MESH is loaded. The mesh only contains a single variable: Recharge.\nClick the button Select Points, your mouse changes into a . Be sure Update on Selection is checked and hover over the mesh. The graph shows the timeseries at the location of your mouse.\nDeselect the checkbox Update on Selection.\nClick the button Select Points (your mouse becomes a  and with the left mouse button select 3 points ad random.\nFinally click the Plot button and the 3 timeseries are added to the chart. Colors can be changed.\n\n\n\n\n\n\n\nFigure 6: Recharge data analysed in the Temporal Controller (QGIS) and the Time Series Plot tool (iMOD)\n\n\n\n\nScript 4 – Geohydrology\n\nThis script reads default parameter values from the file “parameters.csv” in order to create a NetCDF file with top and bottom of 3 layers including the geohydraulic parameters. The default values are: \n\nParameter values\n\n\nParameter\nValue\nQuantity\nDescription\n\n\n\n\nK_tz\n5.9\nm/d\nPermeability Transition Zone\n\n\nK_sb\n0.02\nm/d\nPermeability Shallow Bed rock\n\n\nK_db\n0.014\nm/d\nPermeability Deep Bed rock\n\n\nD_tz\n1\nm\nThickness transition zone\n\n\nD_sb\n5\nm\nThickness shallow bed rock zone\n\n\nD_db\n50\nm\nThickness deep bed rock zone\n\n\n\n\nIn the Deltaforge prompt type the command: Python src\\1-prepare\\4-create-hydrogeology.py and press ENTER.\n\nResults 4: The result is a mesh file (NetCDF format) for the geohydrological data. This NC file must be loaded as mesh instead of a raster.\n\nFrom the menu Layer &gt; Add layer &gt; Add Mesh layer… load the file “…\\iMOD-Suite-Tutorial_01\\data\\2-interim\\hydrogeology_mesh.nc” into QGIS.\nDouble click on the layer name “hydrogeology_mesh” and the window Layer Properties will open.\nClick on the group Source on the left, and on the right you see all Available Datasets in this single mesh.\n\nLet’s create a cross-section with the permeability plot within each layer.\n\nFirst, we must deactivate temporal control. Open the Temporal Control Panel again (), and turn off temporal navigation with the button .\nOn the iMOD Toolbar select the  button to start the iMOD Cross Section tool.\nIn the iMOD cross-section panel be sure the layer “hydrogeology_mesh” is selected. From the Variable dropdown select permeability and from the Layers dropdown select all layers.\nClick the button Add to add this item to the list of chart elements.\nClick on the button Select Location and draw a single line over the model area with your left mouse button. Close the line with your right mouse button.\nClick the button Plot and the geology along the line colored by permeability is draw in the chart.\n\nTIP: If you do not see any line, perhaps the axes are not defined well. To view all data, click you right mouse button in the figure and select the option “View All”. The alternative is to click on the small A symbol () in the lower left of the chart.\nYour screen might look like Figure 7. In case the default legend is not  you can change it.\n\nTo change the legend, click on the colored bar in the column symbology.\nIn the new window go the “Render type” menu and select Unique values and click Apply.\nUse the scroll button on your mouse to zoom in order to make the permeability of the thin first layer visible.\n\n\n\n\n\n\n\nFigure 7: Three model layers coloured by permeability in the iMOD cross-section tool\n\n\n\n\nScript 5 – Create MODFLOW 6 input\n\nNow the input data for the model are available, it is time to convert the data into the standard MODFLOW6 format. For that conversion a function exists within iMOD Python. We prepared another python script for you to easily do the conversion by running the script in the Deltaforge prompt.\n[If you are interested in the content of the script, open it in your Python editor (e.g. Spyder) or a simple Text editor].\n\nIn the Deltaforge prompt type the command: Python src\\2-build\\5-build-model.py and press ENTER.\n\nThe result of the script is a folder with the standard MODFLOW 6 input.\n\nOptional step Visit the folder “…\\iMOD-Suite-Tutorial_01\\data\\3-input” with your file manager. There your find the file MFSIM.NAM. This is the main MODFLOW6 file with references to the other files and settings. The folder GWF_1 contains the model input and later the model results.\n\n\nScript 6 – Run the MODFLOW 6 model\n\niMOD Suite uses the official USGS version of MODFLOW 6. The executable is provided with the tutorial database and is available as “…\\iMOD-Suite-Tutorial_01\\bin\\mf6.exe”.\n\nIn the Deltaforge prompt type the command: Python src\\3-model\\6-run-model.py and press ENTER.\n\nYou can check the logfile of the model in order to see if it was run successful.\nOpen the file “…\\iMOD-Suite-Tutorial_01\\data\\3-input\\mf.sim.lst” in the Text Editor you prefer. Go to the end of the file and see the total run time of the model and a confirmation of a “normal termination of the simulation”.\nOpen the file “…\\iMOD-Suite-Tutorial_01\\data\\3-input\\gwf_1\\gwf_1.lst”. At the end of the file you see the Volume Budgets, the water balance for the last stress period.\n\n\nScript 7 - Convert the MODFLOW 6 results for QGIS\n\nThe standard output of MODFLOW6 cannot be loaded into QGIS. Therefore, iMOD Python contains a function to convert the output into NetCDF files.\n\nIn the Deltaforge prompt type the command: Python src\\3-model\\7-post-process-output.py and press ENTER.\n\nThe result of this script is a NetCDF file with the calculated head for 365 days.\n\nLoad the file “…\\iMOD-Suite-Tutorial_01\\data\\4-output\\hds_mesh.nc” into QGIS.\n\nBy default, the variable bottom_layer_1 is loaded. We will change the selected variable into Heads and pick a legend specific for plotting of time series.\n\nDouble click on the layer “hds_mesh” to open the Layer Properties window.\nSelect the group Source on the left and see that the mesh contains several datasets.\nSelect the group Symbology on the left and select the first tab Dataset (). Here we can select the group we want to plot, for now it is “head_layer_1”.\n\nClick on the icon () on the line for “head_layer_1” and change it into (). Click on Apply.\nSelect the second tab Contours ( ).\nSet the Min value on 40.00 and the Max value on 60.00 in order to see head changes over time.\nFrom the dropdown menu Color Ramp select Turbo and click on OK to close the window.\n\nNow we try to show an animation of the variation of calculated Heads over time and as timeseries.\n\nFor the animation over time, activate the Temporal Control Panel with the button () on the Map Navigation Toolbar.\nFrom you experience with this tool, try to start the animation with timestep of 14 days.\nFor timeseries at location activate the Timeseries panel with the Timeseries button () on the iMOD Toolbar.\nFrom you experience with this tool, select 3 points in the model area and plot the corresponding calculated Heads for layer 1.\n\n\n\n\n\n\n\nFigure 8: Calculated head with MODFLOW 6 on 3 points within the model area\n\n\n\nThe QGIS part of the tutorial ends here. You can save your QGIS project now.",
    "crumbs": [
      "Tutorials",
      "Abbeyfeale"
    ]
  },
  {
    "objectID": "coupler_ribamod_config.html",
    "href": "coupler_ribamod_config.html",
    "title": "Configuration",
    "section": "",
    "text": "The configuration file is necessary to describe the model and its dependencies. It is in the toml format and should have a .toml extension.\nNote that toml uses quote marks differently than python. Single quotes in toml ('') are interpreted similarly to how python would interpret a rawstring (r'' or r\"\"), whereas double quotes (\"\") are interpreted in a similar manner to regular strings in python (\"\" or ''). This matters for paths on Windows, for which we advice to use single quotes.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "coupler_ribamod_config.html#config-schema",
    "href": "coupler_ribamod_config.html#config-schema",
    "title": "Configuration",
    "section": "Config schema",
    "text": "Config schema\n\nlog_level\n\n\n\n\n\n\ndescription\nThis setting determines the severity and therefore the verbosity of the log messages.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\ndefault\nINFO\n\n\nenum\nDEBUG, INFO, WARNING, ERROR, CRITICAL\n\n\n\n\ntiming\n\n\n\n\n\n\ndescription\nSpecifies whether the coupling should be timed. This option requires the log level to at least include INFO.\n\n\ntype\nboolean\n\n\nrequired\nfalse\n\n\ndefault\nfalse\n\n\n\n\ndriver_type\n\n\n\n\n\n\ndescription\nSpecifies which driver should be used. Typically, this determines which hydrological kernels are coupled.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\nenum\nribamod\n\n\n\n\ndriver.kernels.modflow6\n\ndll\n\n\n\n\n\n\ndescription\nThe path to the MODFLOW 6 library.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\ndll_dep_dir\n\n\n\n\n\n\ndescription\nThe path to the dependencies of MODFLOW 6.\n\n\ntype\nstr\n\n\nrequired\nfalse\n\n\n\n\nwork_dir\n\n\n\n\n\n\ndescription\nThe working directory MODFLOW 6 expects. This is the directory where the simulation name file resides.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\n\ndriver.kernels.ribasim\n\ndll\n\n\n\n\n\n\ndescription\nThe path to the Ribasim library.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\ndll_dep_dir\n\n\n\n\n\n\ndescription\nThe path to the dependencies of Ribasim.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nconfig_file\n\n\n\n\n\n\ndescription\nThe path to the Ribasim config file.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\n\ndriver.coupling\n\nmf6_model\n\n\n\n\n\n\ndescription\nSpecifies the MODFLOW 6 model name to which Ribasim will be coupled.\n\n\ntype\nstr\n\n\nrequired\ntrue\n\n\n\n\nmf6_active_river_packages\n\n\n\n\n\n\ndescription\nSpecifies the active river packages of MODFLOW 6 that will be coupled together with the path to the mapping table.\n\n\ntype\ndict[str, str]\n\n\nrequired\ntrue\n\n\n\n\nmf6_passive_river_packages\n\n\n\n\n\n\ndescription\nSpecifies the passive river packages of MODFLOW 6 that will be coupled together with the path to the mapping table.\n\n\ntype\ndict[str, str]\n\n\nrequired\ntrue\n\n\n\n\nmf6_active_drainage_packages\n\n\n\n\n\n\ndescription\nSpecifies the active drainage packages of MODFLOW 6 that will be coupled together with the path to the mapping table.\n\n\ntype\ndict[str, str]\n\n\nrequired\ntrue\n\n\n\n\nmf6_passive_drainage_packages\n\n\n\n\n\n\ndescription\nSpecifies the passive drainage packages of MODFLOW 6 that will be coupled together with the path to the mapping table.\n\n\ntype\ndict[str, str]\n\n\nrequired\ntrue",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Configuration"
    ]
  },
  {
    "objectID": "primod_api/RibaMod.html",
    "href": "primod_api/RibaMod.html",
    "title": "RibaMod",
    "section": "",
    "text": "RibaMod(self, ribasim_model, mf6_simulation, coupling_list)\nCouple Ribasim and MODFLOW 6.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nribasim_model\nribasim.model\nThe Ribasim model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired\n\n\ncoupling_list\nSequence[RibaModDriverCoupling]\nOne entry per MODFLOW 6 model that should be coupled\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nwrite\nWrite Ribasim and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nRibaMod.write(directory, modflow6_dll, ribasim_dll, ribasim_dll_dependency, modflow6_write_kwargs=None)\nWrite Ribasim and Modflow 6 model with exchange files, as well as a .toml file which configures the iMOD Coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nRibaMod.write_toml(directory, coupling_dict, modflow6_dll, ribasim_dll, ribasim_dll_dependency)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired"
  },
  {
    "objectID": "primod_api/RibaMod.html#parameters",
    "href": "primod_api/RibaMod.html#parameters",
    "title": "RibaMod",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nribasim_model\nribasim.model\nThe Ribasim model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired\n\n\ncoupling_list\nSequence[RibaModDriverCoupling]\nOne entry per MODFLOW 6 model that should be coupled\nrequired"
  },
  {
    "objectID": "primod_api/RibaMod.html#methods",
    "href": "primod_api/RibaMod.html#methods",
    "title": "RibaMod",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nwrite\nWrite Ribasim and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nRibaMod.write(directory, modflow6_dll, ribasim_dll, ribasim_dll_dependency, modflow6_write_kwargs=None)\nWrite Ribasim and Modflow 6 model with exchange files, as well as a .toml file which configures the iMOD Coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nRibaMod.write_toml(directory, coupling_dict, modflow6_dll, ribasim_dll, ribasim_dll_dependency)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired"
  },
  {
    "objectID": "primod_api/RibaMetaMod.html",
    "href": "primod_api/RibaMetaMod.html",
    "title": "RibaMetaMod",
    "section": "",
    "text": "RibaMetaMod(self, ribasim_model, msw_model, mf6_simulation, coupling_list)\nCouple Ribasim, MetaSWAP and MODFLOW 6.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nribasim_model\nribasim.model\nThe Ribasim model that should be coupled.\nrequired\n\n\nmsw_model\nMetaSwapModel\nThe MetaSWAP model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired\n\n\ncoupling_list\nSequence[DriverCoupling]\nOne entry per MODFLOW 6 model that should be coupled\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nwrite\nWrite Ribasim, MetaSWAP and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nRibaMetaMod.write(directory, modflow6_dll, ribasim_dll, ribasim_dll_dependency, metaswap_dll, metaswap_dll_dependency, modflow6_write_kwargs=None)\nWrite Ribasim, MetaSWAP and Modflow 6 model with exchange files, as well as a .toml file which configures the iMOD Coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nRibaMetaMod.write_toml(directory, coupling_dict, modflow6_dll, metaswap_dll, metaswap_dll_dependency, ribasim_dll, ribasim_dll_dependency)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired"
  },
  {
    "objectID": "primod_api/RibaMetaMod.html#parameters",
    "href": "primod_api/RibaMetaMod.html#parameters",
    "title": "RibaMetaMod",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nribasim_model\nribasim.model\nThe Ribasim model that should be coupled.\nrequired\n\n\nmsw_model\nMetaSwapModel\nThe MetaSWAP model that should be coupled.\nrequired\n\n\nmf6_simulation\nModflow6Simulation\nThe Modflow6 simulation that should be coupled.\nrequired\n\n\ncoupling_list\nSequence[DriverCoupling]\nOne entry per MODFLOW 6 model that should be coupled\nrequired"
  },
  {
    "objectID": "primod_api/RibaMetaMod.html#methods",
    "href": "primod_api/RibaMetaMod.html#methods",
    "title": "RibaMetaMod",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nwrite\nWrite Ribasim, MetaSWAP and Modflow 6 model with exchange files, as well as a\n\n\nwrite_toml\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\nRibaMetaMod.write(directory, modflow6_dll, ribasim_dll, ribasim_dll_dependency, metaswap_dll, metaswap_dll_dependency, modflow6_write_kwargs=None)\nWrite Ribasim, MetaSWAP and Modflow 6 model with exchange files, as well as a .toml file which configures the iMOD Coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the coupled models\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired\n\n\nmodflow6_write_kwargs\ndict[str, Any] | None\nOptional dictionary with keyword arguments for the writing of Modflow6 models. You can use this for example to turn off the validation at writing (validation=False) or to write text files (binary=False)\nNone\n\n\n\n\n\n\n\nRibaMetaMod.write_toml(directory, coupling_dict, modflow6_dll, metaswap_dll, metaswap_dll_dependency, ribasim_dll, ribasim_dll_dependency)\nWrite .toml file which configures the imod coupler run.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndirectory\nstr | Path\nDirectory in which to write the .toml file.\nrequired\n\n\nmodflow6_dll\nstr | Path\nPath to modflow6 .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll\nstr | Path\nPath to metaswap .dll. You can obtain this library by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nmetaswap_dll_dependency\nstr | Path\nDirectory with metaswap .dll dependencies. Directory should contain: [fmpich2.dll, mpich2mpi.dll, mpich2nemesis.dll, TRANSOL.dll]. You can obtain these by downloading the last iMOD5 release &lt;https://oss.deltares.nl/web/imod/download-imod5&gt;_\nrequired\n\n\nribasim_dll\nstr | Path\nPath to ribasim .dll.\nrequired\n\n\nribasim_dll_dependency\nstr | Path\nDirectory with ribasim .dll dependencies.\nrequired"
  },
  {
    "objectID": "primod_api/RibaModActiveDriverCoupling.html",
    "href": "primod_api/RibaModActiveDriverCoupling.html",
    "title": "RibaModActiveDriverCoupling",
    "section": "",
    "text": "RibaModActiveDriverCoupling\nRibaModActiveDriverCoupling()"
  },
  {
    "objectID": "primod_api/RibaModPassiveDriverCoupling.html",
    "href": "primod_api/RibaModPassiveDriverCoupling.html",
    "title": "RibaModPassiveDriverCoupling",
    "section": "",
    "text": "RibaModPassiveDriverCoupling\nRibaModPassiveDriverCoupling()"
  },
  {
    "objectID": "3dviewer_user_manual.html",
    "href": "3dviewer_user_manual.html",
    "title": "3D Viewer User Manual",
    "section": "",
    "text": "The iMOD 3D Viewer is a viewer for grids and datasets. In this manual we consider a grid to be a region of space that is subdivided into cells. A grid input file contains the geometry of these cells, often as a list of vertex coordinates and cell-vertex connections.\nA dataset is a list of values associated to the cells or vertices of a grid. A dataset can contain for example a porosity or hydraulic head for every cell in the grid. A dataset can have an associated time. In an input file, a dataset is usually just a list of values where value number N is associated to cell number N in the grid.\nThe iMOD 3D Viewer is used for viewing the grids in 3D, and for plotting datasets on top of the grids using a color legend. To gain more insight in the data, the color legend can be edited, and the values of individual cells can be inspected. Slider tools allow viewing the inside of 3D bodies.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#introduction",
    "href": "3dviewer_user_manual.html#introduction",
    "title": "3D Viewer User Manual",
    "section": "",
    "text": "The iMOD 3D Viewer is a viewer for grids and datasets. In this manual we consider a grid to be a region of space that is subdivided into cells. A grid input file contains the geometry of these cells, often as a list of vertex coordinates and cell-vertex connections.\nA dataset is a list of values associated to the cells or vertices of a grid. A dataset can contain for example a porosity or hydraulic head for every cell in the grid. A dataset can have an associated time. In an input file, a dataset is usually just a list of values where value number N is associated to cell number N in the grid.\nThe iMOD 3D Viewer is used for viewing the grids in 3D, and for plotting datasets on top of the grids using a color legend. To gain more insight in the data, the color legend can be edited, and the values of individual cells can be inspected. Slider tools allow viewing the inside of 3D bodies.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#relationship-with-qgis",
    "href": "3dviewer_user_manual.html#relationship-with-qgis",
    "title": "3D Viewer User Manual",
    "section": "Relationship with QGIS",
    "text": "Relationship with QGIS\nThe iMOD 3D Viewer can be used as a standalone or in combination with the iMOD QGIS plugin. From this plugin, the viewer can be launched, and grids can be loaded into it. Using the QGIS plugin is currently the only way to create fence diagrams in the viewer. Also, the QGIS plugin allows for specifying a bounding box for UGRID files. When this option is used, the viewer only loads the part of the grid in an UGRID file that is inside the bounding box.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#features",
    "href": "3dviewer_user_manual.html#features",
    "title": "3D Viewer User Manual",
    "section": "Features",
    "text": "Features\nThe iMOD 3D Viewer supports visualizing grids in the following file formats:\n\nIDF files. Both equidistant and non-equidistant UGRIDs are supported.\nUGRID files. the iMOD 3D Viewer can read UGRIDs that contain exclusively 2D elements such as triangles, quadrilaterals and other polygons. 1D and 3D elements are not supported. In some cases, a layered grid can be encoded as a 2D grid with certain properties. See the Layered UGRID chapter for more detail.\nGrb.disu files. These files are written by modflow and contain an unstructured layered grid used in a modflow simulation. Only the grid can be loaded; datasets cannot be loaded (yet)\n\nThe iMOD 3D Viewer also supports viewing some non-grid objects.\n\nIPF files. These files contain tables of numeric and text data, separated by commas and whitespace, and with a small file header containing the column names. IPF files can be rendered as a collection of points (the user chooses which columns to use for x, y, and z coordinates) or vertical cylinders (the user chooses which columns to use for x, y, top and bottom). The intended use of this is to visualize for example borehole locations, observations wells, production wells or well filters.\nShapefiles. These can be used to add geographical context, by adding rivers or province boundaries to the view. Only vector-type shapefiles can be show, and only the linestrings, polygons and multipolygons in it are imported.\n\nThe iMOD 3D Viewer can show fence diagrams. This only works when used in combination with the iMOD QGIS plugin",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#general-workings",
    "href": "3dviewer_user_manual.html#general-workings",
    "title": "3D Viewer User Manual",
    "section": "General Workings",
    "text": "General Workings\n\niMOD 3D Viewer solutions and autosave file\n\n\n\n\n\n\nFigure 1: File menu options for saving and loading projects.\n\n\n\nThe list of open files, along with the chosen legends and IPF column mappings, can be saved into an iMOD 3D Viewer solution file. To do this, open the file menu and choose “save” or “save as”.\nThe resulting file can be opened with the “open project file” option.\nAn autosave file is automatically created or updated when opening a grid, overlay or IPF file, or when editing a legend or an IPF column mapping. This autosave file therefore reflects the state of the viewer more or less recently and is stored in the appdata directory, most likely this:\nC:\\\\Users\\\\yourname\\\\AppData\\\\Roaming\\\\IMOD6\n\n\nThe explorer sidebar\nWhen a file is opened- for example a file containing a grid- then automatically entries are added to the sidebar of the application. These entries represent the grids and datasets in the file and allow you to interact with them (Figure 2).\n\n\n\n\n\n\nFigure 2: The explorer sidebar shows the objects that are available for viewing as a tree structure\n\n\n\nThe explorer sidebar shows the objects that are available for viewing as a tree structure\nIn the example in Figure 2, the content of the explorer sidebar is shown. In this example, the sidebar contains a shapefile (a map of the waterboards that is used for orientation of the user only); and IPF file containing boreholes, and a layered UGRID file.\nAll The shapefile and the grid are shown in the viewer, which is why they are bold. The IPF is not shown in the viewer and is not bold. The shapefile and the IPF file are each only one line in the sidebar. The layered UGRID is a tree-node that can be expanded or collapsed as desired. For all three of these, a context menu will appear when a right mouse click is performed on it.\nThe layered UGRID root node is called “Dommel-test.nc”. this represents the whole UGRID file. This node can be expanded to show the following nodes:\n\na grouping node called “All Layers”. This node has no context menu and is never bold.\n\nan entry for each layer. They have the same name as the inputfile, with the suffix “_layer_X” where X is the layer number. Layers are shown in boldface when the layer is shown in the viewer. A context menu appears on a right mouse click on this node.\n\nthe available datasets per layer. In this case, “bottom_layer_x”, “thickness_layer_x”, “top_layer_x”, “Elevation (cell centre)_layer_x”. These datasets are shown in bold if they are visible in the viewer. Only one dataset per layer can be shown in the viewer. A dataset is shown in the viewer when double-clicked with the left mouse button.\n\n\nA grouping node called “Layered datasets”. This node has no context menu and is never bold.\n\nAn entry for layered datasets. These entries are used to synchronise the dataset that is shown for all the layers of the grid. This means that if we double-click the layered dataset “bottom”, then grid layer 1 (if visible) will show dataset “bottom_layer_1”; grid layer N will show “bottom_layer _N” etcetera. A context menu appears when doing a right mouse click on this node, allowing you to set a legend for all layers at once.\n\n\n\n\nLoading and unloading objects\nObjects can be added to the explorer\n\nThrough the QGIS plugin ( see the manual of that)\nBy opening the “data”menu and selecting “open grid” (for UGRID, IPF,or grb.disu files); “open overlay” ( for shapefiles) ; or “open point data” (for IPF files)\n\nWhen the second method is used, then the objects appear in the sidebar but not in the viewer. They have to be loaded into the viewer in a second step. To do that, select the objects you want to see in the sidebar and click the “draw selected layers” button. () (Figure 3).\n\n\n\n\n\n\nFigure 3: In order to visualize a grid in the viewer, select the grid and then press the green button.\n\n\n\nWhen an object is visualized in the viewer, its name appears in boldface in the explorer.\nWhen the “draw selected layers” button () is pressed, all object that are not selected are unloaded from the viewer and are no longer bold, except if they are locked.\n\n\nHow to visualize data on a grid\nIn order to visualize a dataset on a grid, first visualize the grid itself. Then double-click on one of the datasets in the explorer.\nOnce visualized, the dataset will appear in boldface in the explorer (Figure 4).\n\n\n\n\n\n\nFigure 4: The dataset 'water level' is visualized on the grid and is marked in bold in the explorer.\n\n\n\nCurrently, only datasets that hold scalar values associated to cells can be shown.\n\n\nLocking mechanism\nTop level nodes can be “locked” and grid layer nodes can be\nWhen a node is “locked”, the object it represents is no longer automatically unloaded when the “draw selected layers” () is pressed. It can still be moved or deleted through the context menu.\nTo lock a node, select it and press L (lowercase or uppercase) on the keyboard. A padlock icon now appears next to it (Figure 5).\nTo unlock it, press O (lowercase or uppercase) on the keyboard. Now an open padlock icon appears.\n\n\n\n\n\n\nFigure 5: The padlock icon shows if a node is locked or unlocked\n\n\n\n\n\nMoving objects in the treeview\nTop level nodes can be moved up and down the treeview, allowing you to order the objects as you see fit.\nTo move an item in the treeview, select it with the mouse and then press u (up) or d (down) to move the object.\n\n\nHow to delete an object\nTo delete an object (grid, overlay or IPF cylinders) , right click on it in the explorer. Now a context menu appears. Choose the option “delete” to have the grid removed from the explorer. If you want to stop visualization of the grid without removing it from the explorer, use the redraw button instead. In the explorer, select the grids you want to be visualized, and make sure the grids you want to be unloaded are unselected. Then press redraw.\n\n\nUsing the time-slider\nSome datasets vary through time. The iMOD 3D Viewer currently supports 2 cases:\n\nthe dataset does not have a time associated. In this case it is called “invariant” in the UI\nthe dataset has one or more sets of values, each one with a specific point in time associated ( so not an interval!). This time must be an actual date-time; we don’t support dimensionless time or unreferenced time.\n\n\n\n\n\n\n\nFigure 6: Tools and texts related to time in the UI\n\n\n\nFigure 6 shows the location of tools and texts in the UI that help the user orientate in and step through the time dimension of datasets. First note the time displayed in the top toolbar (1). This is the “viewer time”, the time the viewer is currently trying to display. Since the time discretization can be different per dataset and we can show different datasets and grids simultaneously, it is not guaranteed that all datasets currently in the viewer can be shown for this specific time! Hence, in the sidebar it is shown at what time the datasets are actually displayed (2).\nThe viewer time can be selected using the slider. It varies over the temporal range of all displayed datasets combined- this means that when you display another dataset, the range of the slider could change. The scaling of the slider is based on the time indexes, not on the time value itself. This means that if you have dataset values for 3 times, the slider will be divided in 2 equally sized intervals- and you would be able to select the beginning, halfway and the end of the slider, regardless of how much actual time there is between these 3 times.\nWhen there are many times available, the resolution of the slider becomes very fine and it can then be more convenient to use the “next time”and “previous time” buttons, which increment and decrement the slider one position. There is also a “rewind” button to move the slider to its lowest value.\nFinally, it is possible to animate plots using a “play” button. This moves the slider one step forward per second, or slower if updating the plot takes longer. The animation can be stopped using the “stop” button.\nThe decision on what time to display for each dataset is taken as follows (see Figure 7):\n\ninvariant datasets are shown regardless of the viewer time’\nif a dataset has a value at the viewer time this value is shown\nif it has no value at the viewer time but it has a value earlier than the viewer time then this value is shown\nif it has no value at the viewer time and no value earlier than the viewer time then the first time after the viewer time is shown.\n\n\n\n\n\n\n\nFigure 7: Times displayed for different dataset for a given viewer time (the vertical line). The blue dots indicate the times at which a dataset has values. The red dots indicate the values displayed.\n\n\n\n\n\nProperty windows\nBy right-clicking on grids or datasets in the explorer, a context menu appears. In it, there is usually a “properties” option which opens a form displaying some of the properties of the object- and sometimes it allows setting some properties as well. Here are a few examples:\n\n\n\n\n\n\nFigure 8: Property windows, from left to right for a grid, a layered grid and a dataset",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#how-to-use-the-viewer",
    "href": "3dviewer_user_manual.html#how-to-use-the-viewer",
    "title": "3D Viewer User Manual",
    "section": "How to use the viewer",
    "text": "How to use the viewer\nThe following controls work if the mouse pointer is in the viewer area:\nSpinning the mouse wheel forward: zooms in\nSpinning the mouse wheel backward: zooms out\nHold shift key, while pressing the right mouse key, and move the mouse: moves the camera horizontally, corresponding to the mouse movement\nHold ctrl key, while pressing the right mouse key, and move the mouse: this rotates the camera around its lens.\nClicking on a grid: this selects or unselects the grid. When a grid is selected, its name appears in red in the explorer. Only one grid can be selected at any time. A grid must be selected in order to change its legend, or to inspect its cells values. This way of selecting a grid can be slow for larger grids. Grids can also be selected by using the context menu of the grid in the sidebar. It has an option Select in viewer.\nPressing the “zoom to extent” button (  ) in the toolbar: zooms out until all the grids that are visualized in the current viewer fit on the screen.\nIn the 3D viewer the following also works:\nHold the right mouse button while moving the mouse: this moves the camera in a trajectory around the grid. The direction and length of the mouse movement determine the amount of camera movement.\n\n\n\n\n\n\nFigure 9: Some of the viewer controls are also implemented by buttons.\n\n\n\nUsing the toolbar buttons to control the viewer As shown in Figure 9, there are also buttons in the toolbar to control the viewer. From left to right in this figure, the buttons do the following\n\nzoom to extent. use this button to get a top view of the grid, zoomed out so that all of it is visible\nright(+x). use this button to position the camera so that we look in the +x direction, zoomed out so that the whole y and z range of the grid is visible.\nleft(-x). use this button to position the camera so that we look in the -x direction, zoomed out so that the whole y and z range of the grid is visible.\nfront(-y). use this button to position the camera so that we look in the -y direction, zoomed out so that the whole x and z range of the grid is visible.\nback(+y). use this button to position the camera so that we look in the +y direction, zoomed out so that the whole x and z range of the grid is visible.\npan. Once this button is pressed, the camera can be dragged. Position the mouse anywhere in the viewer and keep the left mouse button pressed while dragging.\nzoom out.\nzoom in.\n\n\nHow to use clipping\nThe clipping functionality allows one to “cut off” slices of one or more grids in the 3D viewer. The internals of the grids are then exposed, allowing us to see the value of datasets or the grid geometry inside.\nTo use clipping, open the 3D viewer and visualize one or more grids on it. Then press the clipping button in the toolbar (Figure 10).\n\n\n\n\n\n\nFigure 10: Activate clipping mode by pressing the clipping button in the toolbar. Sliders appear in the 3D viewer.\n\n\n\nNow use the sliders to clip the model. Each slider represents the combined range of all the grids in the viewer in one direction.\n\n\n\n\n\n\nFigure 11: Use sliders to cut model in each direction\n\n\n\n\n\nHow to plot gridlines\nIt is possible to plot geographical gridlines on top of a grid (Figure 12). This feature only works well at near-vertical viewing angles.\n\n\n\n\n\n\nFigure 12: Toggle gridlines with the gridlines button\n\n\n\n\n\nHow to change the vertical exaggeration\nIn the 3D viewer, objects can appear to be flat when they are not, because the range in the x and y directions for geological structures is often much larger than the range in the z direction. For example, geological layers may extend for tens or hundreds of kilometers horizontally but have a thickness and height variation of tens of meters.\nTo fix this issue, vertical exaggeration can be applied. The same vertical exaggeration is applied to all the visible grids.\nBy default, a vertical exaggeration is computed from the grid geometry. It computes a vertical exaggeration such that the vertical variation becomes at least 10% of the horizontal variation.\nThe exaggeration factor can also be set manually. To do so, disable the Use automatic exaggeration of z-axis slider and enter the desired value in the text field above it (Figure 13).\n\n\n\n\n\n\nFigure 13: Vertical exaggeration slider and text field\n\n\n\n\n\nHow to change the representation of a grid\nIn the 3D viewer, grids can be visualized as solid bodies (Figure 14); as wireframes and as point clouds. In wireframe mode, only the edges of the cells are drawn, allowing one to look inside the grid. In point cloud mode, only points corresponding to the cell centers are shown\nTo change the representation, use the dropdown in the viewer toolbar. Once selected, a dropdown appears where the representation can be changed. All visible grids get the selected representation.\n\n\n\n\n\n\nFigure 14: The 3 representations of a grid. Left the Surface representation, in the centre Wireframe, and right the Point representation.\n\n\n\nThe representation can also be changed from the property window of a grid. Here some other tweaks can also be made, like highlighting cell edges or changing the opacity of the plot.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#changing-the-legend-of-a-ugrid-dataset-idf-or-fence-diagram-grid.",
    "href": "3dviewer_user_manual.html#changing-the-legend-of-a-ugrid-dataset-idf-or-fence-diagram-grid.",
    "title": "3D Viewer User Manual",
    "section": "Changing the legend of a UGRID dataset, IDF or fence diagram grid.",
    "text": "Changing the legend of a UGRID dataset, IDF or fence diagram grid.\nTo edit the legend of a dataset in an UGRID file, IDF file or fence diagram, it is necessary to load the legend editor form. From there, the legend can be customized.\nThe way to make the legend editor appear, depends on the object.\nFor an IDF file, or a single layer of a layered UGRID file, or a non-layered UGRID file, do the following:\n\nIf not done yet, double click on the dataset to make it appear in the viewer\nOpen the context menu of the IDF file or grid layer\nPress Select in viewer\nPress the edit legend button () .\n\nFor a layered ugid dataset (so applying on all layers at the same time)\n\nRight click on the data set you want to apply the legend to\nFrom the context menu, select Edit legend\n\n\nThe legend editor\nThe legend editor consists of 2 tabs: one for continuous legends and one for discrete ones (Figure 15).\nThis form is more or less self explanatory. You can choose a color scale (currently rainbow or blue-white-red). Note that it is possible to save a legend in a separate file, or to load a legend from such a file, with the Save and Load buttons.\n\n\n\n\n\n\nFigure 15: The 2 tabs of the legend editor\n\n\n\nWhen using a percentile legend, colors are assigned to a cell based on the percentage of cells that hold a value lower than that of the current cell. The color map is distorted to reflect this. For example, when using the “heat map” legend, the lowest value is blue, the highest red, and the middle of the range is white. When using a heat map with percentiles, the white color represents not the middle of the range, but the value for which 50% of other values is smaller than itself (Figure 16).\nFor unstructured grids, note that the percentile calculation does not take cell area into account. For example, for a dataset with lot of small cells and a few large cells, the percentile legend will be skewed towards the values of the small cells.\n\n\n\n\n\n\nFigure 16: Heat map legend with percentiles on and off. Without percentiles (left), the white color is the middle of the legend range. With percentiles on (right),the color map is distorted and white is now the median value (50%) of the dataset. In general, a color that represents N % of the range in the linear legend, is mapped to the value that is larger than N % of the data in the percentiles legend.\n\n\n\n\n\nLegend sidepane\nFor quick reference, the legend is shown on a retractable sidepane. To open or close it, use the button highlighted in the figure below.\n\n\n\nWorking with fence diagrams\nFence diagrams have the same user interface as layered UGRID files. They have the same layers as the original layered UGRID they cut through, and the same datasets. Their legend can be set per-layer or for the whole fence diagram in the same way as we do for layered UGRIDs.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#working-with-ipf-files",
    "href": "3dviewer_user_manual.html#working-with-ipf-files",
    "title": "3D Viewer User Manual",
    "section": "Working with IPF files",
    "text": "Working with IPF files\nTo visualize an IPF file, open the data menu and click on open overlay file. An open file dialog appears. Select an IPF file. As with grids, the filename is then displayed in the explorer bar, but the IPF file is not yet rendered. To render it, select the IPF’s row in the explorer bar and hit the  button.\nOn import, the iMOD 3D Viewer will attempt to draw a vertical cylinder for each row in the IPF file’s data block (so excluding the header).\nBy default, a column called “x”or “X” and “y” or “Y” are used for the center of the cylinder’s top and bottom; and “top”or “TOP” and “bot” or “BOT” are used for the z-coordinates of the cylinders top and bottom, respectively.\nIf these columns are not present or if they contain text data, then the first 3 numerical columns are used for x, y and z, and the IPF data is plotted as points on these locations (Figure 17).\n\n\n\n\n\n\nFigure 17: When the default column names are not found an error message appears.\n\n\n\nTo adjust the column mapping, right click on the IPF’s row in the explorer bar and select the “Properties” menu option. Then a window appears where the column mapping can be updated (Figure 18).\n\n\n\n\n\n\nFigure 18: Property window allows to choose what IPF columns to use for drawing cylinders.\n\n\n\nThe z0 and z1 comboboxes will be used for the cylinder’s top and bottoms respectively. If the z1 column is not set, then points will be generated instead of cylinders.\nThe Label column combobox allows choosing a combobox to be used for labels. If not set, then no labels are shown. Otherwise the content of the selected column will be shown as a text label near the top of the column.\nThe IPF column mapping is serialized into solution and autosave files, and the next time a solution is loaded, the last-used column mapping will be assigned to each IPF file.\nAs with overlays, the color and cylinder thickness can be adjusted from the context menu of the IPF file.\n\n\n\n\n\n\nFigure 19: Image of an IPF plot with labels, viewed from the top.\n\n\n\n\nPlotting borehole data\nWhen the IPF file contains references to additional datafiles, one for each row in the IPF file, and when these datafiles contain 1D borehole data, then this data can be plotted on the cylinders.\nTo do that, check the option “Plot data on cylinder” on the IPF property form (Figure 20) . Both real number data and string data can be plotted. When the checkbox is checked, a legend the appears on the form proposing a color mapping. This legend is either a continuous scale (for real numbers) or a string-to-color mapping like in the example in Figure 20. The colors can be changed by clicking on a particular color box.\nThese legends can be saved and loaded as well.\n\n\n\n\n\n\nFigure 20: 1D borehole data can be plotted on cylinders generated from the IPF file. Both real number data and string data can be plotted. In this example, string data was present in the \"Admixture\" column",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#working-with-idf-files",
    "href": "3dviewer_user_manual.html#working-with-idf-files",
    "title": "3D Viewer User Manual",
    "section": "Working with IDF files",
    "text": "Working with IDF files\n\nIDF file resolution\nAn IDF files contains a 2D structured grid, and 1 dataset with cell data. This dataset is treated for visualization purposes as if it were elevation, but it can be anything. The resolution is sometimes so high it makes the grid slow to load. Therefore, an automatic upscaling is applied when visualizing the grid, reducing the number of cells to approximately 100*100. Each upscaled cell contains an integer number of actual cells in both the x and y directions; therefore cell boundaries in the upscaled grid are guaranteed to coincide with cell boundaries in the actual grid.\nThe “elevation” value of each upscaled cell is taken from the actual cell that contains the upscaled cell’s center.\nTo increase the resolution of the IDF grid in the viewer, zoom in with the mouse wheel to the area where additional detail is required. Then press the redraw button( ).\nThis renders the area visible in the viewer in higher resolution, but removes the invisible parts of the grid (Figure 21{.interpreted-text role=“numref”}). To restore those, zoom out again and press  again.\n\n\n\n\n\n\nFigure 21: Left, an upscaled IDF file. Middle: after zooming in on an area of interest. Right: after pressing the redraw button to increase resolution.\n\n\n\nAnother way to change the resolution of an IDF file is to select the IDF’s row in the explorer bar and clicking on “resolution” (Figure 22). This allows choosing a resolution of 100x100, 250x250 or 500x500 for the IPF file (Figure 23).\n\n\n\n\n\n\nFigure 22: Choose the resolution of the IDF file\n\n\n\n\n\n\n\n\n\nFigure 23: IDF file at resolution 100x100 (left); 250*250(middle) and 500x500 (right)\n\n\n\n\n\nAdditional representation options for IDF files\nThe options outlined above change the way each cell is rendered, but they do not change the underlying geometry of the cells. For IDF files we have an additional option. IDF cells are horizontal rectangles, and a surface formed by an IDF grid may look strange in the 3D viewer because these rectangles “float” at different elevations (Figure 25). Therefore, an additional option of rendering an IDF grid as triangles was added. The corner points of the triangle are the cell-centers of the rectangles, and have the elevation of that rectangle.\nTo change the representation of an IDF file, load the IPF file and then right-click on its entry in the explorer bar. A context menu appears (Figure 24). Choose rectangles or triangles as desired.\n\n\n\n\n\n\nFigure 24: Context menu for changing representation of an IDF file\n\n\n\n\n\n\n\n\n\nFigure 25: An IDF file rendered as rectangles (left) and triangles (right)",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#working-with-shapefiles",
    "href": "3dviewer_user_manual.html#working-with-shapefiles",
    "title": "3D Viewer User Manual",
    "section": "Working with shapefiles",
    "text": "Working with shapefiles\nTo visualize an overlay, open the data menu and click on “open overlay file”. An open file dialog appears. Select a shapefile containing vector data. As with grids, the filename is then displayed in the explorer bar, but the overlay is not yet rendered. To render it, select the overlay’s row in the explorer bar and hit the  button.\nOnce loaded, the line thickness and color of the overlay can be changed by right clicking on the overlay’s row in the explorer bar. This makes a context menu appear (Figure 26). There is a menu option for changing the color and one for changing the line thickness.\n\n\n\n\n\n\nFigure 26: Context menu options for changing the color and line thickness of an overlay.",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#how-to-inspect-dataset-values-of-a-cell",
    "href": "3dviewer_user_manual.html#how-to-inspect-dataset-values-of-a-cell",
    "title": "3D Viewer User Manual",
    "section": "How to inspect dataset values of a cell",
    "text": "How to inspect dataset values of a cell\nWhen we visualize a dataset, its values are used to assign a color to each cell; the value to cell mapping is defined by the legend. Hence, inspecting the plot of a dataset gives a rough idea of the value of that dataset in each cell.\nTo get a more precise value, it is possible to click on a cell and get a list of the values of different datasets in that cell. Take the following steps to do this (Figure 27):\n\nVisualize a grid in the viewer and select it.\nPress the “identify” button in the toolbar.\nSelect some datasets of the selected grid in the explorer\nClick on a cell of the grid. It will be highlighted in black.\nNow a window opens showing the values of the selected datasets in the selected cell.\n\nTo end identifying, press the “identify” button again.\n\n\n\n\n\n\nFigure 27: Dataset values can be inspected with the identify button",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "3dviewer_user_manual.html#layered-ugrid",
    "href": "3dviewer_user_manual.html#layered-ugrid",
    "title": "3D Viewer User Manual",
    "section": "Layered UGRID",
    "text": "Layered UGRID\nThe iMOD 3D Viewer currently supports only 2D UGRID files. However, when it recognizes that datasets called layer_1_top and layer_1_bottom are present (1 being a layer number), it will create a 3D grid using the x and y coordinates from the 2D grid, and the top and bottoms from the datasets. The result is a grid with cells that have horizontal and vertical cell faces, and that can represent for example a geological layer. Additional datasets (layer_2_top and layer_2_bottom) can be provided to create additional layers. The grids created this way will all have the same x and y positions for their nodes, but due to the top and bot datasets, they are at different depths. There can be holes between the layers to represent for example aquicludes.\nEach layer is shown in the explorer as a separate grid that can be loaded and unloaded independently. Properties can be assigned to each layer by listing the layer number in the dataset name. For example, we can assign a kD property to each layer by creating datasets called kD_layer_1, kD_layer_2, etcetera.\nAn example to convert a layered subsurface model in *.idf to a UGRID file can be found on https:/gitlab.com/deltares/imod/imod-python/-/snippets/2104179\n\n\n\n\n\n\nFigure 28: A 2D UGRID file rendered as a layered 3D grid\n\n\n\n\n\n\n\n\n\nFigure 29: View on internals of UGRID that can be used for rendering as a 3D layered grid",
    "crumbs": [
      "iMOD Viewer",
      "3D Viewer User Manual"
    ]
  },
  {
    "objectID": "practical_powershell.html",
    "href": "practical_powershell.html",
    "title": " Powershell profile error",
    "section": "",
    "text": "Your computer might throw you the following error in Windows PowerShell. This is annoying, because it prevents the Visual Studio Code terminal (which uses PowerShell) to use conda.\nFile C:\\Users\\Herman\\Documents\\WindowsPowerShell\\profile.ps1 cannot be loaded because the\nexecution of scripts is disabled on this system. Please see \"get-help about_signing\" for\nmore details.\nAt line:1 char:2\n+ . &lt;&lt;&lt;&lt;  'C:\\Users\\Herman\\Documents\\WindowsPowerShell\\profile.ps1'\n    + CategoryInfo          : NotSpecified: (:) [], PSSecurityException\n    + FullyQualifiedErrorId : RuntimeException\nIn order to solve this, it is recommended to run the following command:\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser\nFor more information, see this link."
  },
  {
    "objectID": "tutorial_Hondsrug.html#note-beforehand",
    "href": "tutorial_Hondsrug.html#note-beforehand",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Note beforehand",
    "text": "Note beforehand\nThis is a modified version of the Jupyter notebook distributed during the iMOD International days 2023. The modifications made to the original material mainly make accessing the data required for the course easier. To read the original course material follow this link.",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#requirements",
    "href": "tutorial_Hondsrug.html#requirements",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Requirements",
    "text": "Requirements\n\nPython environment with iMOD Python version &gt; 0.16.0  Start this notebook within a python environment where all required packages are installed. We suggest to use Deltaforge, a python distribution which includes iMOD Python and all its dependencies. Deltaforge is provided as an installer and makes installing iMOD Python easy. You can download the Deltaforge installer on the Deltares download portal.",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#description",
    "href": "tutorial_Hondsrug.html#description",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Description",
    "text": "Description\nIn this tutorial, you will learn how to use iMOD Python for building, running and analysing your MODFLOW 6 model. We compiled a tutorial to help you get started with iMOD Python and give you an overview of its capabilities.\nIn this Tutorial you learn how to: 1. load an existing model; 1. view some of the model input; 1. write and run the MODFLOW 6 simulation; 1. view results; 1. add a WEL package; 1. compare results; 1. replace the RCH package; 1. regrid the RCH package to the model dimensions.\nWe run this tutorial in a Jupyter notebook. You can run this cell by cell: [] means the cell is not run yet, [*] means the cell is currently running, [1] means the cell is finished. &gt; Note: The cells where we run the simulation will take a few minutes.",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#read-simulation-from-toml",
    "href": "tutorial_Hondsrug.html#read-simulation-from-toml",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Read simulation from toml",
    "text": "Read simulation from toml\nWith iMOD Python you can of course create a MODFLOW 6 model from scratch. It is also possible to read/import a model that was already created by iMOD Python. To share models iMOD Python uses a toml as configuration file and netcdf for data.  You find the toml file for this tutorial in the tutorial database named “… -hondsrug-example.toml”.   This is the content of the toml file:\n[GroundwaterFlowModel]\n  GWF = \"GWF/GWF.toml\"\n[Solution]\n  solver = \"solver.nc\"\n[TimeDiscretization]\n  time_discretization = \"time_discretization.nc\"\nFrom this toml you see that in turn it refers to another toml for the content of ground water model GWF, in the section [GroundwaterFlowModel]. The toml contains solver settings in the section [Solution] and timing information in the section [TimeDiscretization].\nWe will use the function from_file to load this MODFLOW 6 model from the toml file. This returns a so called Modflow6Simulation object. We will show that this object behaves similar to a python dictionary.\n\nNB With iMOD Python you can create native MODFLOW 6 model files (e.g. .dis6, .npf6, *.rch6 files). iMOD Python functions to read native MODFLOW 6 model files follow in 2024.",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#plot-model-parameters",
    "href": "tutorial_Hondsrug.html#plot-model-parameters",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Plot model parameters",
    "text": "Plot model parameters\nAn xarray Dataset has plot functionalities included. This makes it easy to get an impression of the spatial distrubution of our stage values for layer 1.  In the next cell just type the name of 2D Dataset you just created including the call for the plot function .plot(). %% replace with your plot command\nCongratulations, your first picture in this tutorial!  Instead of this default plot option, we can plot this stage data also on a map with the iMOD Python function imod.visualize.plot_map.\nWe’ll start off by defining a colormap and levels for the legend.\n\nimport numpy as np\n\ncolors = \"Blues\"\nlevels = np.arange(-2.5, 18.5, 2.5)\n\nWith this colormap, the legend range and the 2d Dataset, we call the iMOD Python plot_map function:\n\n\nimod.visualize.plot_map(riv_stage_layer_1, colors, levels)\n\n\n\n\n\n\n\n\nAs you can see imod.visualize.plot_map preserves the aspect ratio, whereas the .plot method stretches the figure in the y-direction to make a square figure.\nTry plotting with a different colormap. For all possible colormaps, see the Matplotlib page. For instance pick colormap “viridis”.\n\ncolors = \"viridis\"  # specify your color here\n\nimod.visualize.plot_map(riv_stage_layer_1, colors, levels)\n\n\n\n\n\n\n\n\nWe can add a background map to this plot for a better orientation. Therefore we need to import the package contextily first. This opens a wide range of possible basemaps, see the full list here. * Next step is to define our background_map, in this example it is one of the OpenStreetMap variants. * The we add this basemap as argument to our plot function.\n\nimport contextily as ctx\n\n# Access background maps\nbackground_map = ctx.providers[\"OpenStreetMap\"][\"Mapnik\"]\n\n# Add background map to your plot\nimod.visualize.plot_map(riv_stage_layer_1, colors, levels, basemap=background_map)\n\n\n\n\n\n\n\n\nAssignment: in the next cell, try to visualize the bottom elevation of layer 3.\n\n#\n# type here you python commands to select and plot bottom data for layer 3\n\nIt can be convenient to combine the rivers over all layers into one map. You can aggregate layers using xarrays aggregation functionality. For example we can compute the mean of the river stage across all layers:\n\nriv_all = riv_pkg[\"stage\"].mean(dim=\"layer\")\n\nimod.visualize.plot_map(riv_all, colors, levels, basemap=background_map)",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#aligning-the-recharge-data-over-time",
    "href": "tutorial_Hondsrug.html#aligning-the-recharge-data-over-time",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Aligning the recharge data over time",
    "text": "Aligning the recharge data over time\nThe recharge data has quite a lot of timesteps: data on a daily timestep for over 20 years from 1999 to 2020.\n\nrecharge.coords[\"time\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7896)&gt; Size: 63kB\narray(['1999-01-01T00:00:00.000000000', '1999-01-02T00:00:00.000000000',\n       '1999-01-03T00:00:00.000000000', ..., '2020-04-07T00:00:00.000000000',\n       '2020-04-08T00:00:00.000000000', '2020-04-09T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 63kB 1999-01-01 1999-01-02 ... 2020-04-09\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03xarray.DataArray'time'time: 78961999-01-01 1999-01-02 1999-01-03 ... 2020-04-07 2020-04-08 2020-04-09array(['1999-01-01T00:00:00.000000000', '1999-01-02T00:00:00.000000000',\n       '1999-01-03T00:00:00.000000000', ..., '2020-04-07T00:00:00.000000000',\n       '2020-04-08T00:00:00.000000000', '2020-04-09T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (3)time(time)datetime64[ns]1999-01-01 ... 2020-04-09array(['1999-01-01T00:00:00.000000000', '1999-01-02T00:00:00.000000000',\n       '1999-01-03T00:00:00.000000000', ..., '2020-04-07T00:00:00.000000000',\n       '2020-04-08T00:00:00.000000000', '2020-04-09T00:00:00.000000000'],\n      dtype='datetime64[ns]')dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['1999-01-01 00:00:00', '1999-01-02 00:00:00',\n               '1999-01-03 00:00:00', '1999-01-04 00:00:00',\n               '1999-01-05 00:00:00', '1999-01-06 00:00:00',\n               '1999-01-07 00:00:00', '1999-01-08 00:00:00',\n               '1999-01-09 00:00:00', '1999-01-10 00:00:00',\n               ...\n               '2020-03-31 00:00:00', '2020-04-01 00:00:00',\n               '2020-04-02 00:00:00', '2020-04-03 00:00:00',\n               '2020-04-04 00:00:00', '2020-04-05 00:00:00',\n               '2020-04-06 00:00:00', '2020-04-07 00:00:00',\n               '2020-04-08 00:00:00', '2020-04-09 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=7896, freq=None))Attributes: (0)\n\n\nThis is entirely different from our model discretization as you can see from the next command. It is on a yearly timestep and lasts from 2010 to 2015.\n\nsimulation[\"time_discretization\"][\"time\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7)&gt; Size: 56B\narray(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31xarray.DataArray'time'time: 72009-12-30T23:59:59 2009-12-31 2010-12-31 ... 2013-12-31 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\nWe therefore need to align this data over time. We’ll start off by selecting the data in this time range.\n\nrecharge_daily = recharge.sel(time=slice(\"2010-01-01\", \"2015-12-31\"))\n\nrecharge_daily\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 2191, y: 32, x: 46)&gt; Size: 13MB\narray([[[-8.16326501e-05, -2.64687988e-05,  3.28923052e-05, ...,\n         -2.24501506e-04, -2.23106923e-04, -2.21713140e-04],\n        [-1.04659906e-04, -6.49848080e-05, -2.45948613e-05, ...,\n         -2.23988682e-04, -2.22599207e-04, -2.21210474e-04],\n        [-1.28739004e-04, -1.02283215e-04, -7.61318515e-05, ...,\n         -2.23471667e-04, -2.22087663e-04, -2.20704300e-04],\n        ...,\n        [-2.50906800e-04, -2.50017096e-04, -2.49122648e-04, ...,\n         -2.08009442e-04, -2.06839439e-04, -2.05661054e-04],\n        [-2.50064710e-04, -2.49169330e-04, -2.48269411e-04, ...,\n         -2.07411562e-04, -2.06249417e-04, -2.05078526e-04],\n        [-2.49222794e-04, -2.48322089e-04, -2.47417163e-04, ...,\n         -2.06814919e-04, -2.05660428e-04, -2.04496857e-04]],\n\n       [[ 5.76382829e-03,  5.71064278e-03,  5.66325895e-03, ...,\n          7.91468285e-03,  7.97893107e-03,  8.00823327e-03],\n        [ 5.92353567e-03,  5.87961730e-03,  5.84226800e-03, ...,\n          8.03106371e-03,  8.06891546e-03,  8.07126891e-03],\n        [ 6.07634475e-03,  6.04142435e-03,  6.01337850e-03, ...,\n          8.12761765e-03,  8.14526342e-03,  8.13211594e-03],\n...\n          1.01315859e-03,  1.00552640e-03,  9.98232979e-04],\n        [ 1.37537799e-03,  1.37999584e-03,  1.38323172e-03, ...,\n          1.01078511e-03,  1.00376888e-03,  9.97082097e-04],\n        [ 1.34900177e-03,  1.35437632e-03,  1.35794852e-03, ...,\n          1.00786844e-03,  1.00155268e-03,  9.95498151e-04]],\n\n       [[-3.25558620e-04, -3.25299829e-04, -2.33122453e-04, ...,\n         -1.36521907e-04, -1.25874009e-04, -1.14803712e-04],\n        [-3.26562236e-04, -2.40133348e-04, -2.25921947e-04, ...,\n         -1.39027179e-04, -1.26366285e-04, -1.13161819e-04],\n        [-2.45688629e-04, -2.33959145e-04, -2.19888287e-04, ...,\n         -1.40678341e-04, -1.26630446e-04, -1.12137481e-04],\n        ...,\n        [-3.58189340e-04, -3.58125748e-04, -3.58054065e-04, ...,\n         -3.46493849e-04, -3.46101238e-04, -3.45708366e-04],\n        [-3.59323138e-04, -3.59265337e-04, -3.59199534e-04, ...,\n         -3.47538589e-04, -3.47140507e-04, -3.46742338e-04],\n        [-3.60447710e-04, -3.60395497e-04, -3.60335340e-04, ...,\n         -3.48576548e-04, -3.48173256e-04, -3.47769848e-04]]],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 18kB 2010-01-01 2010-01-02 ... 2015-12-31\n  * x        (x) float64 368B 2.205e+05 2.215e+05 ... 2.645e+05 2.655e+05\n  * y        (y) float64 256B 5.715e+05 5.705e+05 ... 5.415e+05 5.405e+05\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03xarray.DataArraytime: 2191y: 32x: 46-8.163e-05 -2.647e-05 3.289e-05 ... -0.0003486 -0.0003482 -0.0003478array([[[-8.16326501e-05, -2.64687988e-05,  3.28923052e-05, ...,\n         -2.24501506e-04, -2.23106923e-04, -2.21713140e-04],\n        [-1.04659906e-04, -6.49848080e-05, -2.45948613e-05, ...,\n         -2.23988682e-04, -2.22599207e-04, -2.21210474e-04],\n        [-1.28739004e-04, -1.02283215e-04, -7.61318515e-05, ...,\n         -2.23471667e-04, -2.22087663e-04, -2.20704300e-04],\n        ...,\n        [-2.50906800e-04, -2.50017096e-04, -2.49122648e-04, ...,\n         -2.08009442e-04, -2.06839439e-04, -2.05661054e-04],\n        [-2.50064710e-04, -2.49169330e-04, -2.48269411e-04, ...,\n         -2.07411562e-04, -2.06249417e-04, -2.05078526e-04],\n        [-2.49222794e-04, -2.48322089e-04, -2.47417163e-04, ...,\n         -2.06814919e-04, -2.05660428e-04, -2.04496857e-04]],\n\n       [[ 5.76382829e-03,  5.71064278e-03,  5.66325895e-03, ...,\n          7.91468285e-03,  7.97893107e-03,  8.00823327e-03],\n        [ 5.92353567e-03,  5.87961730e-03,  5.84226800e-03, ...,\n          8.03106371e-03,  8.06891546e-03,  8.07126891e-03],\n        [ 6.07634475e-03,  6.04142435e-03,  6.01337850e-03, ...,\n          8.12761765e-03,  8.14526342e-03,  8.13211594e-03],\n...\n          1.01315859e-03,  1.00552640e-03,  9.98232979e-04],\n        [ 1.37537799e-03,  1.37999584e-03,  1.38323172e-03, ...,\n          1.01078511e-03,  1.00376888e-03,  9.97082097e-04],\n        [ 1.34900177e-03,  1.35437632e-03,  1.35794852e-03, ...,\n          1.00786844e-03,  1.00155268e-03,  9.95498151e-04]],\n\n       [[-3.25558620e-04, -3.25299829e-04, -2.33122453e-04, ...,\n         -1.36521907e-04, -1.25874009e-04, -1.14803712e-04],\n        [-3.26562236e-04, -2.40133348e-04, -2.25921947e-04, ...,\n         -1.39027179e-04, -1.26366285e-04, -1.13161819e-04],\n        [-2.45688629e-04, -2.33959145e-04, -2.19888287e-04, ...,\n         -1.40678341e-04, -1.26630446e-04, -1.12137481e-04],\n        ...,\n        [-3.58189340e-04, -3.58125748e-04, -3.58054065e-04, ...,\n         -3.46493849e-04, -3.46101238e-04, -3.45708366e-04],\n        [-3.59323138e-04, -3.59265337e-04, -3.59199534e-04, ...,\n         -3.47538589e-04, -3.47140507e-04, -3.46742338e-04],\n        [-3.60447710e-04, -3.60395497e-04, -3.60335340e-04, ...,\n         -3.48576548e-04, -3.48173256e-04, -3.47769848e-04]]],\n      dtype=float32)Coordinates: (5)time(time)datetime64[ns]2010-01-01 ... 2015-12-31array(['2010-01-01T00:00:00.000000000', '2010-01-02T00:00:00.000000000',\n       '2010-01-03T00:00:00.000000000', ..., '2015-12-29T00:00:00.000000000',\n       '2015-12-30T00:00:00.000000000', '2015-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')x(x)float642.205e+05 2.215e+05 ... 2.655e+05array([220500., 221500., 222500., 223500., 224500., 225500., 226500., 227500.,\n       228500., 229500., 230500., 231500., 232500., 233500., 234500., 235500.,\n       236500., 237500., 238500., 239500., 240500., 241500., 242500., 243500.,\n       244500., 245500., 246500., 247500., 248500., 249500., 250500., 251500.,\n       252500., 253500., 254500., 255500., 256500., 257500., 258500., 259500.,\n       260500., 261500., 262500., 263500., 264500., 265500.])y(y)float645.715e+05 5.705e+05 ... 5.405e+05array([571500., 570500., 569500., 568500., 567500., 566500., 565500., 564500.,\n       563500., 562500., 561500., 560500., 559500., 558500., 557500., 556500.,\n       555500., 554500., 553500., 552500., 551500., 550500., 549500., 548500.,\n       547500., 546500., 545500., 544500., 543500., 542500., 541500., 540500.])dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2010-01-01', '2010-01-02', '2010-01-03', '2010-01-04',\n               '2010-01-05', '2010-01-06', '2010-01-07', '2010-01-08',\n               '2010-01-09', '2010-01-10',\n               ...\n               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n               '2015-12-30', '2015-12-31'],\n              dtype='datetime64[ns]', name='time', length=2191, freq=None))xPandasIndexPandasIndex(Index([220500.0, 221500.0, 222500.0, 223500.0, 224500.0, 225500.0, 226500.0,\n       227500.0, 228500.0, 229500.0, 230500.0, 231500.0, 232500.0, 233500.0,\n       234500.0, 235500.0, 236500.0, 237500.0, 238500.0, 239500.0, 240500.0,\n       241500.0, 242500.0, 243500.0, 244500.0, 245500.0, 246500.0, 247500.0,\n       248500.0, 249500.0, 250500.0, 251500.0, 252500.0, 253500.0, 254500.0,\n       255500.0, 256500.0, 257500.0, 258500.0, 259500.0, 260500.0, 261500.0,\n       262500.0, 263500.0, 264500.0, 265500.0],\n      dtype='float64', name='x'))yPandasIndexPandasIndex(Index([571500.0, 570500.0, 569500.0, 568500.0, 567500.0, 566500.0, 565500.0,\n       564500.0, 563500.0, 562500.0, 561500.0, 560500.0, 559500.0, 558500.0,\n       557500.0, 556500.0, 555500.0, 554500.0, 553500.0, 552500.0, 551500.0,\n       550500.0, 549500.0, 548500.0, 547500.0, 546500.0, 545500.0, 544500.0,\n       543500.0, 542500.0, 541500.0, 540500.0],\n      dtype='float64', name='y'))Attributes: (0)\n\n\nXarray has functionality to resample recharge to yearly timestep (“A” stands for “annum”). If you want to find the aliases for other frequencies, see this table We’ll label the years with their starting point, as iMOD Python defines its stress periods on their starting moment.\n\nrecharge_yearly = recharge_daily.resample(time=\"A\", label=\"left\").mean()\n\nrecharge_yearly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 6, y: 32, x: 46)&gt; Size: 35kB\narray([[[0.00073594, 0.00074953, 0.00076365, ..., 0.00065445,\n         0.00066929, 0.00068409],\n        [0.00073745, 0.00074902, 0.00076116, ..., 0.00063818,\n         0.00065288, 0.00066111],\n        [0.00073997, 0.00074967, 0.00076049, ..., 0.00062062,\n         0.00063231, 0.00064009],\n        ...,\n        [0.00081184, 0.00082499, 0.00083348, ..., 0.00065828,\n         0.00065836, 0.00065948],\n        [0.0008016 , 0.00081223, 0.0008263 , ..., 0.00065725,\n         0.00065529, 0.00065469],\n        [0.00079176, 0.00080563, 0.00081583, ..., 0.00065096,\n         0.00064681, 0.00064626]],\n\n       [[0.00064228, 0.00065644, 0.00067187, ..., 0.00081917,\n         0.00085411, 0.00088009],\n        [0.00063408, 0.00064502, 0.00065816, ..., 0.00078976,\n         0.00081531, 0.000827  ],\n        [0.0006243 , 0.00063393, 0.0006448 , ..., 0.00075673,\n         0.00077378, 0.00078121],\n...\n        [0.00084628, 0.00086339, 0.00087912, ..., 0.00062002,\n         0.00062491, 0.00063112],\n        [0.00085344, 0.00087211, 0.00088709, ..., 0.00062375,\n         0.00062804, 0.00063361],\n        [0.00085948, 0.00088016, 0.00089779, ..., 0.00062747,\n         0.00063116, 0.00063512]],\n\n       [[0.00124327, 0.00125586, 0.00126757, ..., 0.0011327 ,\n         0.00113055, 0.00112583],\n        [0.00125251, 0.00126371, 0.00127229, ..., 0.00111782,\n         0.00111317, 0.00110813],\n        [0.00126285, 0.00127107, 0.00127818, ..., 0.00110242,\n         0.00109554, 0.00108874],\n        ...,\n        [0.0014347 , 0.00144276, 0.00144917, ..., 0.00118225,\n         0.00118231, 0.0011821 ],\n        [0.00142494, 0.00143413, 0.00144147, ..., 0.00118101,\n         0.00118035, 0.00117977],\n        [0.00141579, 0.00142525, 0.0014342 , ..., 0.0011771 ,\n         0.0011758 , 0.00117499]]], dtype=float32)\nCoordinates:\n  * x        (x) float64 368B 2.205e+05 2.215e+05 ... 2.645e+05 2.655e+05\n  * y        (y) float64 256B 5.715e+05 5.705e+05 ... 5.415e+05 5.405e+05\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03\n  * time     (time) datetime64[ns] 48B 2009-12-31 2010-12-31 ... 2014-12-31xarray.DataArraytime: 6y: 32x: 460.0007359 0.0007495 0.0007637 0.0007782 ... 0.001177 0.001176 0.001175array([[[0.00073594, 0.00074953, 0.00076365, ..., 0.00065445,\n         0.00066929, 0.00068409],\n        [0.00073745, 0.00074902, 0.00076116, ..., 0.00063818,\n         0.00065288, 0.00066111],\n        [0.00073997, 0.00074967, 0.00076049, ..., 0.00062062,\n         0.00063231, 0.00064009],\n        ...,\n        [0.00081184, 0.00082499, 0.00083348, ..., 0.00065828,\n         0.00065836, 0.00065948],\n        [0.0008016 , 0.00081223, 0.0008263 , ..., 0.00065725,\n         0.00065529, 0.00065469],\n        [0.00079176, 0.00080563, 0.00081583, ..., 0.00065096,\n         0.00064681, 0.00064626]],\n\n       [[0.00064228, 0.00065644, 0.00067187, ..., 0.00081917,\n         0.00085411, 0.00088009],\n        [0.00063408, 0.00064502, 0.00065816, ..., 0.00078976,\n         0.00081531, 0.000827  ],\n        [0.0006243 , 0.00063393, 0.0006448 , ..., 0.00075673,\n         0.00077378, 0.00078121],\n...\n        [0.00084628, 0.00086339, 0.00087912, ..., 0.00062002,\n         0.00062491, 0.00063112],\n        [0.00085344, 0.00087211, 0.00088709, ..., 0.00062375,\n         0.00062804, 0.00063361],\n        [0.00085948, 0.00088016, 0.00089779, ..., 0.00062747,\n         0.00063116, 0.00063512]],\n\n       [[0.00124327, 0.00125586, 0.00126757, ..., 0.0011327 ,\n         0.00113055, 0.00112583],\n        [0.00125251, 0.00126371, 0.00127229, ..., 0.00111782,\n         0.00111317, 0.00110813],\n        [0.00126285, 0.00127107, 0.00127818, ..., 0.00110242,\n         0.00109554, 0.00108874],\n        ...,\n        [0.0014347 , 0.00144276, 0.00144917, ..., 0.00118225,\n         0.00118231, 0.0011821 ],\n        [0.00142494, 0.00143413, 0.00144147, ..., 0.00118101,\n         0.00118035, 0.00117977],\n        [0.00141579, 0.00142525, 0.0014342 , ..., 0.0011771 ,\n         0.0011758 , 0.00117499]]], dtype=float32)Coordinates: (5)x(x)float642.205e+05 2.215e+05 ... 2.655e+05array([220500., 221500., 222500., 223500., 224500., 225500., 226500., 227500.,\n       228500., 229500., 230500., 231500., 232500., 233500., 234500., 235500.,\n       236500., 237500., 238500., 239500., 240500., 241500., 242500., 243500.,\n       244500., 245500., 246500., 247500., 248500., 249500., 250500., 251500.,\n       252500., 253500., 254500., 255500., 256500., 257500., 258500., 259500.,\n       260500., 261500., 262500., 263500., 264500., 265500.])y(y)float645.715e+05 5.705e+05 ... 5.405e+05array([571500., 570500., 569500., 568500., 567500., 566500., 565500., 564500.,\n       563500., 562500., 561500., 560500., 559500., 558500., 557500., 556500.,\n       555500., 554500., 553500., 552500., 551500., 550500., 549500., 548500.,\n       547500., 546500., 545500., 544500., 543500., 542500., 541500., 540500.])dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)time(time)datetime64[ns]2009-12-31 ... 2014-12-31array(['2009-12-31T00:00:00.000000000', '2010-12-31T00:00:00.000000000',\n       '2011-12-31T00:00:00.000000000', '2012-12-31T00:00:00.000000000',\n       '2013-12-31T00:00:00.000000000', '2014-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (3)xPandasIndexPandasIndex(Index([220500.0, 221500.0, 222500.0, 223500.0, 224500.0, 225500.0, 226500.0,\n       227500.0, 228500.0, 229500.0, 230500.0, 231500.0, 232500.0, 233500.0,\n       234500.0, 235500.0, 236500.0, 237500.0, 238500.0, 239500.0, 240500.0,\n       241500.0, 242500.0, 243500.0, 244500.0, 245500.0, 246500.0, 247500.0,\n       248500.0, 249500.0, 250500.0, 251500.0, 252500.0, 253500.0, 254500.0,\n       255500.0, 256500.0, 257500.0, 258500.0, 259500.0, 260500.0, 261500.0,\n       262500.0, 263500.0, 264500.0, 265500.0],\n      dtype='float64', name='x'))yPandasIndexPandasIndex(Index([571500.0, 570500.0, 569500.0, 568500.0, 567500.0, 566500.0, 565500.0,\n       564500.0, 563500.0, 562500.0, 561500.0, 560500.0, 559500.0, 558500.0,\n       557500.0, 556500.0, 555500.0, 554500.0, 553500.0, 552500.0, 551500.0,\n       550500.0, 549500.0, 548500.0, 547500.0, 546500.0, 545500.0, 544500.0,\n       543500.0, 542500.0, 541500.0, 540500.0],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(DatetimeIndex(['2009-12-31', '2010-12-31', '2011-12-31', '2012-12-31',\n               '2013-12-31', '2014-12-31'],\n              dtype='datetime64[ns]', name='time', freq='YE-DEC'))Attributes: (0)\n\n\nTo visually compare the effects of the yearly versus daily recharge, we can make a lineplot. For there plot functionalities we need to import the package matplotlib one-time. We’ll take a point close to the well. We can use:\n\nimport matplotlib.pyplot as plt\n\n# initialization of the figure and single graph\nfig, ax = plt.subplots()\n# defining the content of the graph\nrecharge_daily.sel(x=x_well, y=y_well, method=\"nearest\").plot(ax=ax)\nrecharge_yearly.sel(x=x_well, y=y_well, method=\"nearest\").plot(ax=ax)\n# display the graph\nplt.show()\n\n\n\n\n\n\n\n\nTo create the final recharge for the transient simulation, the steady state information needs to be concatenated to the transient recharge data. The steady state simulation will be run for one second. This is achieved by using the numpy Timedelta function, first creating a time delta of 1 second, which is assigned to the steady-state recharge information. This dataset is then concatenated using the xarray function xarray.concat to the transient information and indicating that the dimension to join is \"time\".\n\nimport xarray as xr\n\nstarttime = \"2009-12-31\"\n\n# create second before transient\none_second = np.timedelta64(1, \"s\")  # 1 second duration for initial steady-state\nstarttime_ss = np.datetime64(starttime) - one_second\n# fill in with steady-state value\nrecharge_steady_state = recharge_steady_state.assign_coords(time=starttime_ss)\n# add before transient data\nrecharge_ss_yearly = xr.concat([recharge_steady_state, recharge_yearly], dim=\"time\")\n# check timesteps\nrecharge_ss_yearly.coords[\"time\"]\n\n/tmp/ipykernel_4763/3227820086.py:9: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n  recharge_steady_state = recharge_steady_state.assign_coords(time=starttime_ss)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7)&gt; Size: 56B\narray(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')\nCoordinates:\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03\n  * time     (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31xarray.DataArray'time'time: 72009-12-30T23:59:59 2009-12-31 2010-12-31 ... 2013-12-31 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')Coordinates: (3)dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\nThe Recharge package requires a layer coordinate to assign values to. We’ll assign all values to the first layer.\n\nrecharge_ss_yearly = recharge_ss_yearly.assign_coords(layer=1)\n# see that coordinate \"layer\" is added\nrecharge_ss_yearly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 32, x: 46, time: 7)&gt; Size: 41kB\narray([[[0.00090112, 0.00073594, 0.00064228, ..., 0.00049744,\n         0.00038132, 0.00124327],\n        [0.00091149, 0.00074953, 0.00065644, ..., 0.00050439,\n         0.00039466, 0.00125586],\n        [0.00092218, 0.00076365, 0.00067187, ..., 0.00051254,\n         0.00040775, 0.00126757],\n        ...,\n        [0.00089727, 0.00065445, 0.00081917, ..., 0.00086637,\n         0.0006427 , 0.0011327 ],\n        [0.00091131, 0.00066929, 0.00085411, ..., 0.00089234,\n         0.00066672, 0.00113055],\n        [0.00091922, 0.00068409, 0.00088009, ..., 0.0009116 ,\n         0.00068632, 0.00112583]],\n\n       [[0.00089882, 0.00073745, 0.00063408, ..., 0.00049279,\n         0.00039685, 0.00125251],\n        [0.00090778, 0.00074902, 0.00064502, ..., 0.00049859,\n         0.00040766, 0.00126371],\n        [0.0009161 , 0.00076116, 0.00065816, ..., 0.00050548,\n         0.00041812, 0.00127229],\n...\n        [0.00083164, 0.00065725, 0.00082482, ..., 0.00062379,\n         0.00062375, 0.00118101],\n        [0.00082395, 0.00065529, 0.00081596, ..., 0.00061944,\n         0.00062804, 0.00118035],\n        [0.00081767, 0.00065469, 0.00080629, ..., 0.00061614,\n         0.00063361, 0.00117977]],\n\n       [[0.00097266, 0.00079176, 0.00076093, ..., 0.00063289,\n         0.00085948, 0.00141579],\n        [0.0009871 , 0.00080563, 0.000769  , ..., 0.00064574,\n         0.00088016, 0.00142525],\n        [0.00100034, 0.00081583, 0.00077623, ..., 0.00065784,\n         0.00089779, 0.0014342 ],\n        ...,\n        [0.00083168, 0.00065096, 0.00082331, ..., 0.00062643,\n         0.00062747, 0.0011771 ],\n        [0.00082356, 0.00064681, 0.0008135 , ..., 0.00062167,\n         0.00063116, 0.0011758 ],\n        [0.00081632, 0.00064626, 0.00080386, ..., 0.00061691,\n         0.00063512, 0.00117499]]], dtype=float32)\nCoordinates:\n  * x        (x) float64 368B 2.205e+05 2.215e+05 ... 2.645e+05 2.655e+05\n  * y        (y) float64 256B 5.715e+05 5.705e+05 ... 5.415e+05 5.405e+05\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03\n  * time     (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31\n    layer    int64 8B 1xarray.DataArrayy: 32x: 46time: 70.0009011 0.0007359 0.0006423 ... 0.0006169 0.0006351 0.001175array([[[0.00090112, 0.00073594, 0.00064228, ..., 0.00049744,\n         0.00038132, 0.00124327],\n        [0.00091149, 0.00074953, 0.00065644, ..., 0.00050439,\n         0.00039466, 0.00125586],\n        [0.00092218, 0.00076365, 0.00067187, ..., 0.00051254,\n         0.00040775, 0.00126757],\n        ...,\n        [0.00089727, 0.00065445, 0.00081917, ..., 0.00086637,\n         0.0006427 , 0.0011327 ],\n        [0.00091131, 0.00066929, 0.00085411, ..., 0.00089234,\n         0.00066672, 0.00113055],\n        [0.00091922, 0.00068409, 0.00088009, ..., 0.0009116 ,\n         0.00068632, 0.00112583]],\n\n       [[0.00089882, 0.00073745, 0.00063408, ..., 0.00049279,\n         0.00039685, 0.00125251],\n        [0.00090778, 0.00074902, 0.00064502, ..., 0.00049859,\n         0.00040766, 0.00126371],\n        [0.0009161 , 0.00076116, 0.00065816, ..., 0.00050548,\n         0.00041812, 0.00127229],\n...\n        [0.00083164, 0.00065725, 0.00082482, ..., 0.00062379,\n         0.00062375, 0.00118101],\n        [0.00082395, 0.00065529, 0.00081596, ..., 0.00061944,\n         0.00062804, 0.00118035],\n        [0.00081767, 0.00065469, 0.00080629, ..., 0.00061614,\n         0.00063361, 0.00117977]],\n\n       [[0.00097266, 0.00079176, 0.00076093, ..., 0.00063289,\n         0.00085948, 0.00141579],\n        [0.0009871 , 0.00080563, 0.000769  , ..., 0.00064574,\n         0.00088016, 0.00142525],\n        [0.00100034, 0.00081583, 0.00077623, ..., 0.00065784,\n         0.00089779, 0.0014342 ],\n        ...,\n        [0.00083168, 0.00065096, 0.00082331, ..., 0.00062643,\n         0.00062747, 0.0011771 ],\n        [0.00082356, 0.00064681, 0.0008135 , ..., 0.00062167,\n         0.00063116, 0.0011758 ],\n        [0.00081632, 0.00064626, 0.00080386, ..., 0.00061691,\n         0.00063512, 0.00117499]]], dtype=float32)Coordinates: (6)x(x)float642.205e+05 2.215e+05 ... 2.655e+05array([220500., 221500., 222500., 223500., 224500., 225500., 226500., 227500.,\n       228500., 229500., 230500., 231500., 232500., 233500., 234500., 235500.,\n       236500., 237500., 238500., 239500., 240500., 241500., 242500., 243500.,\n       244500., 245500., 246500., 247500., 248500., 249500., 250500., 251500.,\n       252500., 253500., 254500., 255500., 256500., 257500., 258500., 259500.,\n       260500., 261500., 262500., 263500., 264500., 265500.])y(y)float645.715e+05 5.705e+05 ... 5.405e+05array([571500., 570500., 569500., 568500., 567500., 566500., 565500., 564500.,\n       563500., 562500., 561500., 560500., 559500., 558500., 557500., 556500.,\n       555500., 554500., 553500., 552500., 551500., 550500., 549500., 548500.,\n       547500., 546500., 545500., 544500., 543500., 542500., 541500., 540500.])dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')layer()int641array(1)Indexes: (3)xPandasIndexPandasIndex(Index([220500.0, 221500.0, 222500.0, 223500.0, 224500.0, 225500.0, 226500.0,\n       227500.0, 228500.0, 229500.0, 230500.0, 231500.0, 232500.0, 233500.0,\n       234500.0, 235500.0, 236500.0, 237500.0, 238500.0, 239500.0, 240500.0,\n       241500.0, 242500.0, 243500.0, 244500.0, 245500.0, 246500.0, 247500.0,\n       248500.0, 249500.0, 250500.0, 251500.0, 252500.0, 253500.0, 254500.0,\n       255500.0, 256500.0, 257500.0, 258500.0, 259500.0, 260500.0, 261500.0,\n       262500.0, 263500.0, 264500.0, 265500.0],\n      dtype='float64', name='x'))yPandasIndexPandasIndex(Index([571500.0, 570500.0, 569500.0, 568500.0, 567500.0, 566500.0, 565500.0,\n       564500.0, 563500.0, 562500.0, 561500.0, 560500.0, 559500.0, 558500.0,\n       557500.0, 556500.0, 555500.0, 554500.0, 553500.0, 552500.0, 551500.0,\n       550500.0, 549500.0, 548500.0, 547500.0, 546500.0, 545500.0, 544500.0,\n       543500.0, 542500.0, 541500.0, 540500.0],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\nFurthermore, iMOD Python expects its data to follow the dimension order: [\"time\", \"layer\", \"y\", \"x\"]. The recharge data has order [\"y\", \"x\", \"time\"] after concatenation.\n\nrecharge_ss_yearly = recharge_ss_yearly.transpose(\"time\", \"y\", \"x\")\n\nrecharge_ss_yearly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (time: 7, y: 32, x: 46)&gt; Size: 41kB\narray([[[0.00090112, 0.00091149, 0.00092218, ..., 0.00089727,\n         0.00091131, 0.00091922],\n        [0.00089882, 0.00090778, 0.0009161 , ..., 0.00087254,\n         0.00087931, 0.00088026],\n        [0.00089744, 0.00090371, 0.00091122, ..., 0.00084502,\n         0.00084642, 0.00084295],\n        ...,\n        [0.0009712 , 0.00098286, 0.00099209, ..., 0.00082975,\n         0.00082282, 0.00081758],\n        [0.00097145, 0.00098481, 0.00099601, ..., 0.00083164,\n         0.00082395, 0.00081767],\n        [0.00097266, 0.0009871 , 0.00100034, ..., 0.00083168,\n         0.00082356, 0.00081632]],\n\n       [[0.00073594, 0.00074953, 0.00076365, ..., 0.00065445,\n         0.00066929, 0.00068409],\n        [0.00073745, 0.00074902, 0.00076116, ..., 0.00063818,\n         0.00065288, 0.00066111],\n        [0.00073997, 0.00074967, 0.00076049, ..., 0.00062062,\n         0.00063231, 0.00064009],\n...\n        [0.00084628, 0.00086339, 0.00087912, ..., 0.00062002,\n         0.00062491, 0.00063112],\n        [0.00085344, 0.00087211, 0.00088709, ..., 0.00062375,\n         0.00062804, 0.00063361],\n        [0.00085948, 0.00088016, 0.00089779, ..., 0.00062747,\n         0.00063116, 0.00063512]],\n\n       [[0.00124327, 0.00125586, 0.00126757, ..., 0.0011327 ,\n         0.00113055, 0.00112583],\n        [0.00125251, 0.00126371, 0.00127229, ..., 0.00111782,\n         0.00111317, 0.00110813],\n        [0.00126285, 0.00127107, 0.00127818, ..., 0.00110242,\n         0.00109554, 0.00108874],\n        ...,\n        [0.0014347 , 0.00144276, 0.00144917, ..., 0.00118225,\n         0.00118231, 0.0011821 ],\n        [0.00142494, 0.00143413, 0.00144147, ..., 0.00118101,\n         0.00118035, 0.00117977],\n        [0.00141579, 0.00142525, 0.0014342 , ..., 0.0011771 ,\n         0.0011758 , 0.00117499]]], dtype=float32)\nCoordinates:\n  * x        (x) float64 368B 2.205e+05 2.215e+05 ... 2.645e+05 2.655e+05\n  * y        (y) float64 256B 5.715e+05 5.705e+05 ... 5.415e+05 5.405e+05\n    dx       float64 8B 1e+03\n    dy       float64 8B -1e+03\n  * time     (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31\n    layer    int64 8B 1xarray.DataArraytime: 7y: 32x: 460.0009011 0.0009115 0.0009222 0.0009325 ... 0.001177 0.001176 0.001175array([[[0.00090112, 0.00091149, 0.00092218, ..., 0.00089727,\n         0.00091131, 0.00091922],\n        [0.00089882, 0.00090778, 0.0009161 , ..., 0.00087254,\n         0.00087931, 0.00088026],\n        [0.00089744, 0.00090371, 0.00091122, ..., 0.00084502,\n         0.00084642, 0.00084295],\n        ...,\n        [0.0009712 , 0.00098286, 0.00099209, ..., 0.00082975,\n         0.00082282, 0.00081758],\n        [0.00097145, 0.00098481, 0.00099601, ..., 0.00083164,\n         0.00082395, 0.00081767],\n        [0.00097266, 0.0009871 , 0.00100034, ..., 0.00083168,\n         0.00082356, 0.00081632]],\n\n       [[0.00073594, 0.00074953, 0.00076365, ..., 0.00065445,\n         0.00066929, 0.00068409],\n        [0.00073745, 0.00074902, 0.00076116, ..., 0.00063818,\n         0.00065288, 0.00066111],\n        [0.00073997, 0.00074967, 0.00076049, ..., 0.00062062,\n         0.00063231, 0.00064009],\n...\n        [0.00084628, 0.00086339, 0.00087912, ..., 0.00062002,\n         0.00062491, 0.00063112],\n        [0.00085344, 0.00087211, 0.00088709, ..., 0.00062375,\n         0.00062804, 0.00063361],\n        [0.00085948, 0.00088016, 0.00089779, ..., 0.00062747,\n         0.00063116, 0.00063512]],\n\n       [[0.00124327, 0.00125586, 0.00126757, ..., 0.0011327 ,\n         0.00113055, 0.00112583],\n        [0.00125251, 0.00126371, 0.00127229, ..., 0.00111782,\n         0.00111317, 0.00110813],\n        [0.00126285, 0.00127107, 0.00127818, ..., 0.00110242,\n         0.00109554, 0.00108874],\n        ...,\n        [0.0014347 , 0.00144276, 0.00144917, ..., 0.00118225,\n         0.00118231, 0.0011821 ],\n        [0.00142494, 0.00143413, 0.00144147, ..., 0.00118101,\n         0.00118035, 0.00117977],\n        [0.00141579, 0.00142525, 0.0014342 , ..., 0.0011771 ,\n         0.0011758 , 0.00117499]]], dtype=float32)Coordinates: (6)x(x)float642.205e+05 2.215e+05 ... 2.655e+05array([220500., 221500., 222500., 223500., 224500., 225500., 226500., 227500.,\n       228500., 229500., 230500., 231500., 232500., 233500., 234500., 235500.,\n       236500., 237500., 238500., 239500., 240500., 241500., 242500., 243500.,\n       244500., 245500., 246500., 247500., 248500., 249500., 250500., 251500.,\n       252500., 253500., 254500., 255500., 256500., 257500., 258500., 259500.,\n       260500., 261500., 262500., 263500., 264500., 265500.])y(y)float645.715e+05 5.705e+05 ... 5.405e+05array([571500., 570500., 569500., 568500., 567500., 566500., 565500., 564500.,\n       563500., 562500., 561500., 560500., 559500., 558500., 557500., 556500.,\n       555500., 554500., 553500., 552500., 551500., 550500., 549500., 548500.,\n       547500., 546500., 545500., 544500., 543500., 542500., 541500., 540500.])dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')layer()int641array(1)Indexes: (3)xPandasIndexPandasIndex(Index([220500.0, 221500.0, 222500.0, 223500.0, 224500.0, 225500.0, 226500.0,\n       227500.0, 228500.0, 229500.0, 230500.0, 231500.0, 232500.0, 233500.0,\n       234500.0, 235500.0, 236500.0, 237500.0, 238500.0, 239500.0, 240500.0,\n       241500.0, 242500.0, 243500.0, 244500.0, 245500.0, 246500.0, 247500.0,\n       248500.0, 249500.0, 250500.0, 251500.0, 252500.0, 253500.0, 254500.0,\n       255500.0, 256500.0, 257500.0, 258500.0, 259500.0, 260500.0, 261500.0,\n       262500.0, 263500.0, 264500.0, 265500.0],\n      dtype='float64', name='x'))yPandasIndexPandasIndex(Index([571500.0, 570500.0, 569500.0, 568500.0, 567500.0, 566500.0, 565500.0,\n       564500.0, 563500.0, 562500.0, 561500.0, 560500.0, 559500.0, 558500.0,\n       557500.0, 556500.0, 555500.0, 554500.0, 553500.0, 552500.0, 551500.0,\n       550500.0, 549500.0, 548500.0, 547500.0, 546500.0, 545500.0, 544500.0,\n       543500.0, 542500.0, 541500.0, 540500.0],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\nWe’ll assign the recharge to recharge package.\n\nrecharge_pkg_coarse = imod.mf6.Recharge(rate=recharge_ss_yearly)\n\nrecharge_pkg_coarse\n\nRecharge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 42kB\nDimensions:        (x: 46, y: 32, time: 7)\nCoordinates:\n  * x              (x) float64 368B 2.205e+05 2.215e+05 ... 2.645e+05 2.655e+05\n  * y              (y) float64 256B 5.715e+05 5.705e+05 ... 5.415e+05 5.405e+05\n    dx             float64 8B 1e+03\n    dy             float64 8B -1e+03\n  * time           (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31\n    layer          int64 8B 1\nData variables:\n    rate           (time, y, x) float32 41kB 0.0009011 0.0009115 ... 0.001175\n    print_input    bool 1B False\n    print_flows    bool 1B False\n    save_flows     bool 1B False\n    observations   object 8B None\n    repeat_stress  object 8B None\n    fixed_cell     bool 1B Falsexarray.DatasetDimensions:x: 46y: 32time: 7Coordinates: (6)x(x)float642.205e+05 2.215e+05 ... 2.655e+05array([220500., 221500., 222500., 223500., 224500., 225500., 226500., 227500.,\n       228500., 229500., 230500., 231500., 232500., 233500., 234500., 235500.,\n       236500., 237500., 238500., 239500., 240500., 241500., 242500., 243500.,\n       244500., 245500., 246500., 247500., 248500., 249500., 250500., 251500.,\n       252500., 253500., 254500., 255500., 256500., 257500., 258500., 259500.,\n       260500., 261500., 262500., 263500., 264500., 265500.])y(y)float645.715e+05 5.705e+05 ... 5.405e+05array([571500., 570500., 569500., 568500., 567500., 566500., 565500., 564500.,\n       563500., 562500., 561500., 560500., 559500., 558500., 557500., 556500.,\n       555500., 554500., 553500., 552500., 551500., 550500., 549500., 548500.,\n       547500., 546500., 545500., 544500., 543500., 542500., 541500., 540500.])dx()float641e+03array(1000.)dy()float64-1e+03array(-1000.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')layer()int641array(1)Data variables: (7)rate(time, y, x)float320.0009011 0.0009115 ... 0.001175array([[[0.00090112, 0.00091149, 0.00092218, ..., 0.00089727,\n         0.00091131, 0.00091922],\n        [0.00089882, 0.00090778, 0.0009161 , ..., 0.00087254,\n         0.00087931, 0.00088026],\n        [0.00089744, 0.00090371, 0.00091122, ..., 0.00084502,\n         0.00084642, 0.00084295],\n        ...,\n        [0.0009712 , 0.00098286, 0.00099209, ..., 0.00082975,\n         0.00082282, 0.00081758],\n        [0.00097145, 0.00098481, 0.00099601, ..., 0.00083164,\n         0.00082395, 0.00081767],\n        [0.00097266, 0.0009871 , 0.00100034, ..., 0.00083168,\n         0.00082356, 0.00081632]],\n\n       [[0.00073594, 0.00074953, 0.00076365, ..., 0.00065445,\n         0.00066929, 0.00068409],\n        [0.00073745, 0.00074902, 0.00076116, ..., 0.00063818,\n         0.00065288, 0.00066111],\n        [0.00073997, 0.00074967, 0.00076049, ..., 0.00062062,\n         0.00063231, 0.00064009],\n...\n        [0.00084628, 0.00086339, 0.00087912, ..., 0.00062002,\n         0.00062491, 0.00063112],\n        [0.00085344, 0.00087211, 0.00088709, ..., 0.00062375,\n         0.00062804, 0.00063361],\n        [0.00085948, 0.00088016, 0.00089779, ..., 0.00062747,\n         0.00063116, 0.00063512]],\n\n       [[0.00124327, 0.00125586, 0.00126757, ..., 0.0011327 ,\n         0.00113055, 0.00112583],\n        [0.00125251, 0.00126371, 0.00127229, ..., 0.00111782,\n         0.00111317, 0.00110813],\n        [0.00126285, 0.00127107, 0.00127818, ..., 0.00110242,\n         0.00109554, 0.00108874],\n        ...,\n        [0.0014347 , 0.00144276, 0.00144917, ..., 0.00118225,\n         0.00118231, 0.0011821 ],\n        [0.00142494, 0.00143413, 0.00144147, ..., 0.00118101,\n         0.00118035, 0.00117977],\n        [0.00141579, 0.00142525, 0.0014342 , ..., 0.0011771 ,\n         0.0011758 , 0.00117499]]], dtype=float32)print_input()boolFalsearray(False)print_flows()boolFalsearray(False)save_flows()boolFalsearray(False)observations()objectNonearray(None, dtype=object)repeat_stress()objectNonearray(None, dtype=object)fixed_cell()boolFalsearray(False)Indexes: (3)xPandasIndexPandasIndex(Index([220500.0, 221500.0, 222500.0, 223500.0, 224500.0, 225500.0, 226500.0,\n       227500.0, 228500.0, 229500.0, 230500.0, 231500.0, 232500.0, 233500.0,\n       234500.0, 235500.0, 236500.0, 237500.0, 238500.0, 239500.0, 240500.0,\n       241500.0, 242500.0, 243500.0, 244500.0, 245500.0, 246500.0, 247500.0,\n       248500.0, 249500.0, 250500.0, 251500.0, 252500.0, 253500.0, 254500.0,\n       255500.0, 256500.0, 257500.0, 258500.0, 259500.0, 260500.0, 261500.0,\n       262500.0, 263500.0, 264500.0, 265500.0],\n      dtype='float64', name='x'))yPandasIndexPandasIndex(Index([571500.0, 570500.0, 569500.0, 568500.0, 567500.0, 566500.0, 565500.0,\n       564500.0, 563500.0, 562500.0, 561500.0, 560500.0, 559500.0, 558500.0,\n       557500.0, 556500.0, 555500.0, 554500.0, 553500.0, 552500.0, 551500.0,\n       550500.0, 549500.0, 548500.0, 547500.0, 546500.0, 545500.0, 544500.0,\n       543500.0, 542500.0, 541500.0, 540500.0],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\nThis recharge package is defined on a coarse grid and not the model grid. iMOD Python has functionality regrid_like to regrid model packages to the appropriate grid. We’ll use the first layer of the idomain in our model as the template grid.\nNote that we create a RegridderWeightsCache here. This will store the weights of the regridder. Using the same cache to regrid another package will lead to a performance increase if that package uses the same regridding method, because initializing a regridder is costly.\n\nfrom imod.mf6.utilities.regrid import RegridderWeightsCache\n\ntemplate_grid = gwf_model[\"dis\"][\"idomain\"].sel(layer=1)\n\nregrid_context = RegridderWeightsCache()\nrecharge_pkg = recharge_pkg_coarse.regrid_like(template_grid, regrid_context)\n\nrecharge_pkg\n\nRecharge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3MB\nDimensions:        (time: 7, y: 200, x: 500)\nCoordinates:\n    dx             float64 8B 25.0\n    dy             float64 8B -25.0\n  * time           (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31\n    layer          int64 8B 1\n  * y              (y) float64 2kB 5.64e+05 5.64e+05 ... 5.59e+05 5.59e+05\n  * x              (x) float64 4kB 2.375e+05 2.375e+05 ... 2.5e+05 2.5e+05\nData variables:\n    rate           (time, y, x) float32 3MB 0.0008994 0.0008994 ... 0.001361\n    print_input    bool 1B False\n    print_flows    bool 1B False\n    save_flows     bool 1B False\n    observations   object 8B None\n    repeat_stress  object 8B None\n    fixed_cell     bool 1B Falsexarray.DatasetDimensions:time: 7y: 200x: 500Coordinates: (6)dx()float6425.0array(25.)dy()float64-25.0array(-25.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')layer()int641array(1)y(y)float645.64e+05 5.64e+05 ... 5.59e+05array([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5, 563737.5, 563712.5, 563687.5, 563662.5,\n       563637.5, 563612.5, 563587.5, 563562.5, 563537.5, 563512.5, 563487.5,\n       563462.5, 563437.5, 563412.5, 563387.5, 563362.5, 563337.5, 563312.5,\n       563287.5, 563262.5, 563237.5, 563212.5, 563187.5, 563162.5, 563137.5,\n       563112.5, 563087.5, 563062.5, 563037.5, 563012.5, 562987.5, 562962.5,\n       562937.5, 562912.5, 562887.5, 562862.5, 562837.5, 562812.5, 562787.5,\n       562762.5, 562737.5, 562712.5, 562687.5, 562662.5, 562637.5, 562612.5,\n       562587.5, 562562.5, 562537.5, 562512.5, 562487.5, 562462.5, 562437.5,\n       562412.5, 562387.5, 562362.5, 562337.5, 562312.5, 562287.5, 562262.5,\n       562237.5, 562212.5, 562187.5, 562162.5, 562137.5, 562112.5, 562087.5,\n       562062.5, 562037.5, 562012.5, 561987.5, 561962.5, 561937.5, 561912.5,\n       561887.5, 561862.5, 561837.5, 561812.5, 561787.5, 561762.5, 561737.5,\n       561712.5, 561687.5, 561662.5, 561637.5, 561612.5, 561587.5, 561562.5,\n       561537.5, 561512.5, 561487.5, 561462.5, 561437.5, 561412.5, 561387.5,\n       561362.5, 561337.5, 561312.5, 561287.5, 561262.5, 561237.5, 561212.5,\n       561187.5, 561162.5, 561137.5, 561112.5, 561087.5, 561062.5, 561037.5,\n       561012.5, 560987.5, 560962.5, 560937.5, 560912.5, 560887.5, 560862.5,\n       560837.5, 560812.5, 560787.5, 560762.5, 560737.5, 560712.5, 560687.5,\n       560662.5, 560637.5, 560612.5, 560587.5, 560562.5, 560537.5, 560512.5,\n       560487.5, 560462.5, 560437.5, 560412.5, 560387.5, 560362.5, 560337.5,\n       560312.5, 560287.5, 560262.5, 560237.5, 560212.5, 560187.5, 560162.5,\n       560137.5, 560112.5, 560087.5, 560062.5, 560037.5, 560012.5, 559987.5,\n       559962.5, 559937.5, 559912.5, 559887.5, 559862.5, 559837.5, 559812.5,\n       559787.5, 559762.5, 559737.5, 559712.5, 559687.5, 559662.5, 559637.5,\n       559612.5, 559587.5, 559562.5, 559537.5, 559512.5, 559487.5, 559462.5,\n       559437.5, 559412.5, 559387.5, 559362.5, 559337.5, 559312.5, 559287.5,\n       559262.5, 559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5,\n       559087.5, 559062.5, 559037.5, 559012.5])x(x)float642.375e+05 2.375e+05 ... 2.5e+05array([237512.5, 237537.5, 237562.5, ..., 249937.5, 249962.5, 249987.5])Data variables: (7)rate(time, y, x)float320.0008994 0.0008994 ... 0.001361array([[[0.00089943, 0.00089943, 0.00089943, ..., 0.00083373,\n         0.00083373, 0.00083373],\n        [0.00089943, 0.00089943, 0.00089943, ..., 0.00083373,\n         0.00083373, 0.00083373],\n        [0.00089943, 0.00089943, 0.00089943, ..., 0.00083373,\n         0.00083373, 0.00083373],\n        ...,\n        [0.00091826, 0.00091826, 0.00091826, ..., 0.00088319,\n         0.00088319, 0.00088319],\n        [0.00091826, 0.00091826, 0.00091826, ..., 0.00088319,\n         0.00088319, 0.00088319],\n        [0.00091826, 0.00091826, 0.00091826, ..., 0.00088319,\n         0.00088319, 0.00088319]],\n\n       [[0.00079024, 0.00079024, 0.00079024, ..., 0.00049993,\n         0.00049993, 0.00049993],\n        [0.00079024, 0.00079024, 0.00079024, ..., 0.00049993,\n         0.00049993, 0.00049993],\n        [0.00079024, 0.00079024, 0.00079024, ..., 0.00049993,\n         0.00049993, 0.00049993],\n...\n        [0.00065345, 0.00065345, 0.00065345, ..., 0.0005451 ,\n         0.0005451 , 0.0005451 ],\n        [0.00065345, 0.00065345, 0.00065345, ..., 0.0005451 ,\n         0.0005451 , 0.0005451 ],\n        [0.00065345, 0.00065345, 0.00065345, ..., 0.0005451 ,\n         0.0005451 , 0.0005451 ]],\n\n       [[0.00130635, 0.00130635, 0.00130635, ..., 0.00128316,\n         0.00128316, 0.00128316],\n        [0.00130635, 0.00130635, 0.00130635, ..., 0.00128316,\n         0.00128316, 0.00128316],\n        [0.00130635, 0.00130635, 0.00130635, ..., 0.00128316,\n         0.00128316, 0.00128316],\n        ...,\n        [0.00140879, 0.00140879, 0.00140879, ..., 0.0013607 ,\n         0.0013607 , 0.0013607 ],\n        [0.00140879, 0.00140879, 0.00140879, ..., 0.0013607 ,\n         0.0013607 , 0.0013607 ],\n        [0.00140879, 0.00140879, 0.00140879, ..., 0.0013607 ,\n         0.0013607 , 0.0013607 ]]], dtype=float32)print_input()boolFalsearray(False)print_flows()boolFalsearray(False)save_flows()boolFalsearray(False)observations()objectNonearray(None, dtype=object)repeat_stress()objectNonearray(None, dtype=object)fixed_cell()boolFalsearray(False)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))yPandasIndexPandasIndex(Index([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5,\n       ...\n       559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5, 559087.5,\n       559062.5, 559037.5, 559012.5],\n      dtype='float64', name='y', length=200))xPandasIndexPandasIndex(Index([237512.5, 237537.5, 237562.5, 237587.5, 237612.5, 237637.5, 237662.5,\n       237687.5, 237712.5, 237737.5,\n       ...\n       249762.5, 249787.5, 249812.5, 249837.5, 249862.5, 249887.5, 249912.5,\n       249937.5, 249962.5, 249987.5],\n      dtype='float64', name='x', length=500))Attributes: (0)\n\n\nMODFLOW 6 does not accept recharge cells which are assigned to inactive cells (where idomain != 1). iMOD Python therefore has convenience functions to get the upper active layer\n\nfrom imod.prepare import get_upper_active_grid_cells\n\n# Select the grid cells where idomain == 1, these are the active cells.\nidomain = gwf_model[\"dis\"][\"idomain\"]\nis_active = idomain == 1\n# Find the upper active cells\nis_upper_active_grid = get_upper_active_grid_cells(is_active)\n# We can use xarrays where method to broadcast the recharge rates to the upper\n# active cells.\nrecharge_pkg[\"rate\"] = recharge_pkg[\"rate\"].where(is_upper_active_grid)\n# Finally reorder the dimensions of the dataset to how it is expected by iMOD\n# Python.\nrecharge_pkg.dataset = recharge_pkg.dataset.transpose(\"time\", \"layer\", \"y\", \"x\")\n\nrecharge_pkg\n\nRecharge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 36MB\nDimensions:        (time: 7, layer: 13, y: 200, x: 500)\nCoordinates:\n    dx             float64 8B 25.0\n    dy             float64 8B -25.0\n  * time           (time) datetime64[ns] 56B 2009-12-30T23:59:59 ... 2014-12-31\n  * layer          (layer) int32 52B 1 2 3 4 5 6 7 8 9 10 11 12 13\n  * y              (y) float64 2kB 5.64e+05 5.64e+05 ... 5.59e+05 5.59e+05\n  * x              (x) float64 4kB 2.375e+05 2.375e+05 ... 2.5e+05 2.5e+05\nData variables:\n    rate           (time, layer, y, x) float32 36MB nan nan nan ... nan nan nan\n    print_input    bool 1B False\n    print_flows    bool 1B False\n    save_flows     bool 1B False\n    observations   object 8B None\n    repeat_stress  object 8B None\n    fixed_cell     bool 1B Falsexarray.DatasetDimensions:time: 7layer: 13y: 200x: 500Coordinates: (6)dx()float6425.0array(25.)dy()float64-25.0array(-25.)time(time)datetime64[ns]2009-12-30T23:59:59 ... 2014-12-31array(['2009-12-30T23:59:59.000000000', '2009-12-31T00:00:00.000000000',\n       '2010-12-31T00:00:00.000000000', '2011-12-31T00:00:00.000000000',\n       '2012-12-31T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-12-31T00:00:00.000000000'], dtype='datetime64[ns]')layer(layer)int321 2 3 4 5 6 7 8 9 10 11 12 13array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int32)y(y)float645.64e+05 5.64e+05 ... 5.59e+05array([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5, 563737.5, 563712.5, 563687.5, 563662.5,\n       563637.5, 563612.5, 563587.5, 563562.5, 563537.5, 563512.5, 563487.5,\n       563462.5, 563437.5, 563412.5, 563387.5, 563362.5, 563337.5, 563312.5,\n       563287.5, 563262.5, 563237.5, 563212.5, 563187.5, 563162.5, 563137.5,\n       563112.5, 563087.5, 563062.5, 563037.5, 563012.5, 562987.5, 562962.5,\n       562937.5, 562912.5, 562887.5, 562862.5, 562837.5, 562812.5, 562787.5,\n       562762.5, 562737.5, 562712.5, 562687.5, 562662.5, 562637.5, 562612.5,\n       562587.5, 562562.5, 562537.5, 562512.5, 562487.5, 562462.5, 562437.5,\n       562412.5, 562387.5, 562362.5, 562337.5, 562312.5, 562287.5, 562262.5,\n       562237.5, 562212.5, 562187.5, 562162.5, 562137.5, 562112.5, 562087.5,\n       562062.5, 562037.5, 562012.5, 561987.5, 561962.5, 561937.5, 561912.5,\n       561887.5, 561862.5, 561837.5, 561812.5, 561787.5, 561762.5, 561737.5,\n       561712.5, 561687.5, 561662.5, 561637.5, 561612.5, 561587.5, 561562.5,\n       561537.5, 561512.5, 561487.5, 561462.5, 561437.5, 561412.5, 561387.5,\n       561362.5, 561337.5, 561312.5, 561287.5, 561262.5, 561237.5, 561212.5,\n       561187.5, 561162.5, 561137.5, 561112.5, 561087.5, 561062.5, 561037.5,\n       561012.5, 560987.5, 560962.5, 560937.5, 560912.5, 560887.5, 560862.5,\n       560837.5, 560812.5, 560787.5, 560762.5, 560737.5, 560712.5, 560687.5,\n       560662.5, 560637.5, 560612.5, 560587.5, 560562.5, 560537.5, 560512.5,\n       560487.5, 560462.5, 560437.5, 560412.5, 560387.5, 560362.5, 560337.5,\n       560312.5, 560287.5, 560262.5, 560237.5, 560212.5, 560187.5, 560162.5,\n       560137.5, 560112.5, 560087.5, 560062.5, 560037.5, 560012.5, 559987.5,\n       559962.5, 559937.5, 559912.5, 559887.5, 559862.5, 559837.5, 559812.5,\n       559787.5, 559762.5, 559737.5, 559712.5, 559687.5, 559662.5, 559637.5,\n       559612.5, 559587.5, 559562.5, 559537.5, 559512.5, 559487.5, 559462.5,\n       559437.5, 559412.5, 559387.5, 559362.5, 559337.5, 559312.5, 559287.5,\n       559262.5, 559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5,\n       559087.5, 559062.5, 559037.5, 559012.5])x(x)float642.375e+05 2.375e+05 ... 2.5e+05array([237512.5, 237537.5, 237562.5, ..., 249937.5, 249962.5, 249987.5])Data variables: (7)rate(time, layer, y, x)float32nan nan nan nan ... nan nan nan nanarray([[[[       nan,        nan,        nan, ..., 0.00083373,\n          0.00083373, 0.00083373],\n         [       nan,        nan,        nan, ..., 0.00083373,\n          0.00083373, 0.00083373],\n         [       nan,        nan,        nan, ..., 0.00083373,\n          0.00083373, 0.00083373],\n         ...,\n         [0.00091826, 0.00091826, 0.00091826, ...,        nan,\n                 nan,        nan],\n         [0.00091826, 0.00091826, 0.00091826, ...,        nan,\n                 nan,        nan],\n         [0.00091826, 0.00091826, 0.00091826, ...,        nan,\n                 nan,        nan]],\n\n        [[       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n...\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan]],\n\n        [[       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         ...,\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan],\n         [       nan,        nan,        nan, ...,        nan,\n                 nan,        nan]]]], dtype=float32)print_input()boolFalsearray(False)print_flows()boolFalsearray(False)save_flows()boolFalsearray(False)observations()objectNonearray(None, dtype=object)repeat_stress()objectNonearray(None, dtype=object)fixed_cell()boolFalsearray(False)Indexes: (4)timePandasIndexPandasIndex(DatetimeIndex(['2009-12-30 23:59:59', '2009-12-31 00:00:00',\n               '2010-12-31 00:00:00', '2011-12-31 00:00:00',\n               '2012-12-31 00:00:00', '2013-12-31 00:00:00',\n               '2014-12-31 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))layerPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int32', name='layer'))yPandasIndexPandasIndex(Index([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5,\n       ...\n       559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5, 559087.5,\n       559062.5, 559037.5, 559012.5],\n      dtype='float64', name='y', length=200))xPandasIndexPandasIndex(Index([237512.5, 237537.5, 237562.5, 237587.5, 237612.5, 237637.5, 237662.5,\n       237687.5, 237712.5, 237737.5,\n       ...\n       249762.5, 249787.5, 249812.5, 249837.5, 249862.5, 249887.5, 249912.5,\n       249937.5, 249962.5, 249987.5],\n      dtype='float64', name='x', length=500))Attributes: (0)\n\n\nWe’ll override the recharge package with our newly computed recharge package\n\ngwf_model[\"rch\"] = recharge_pkg\n\nWrite the simulation and run it again\n\nmodeldir = prj_dir / \"new_recharge\"\nsimulation.write(modeldir)\nsimulation.run(mf6_path)\n\n\n# Open heads\nhead_new_recharge = simulation.open_head()\n\nhead_new_recharge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'head' (time: 7, layer: 13, y: 200, x: 500)&gt; Size: 73MB\ndask.array&lt;stack, shape=(7, 13, 200, 500), dtype=float64, chunksize=(1, 13, 200, 500), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * x        (x) float64 4kB 2.375e+05 2.375e+05 2.376e+05 ... 2.5e+05 2.5e+05\n  * y        (y) float64 2kB 5.64e+05 5.64e+05 5.639e+05 ... 5.59e+05 5.59e+05\n    dx       float64 8B 25.0\n    dy       float64 8B -25.0\n  * layer    (layer) int64 104B 1 2 3 4 5 6 7 8 9 10 11 12 13\n  * time     (time) float64 56B 1.157e-05 365.0 730.0 ... 1.826e+03 2.191e+03xarray.DataArray'head'time: 7layer: 13y: 200x: 500dask.array&lt;chunksize=(1, 13, 200, 500), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n69.43 MiB\n9.92 MiB\n\n\nShape\n(7, 13, 200, 500)\n(1, 13, 200, 500)\n\n\nDask graph\n7 chunks in 15 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n               7 1                          500 200 13\n\n\n\n\nCoordinates: (6)x(x)float642.375e+05 2.375e+05 ... 2.5e+05array([237512.5, 237537.5, 237562.5, ..., 249937.5, 249962.5, 249987.5])y(y)float645.64e+05 5.64e+05 ... 5.59e+05array([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5, 563737.5, 563712.5, 563687.5, 563662.5,\n       563637.5, 563612.5, 563587.5, 563562.5, 563537.5, 563512.5, 563487.5,\n       563462.5, 563437.5, 563412.5, 563387.5, 563362.5, 563337.5, 563312.5,\n       563287.5, 563262.5, 563237.5, 563212.5, 563187.5, 563162.5, 563137.5,\n       563112.5, 563087.5, 563062.5, 563037.5, 563012.5, 562987.5, 562962.5,\n       562937.5, 562912.5, 562887.5, 562862.5, 562837.5, 562812.5, 562787.5,\n       562762.5, 562737.5, 562712.5, 562687.5, 562662.5, 562637.5, 562612.5,\n       562587.5, 562562.5, 562537.5, 562512.5, 562487.5, 562462.5, 562437.5,\n       562412.5, 562387.5, 562362.5, 562337.5, 562312.5, 562287.5, 562262.5,\n       562237.5, 562212.5, 562187.5, 562162.5, 562137.5, 562112.5, 562087.5,\n       562062.5, 562037.5, 562012.5, 561987.5, 561962.5, 561937.5, 561912.5,\n       561887.5, 561862.5, 561837.5, 561812.5, 561787.5, 561762.5, 561737.5,\n       561712.5, 561687.5, 561662.5, 561637.5, 561612.5, 561587.5, 561562.5,\n       561537.5, 561512.5, 561487.5, 561462.5, 561437.5, 561412.5, 561387.5,\n       561362.5, 561337.5, 561312.5, 561287.5, 561262.5, 561237.5, 561212.5,\n       561187.5, 561162.5, 561137.5, 561112.5, 561087.5, 561062.5, 561037.5,\n       561012.5, 560987.5, 560962.5, 560937.5, 560912.5, 560887.5, 560862.5,\n       560837.5, 560812.5, 560787.5, 560762.5, 560737.5, 560712.5, 560687.5,\n       560662.5, 560637.5, 560612.5, 560587.5, 560562.5, 560537.5, 560512.5,\n       560487.5, 560462.5, 560437.5, 560412.5, 560387.5, 560362.5, 560337.5,\n       560312.5, 560287.5, 560262.5, 560237.5, 560212.5, 560187.5, 560162.5,\n       560137.5, 560112.5, 560087.5, 560062.5, 560037.5, 560012.5, 559987.5,\n       559962.5, 559937.5, 559912.5, 559887.5, 559862.5, 559837.5, 559812.5,\n       559787.5, 559762.5, 559737.5, 559712.5, 559687.5, 559662.5, 559637.5,\n       559612.5, 559587.5, 559562.5, 559537.5, 559512.5, 559487.5, 559462.5,\n       559437.5, 559412.5, 559387.5, 559362.5, 559337.5, 559312.5, 559287.5,\n       559262.5, 559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5,\n       559087.5, 559062.5, 559037.5, 559012.5])dx()float6425.0array(25.)dy()float64-25.0array(-25.)layer(layer)int641 2 3 4 5 6 7 8 9 10 11 12 13array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])time(time)float641.157e-05 365.0 ... 2.191e+03array([1.157407e-05, 3.650000e+02, 7.300000e+02, 1.096000e+03, 1.461000e+03,\n       1.826000e+03, 2.191000e+03])Indexes: (4)xPandasIndexPandasIndex(Index([237512.5, 237537.5, 237562.5, 237587.5, 237612.5, 237637.5, 237662.5,\n       237687.5, 237712.5, 237737.5,\n       ...\n       249762.5, 249787.5, 249812.5, 249837.5, 249862.5, 249887.5, 249912.5,\n       249937.5, 249962.5, 249987.5],\n      dtype='float64', name='x', length=500))yPandasIndexPandasIndex(Index([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5,\n       ...\n       559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5, 559087.5,\n       559062.5, 559037.5, 559012.5],\n      dtype='float64', name='y', length=200))layerPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int64', name='layer'))timePandasIndexPandasIndex(Index([1.1574074074074073e-05,     365.00001157407405,       730.000011574074,\n            1096.000011574074,      1461.000011574074,      1826.000011574074,\n            2191.000011574074],\n      dtype='float64', name='time'))Attributes: (0)\n\n\n\n\ndiff_new_rch = head_new_recharge - calculated_heads\n\ndiff_new_rch_end_first_aqf = (\n    diff_new_rch.isel(time=-1).sel(layer=slice(3, 5)).mean(dim=\"layer\")\n)\n\nlevels = np.arange(-10.0, 0.0, 1.0)\n\nimod.visualize.plot_map(\n    diff_new_rch_end_first_aqf, \"hot\", levels, basemap=background_map\n)",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#create-geology-dataset",
    "href": "tutorial_Hondsrug.html#create-geology-dataset",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Create geology dataset",
    "text": "Create geology dataset\nThe “permeability” of the model is available in the “npf” package of our model. So we start to fill a new “geology” dataset with this “k” value.\n\ngeology = gwf_model[\"npf\"][\"k\"]\n\nThe “top” and “bottom” information of layers is available in the “dis” package. Unfortunately the “dis” package has bottom information for all layers but only top information for layer 1. Check this in the next cell.\n\ngwf_model[\"dis\"]\n\nStructuredDiscretization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 11MB\nDimensions:  (x: 500, y: 200, layer: 13)\nCoordinates:\n  * x        (x) float64 4kB 2.375e+05 2.375e+05 2.376e+05 ... 2.5e+05 2.5e+05\n  * y        (y) float64 2kB 5.64e+05 5.64e+05 5.639e+05 ... 5.59e+05 5.59e+05\n    dx       float64 8B 25.0\n    dy       float64 8B -25.0\n  * layer    (layer) int32 52B 1 2 3 4 5 6 7 8 9 10 11 12 13\nData variables:\n    idomain  (layer, y, x) int32 5MB -1 -1 -1 -1 -1 -1 -1 -1 ... 1 1 1 1 1 1 1 1\n    top      (y, x) float32 400kB 6.329 6.329 6.329 6.329 ... 3.198 3.198 3.198\n    bottom   (layer, y, x) float32 5MB 6.329 6.329 6.329 ... -166.8 -166.8xarray.DatasetDimensions:x: 500y: 200layer: 13Coordinates: (5)x(x)float642.375e+05 2.375e+05 ... 2.5e+05array([237512.5, 237537.5, 237562.5, ..., 249937.5, 249962.5, 249987.5])y(y)float645.64e+05 5.64e+05 ... 5.59e+05array([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5, 563737.5, 563712.5, 563687.5, 563662.5,\n       563637.5, 563612.5, 563587.5, 563562.5, 563537.5, 563512.5, 563487.5,\n       563462.5, 563437.5, 563412.5, 563387.5, 563362.5, 563337.5, 563312.5,\n       563287.5, 563262.5, 563237.5, 563212.5, 563187.5, 563162.5, 563137.5,\n       563112.5, 563087.5, 563062.5, 563037.5, 563012.5, 562987.5, 562962.5,\n       562937.5, 562912.5, 562887.5, 562862.5, 562837.5, 562812.5, 562787.5,\n       562762.5, 562737.5, 562712.5, 562687.5, 562662.5, 562637.5, 562612.5,\n       562587.5, 562562.5, 562537.5, 562512.5, 562487.5, 562462.5, 562437.5,\n       562412.5, 562387.5, 562362.5, 562337.5, 562312.5, 562287.5, 562262.5,\n       562237.5, 562212.5, 562187.5, 562162.5, 562137.5, 562112.5, 562087.5,\n       562062.5, 562037.5, 562012.5, 561987.5, 561962.5, 561937.5, 561912.5,\n       561887.5, 561862.5, 561837.5, 561812.5, 561787.5, 561762.5, 561737.5,\n       561712.5, 561687.5, 561662.5, 561637.5, 561612.5, 561587.5, 561562.5,\n       561537.5, 561512.5, 561487.5, 561462.5, 561437.5, 561412.5, 561387.5,\n       561362.5, 561337.5, 561312.5, 561287.5, 561262.5, 561237.5, 561212.5,\n       561187.5, 561162.5, 561137.5, 561112.5, 561087.5, 561062.5, 561037.5,\n       561012.5, 560987.5, 560962.5, 560937.5, 560912.5, 560887.5, 560862.5,\n       560837.5, 560812.5, 560787.5, 560762.5, 560737.5, 560712.5, 560687.5,\n       560662.5, 560637.5, 560612.5, 560587.5, 560562.5, 560537.5, 560512.5,\n       560487.5, 560462.5, 560437.5, 560412.5, 560387.5, 560362.5, 560337.5,\n       560312.5, 560287.5, 560262.5, 560237.5, 560212.5, 560187.5, 560162.5,\n       560137.5, 560112.5, 560087.5, 560062.5, 560037.5, 560012.5, 559987.5,\n       559962.5, 559937.5, 559912.5, 559887.5, 559862.5, 559837.5, 559812.5,\n       559787.5, 559762.5, 559737.5, 559712.5, 559687.5, 559662.5, 559637.5,\n       559612.5, 559587.5, 559562.5, 559537.5, 559512.5, 559487.5, 559462.5,\n       559437.5, 559412.5, 559387.5, 559362.5, 559337.5, 559312.5, 559287.5,\n       559262.5, 559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5,\n       559087.5, 559062.5, 559037.5, 559012.5])dx()float6425.0array(25.)dy()float64-25.0array(-25.)layer(layer)int321 2 3 4 5 6 7 8 9 10 11 12 13array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int32)Data variables: (3)idomain(layer, y, x)int32-1 -1 -1 -1 -1 -1 ... 1 1 1 1 1 1array([[[-1, -1, ...,  1,  1],\n        [-1, -1, ...,  1,  1],\n        ...,\n        [ 1,  1, ..., -1, -1],\n        [ 1,  1, ..., -1, -1]],\n\n       [[-1, -1, ..., -1, -1],\n        [-1, -1, ..., -1, -1],\n        ...,\n        [-1, -1, ..., -1, -1],\n        [-1, -1, ..., -1, -1]],\n\n       ...,\n\n       [[ 1,  1, ..., -1, -1],\n        [ 1,  1, ..., -1, -1],\n        ...,\n        [-1, -1, ..., -1, -1],\n        [-1, -1, ..., -1, -1]],\n\n       [[ 1,  1, ...,  1,  1],\n        [ 1,  1, ...,  1,  1],\n        ...,\n        [ 1,  1, ...,  1,  1],\n        [ 1,  1, ...,  1,  1]]], dtype=int32)top(y, x)float326.329 6.329 6.329 ... 3.198 3.198array([[6.3288, 6.3288, 6.3288, ..., 2.5116, 2.5116, 2.5116],\n       [6.3288, 6.3288, 6.3288, ..., 2.5116, 2.5116, 2.5116],\n       [6.3288, 6.3288, 6.3288, ..., 2.5116, 2.5116, 2.5116],\n       ...,\n       [9.4252, 9.4252, 9.4252, ..., 3.1984, 3.1984, 3.1984],\n       [9.4252, 9.4252, 9.4252, ..., 3.1984, 3.1984, 3.1984],\n       [9.4252, 9.4252, 9.4252, ..., 3.1984, 3.1984, 3.1984]], dtype=float32)bottom(layer, y, x)float326.329 6.329 6.329 ... -166.8 -166.8array([[[   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        [   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        ...,\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984],\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984]],\n\n       [[   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        [   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        ...,\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984],\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984]],\n\n       ...,\n\n       [[ -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ],\n        [ -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ],\n        ...,\n        [-100.5972, -100.5972, ...,  -88.6608,  -88.6608],\n        [-100.5972, -100.5972, ...,  -88.6608,  -88.6608]],\n\n       [[-161.11  , -161.11  , ..., -187.276 , -187.276 ],\n        [-161.11  , -161.11  , ..., -187.276 , -187.276 ],\n        ...,\n        [-175.28  , -175.28  , ..., -166.763 , -166.763 ],\n        [-175.28  , -175.28  , ..., -166.763 , -166.763 ]]], dtype=float32)Indexes: (3)xPandasIndexPandasIndex(Index([237512.5, 237537.5, 237562.5, 237587.5, 237612.5, 237637.5, 237662.5,\n       237687.5, 237712.5, 237737.5,\n       ...\n       249762.5, 249787.5, 249812.5, 249837.5, 249862.5, 249887.5, 249912.5,\n       249937.5, 249962.5, 249987.5],\n      dtype='float64', name='x', length=500))yPandasIndexPandasIndex(Index([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5,\n       ...\n       559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5, 559087.5,\n       559062.5, 559037.5, 559012.5],\n      dtype='float64', name='y', length=200))layerPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int32', name='layer'))Attributes: (0)\n\n\nSo first we add the bottom information to our geology dataset.\n\ngeology[\"bottom\"] = gwf_model[\"dis\"][\"bottom\"]\n\nThen we define the top of layer 1 to be the Digital Elevation Model (DEM). Next, for layer 2 to 13, we must fill in the top of each layer with the bottom of the layer above (e.g. top_l5 = bot_l4). Seems like a bit complicated? No, we can use the .shift function of xarray for this.\n\nDEM = gwf_model[\"dis\"][\"top\"]\ngeology[\"top\"] = geology[\"bottom\"].shift(layer=1).fillna(DEM)\n\n# Check the content of geology data set\ngeology\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'k' (layer: 13, y: 200, x: 500)&gt; Size: 5MB\narray([[[         nan,          nan, ..., 1.920480e+00, 1.278839e+00],\n        [         nan,          nan, ..., 2.145113e+00, 1.355379e+00],\n        ...,\n        [6.763072e+00, 6.812381e+00, ...,          nan,          nan],\n        [6.414862e+00, 6.477612e+00, ...,          nan,          nan]],\n\n       [[         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan],\n        ...,\n        [         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan]],\n\n       ...,\n\n       [[1.272980e-02, 1.285313e-02, ...,          nan,          nan],\n        [1.277280e-02, 1.289399e-02, ...,          nan,          nan],\n        ...,\n        [         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan]],\n\n       [[3.516399e+01, 3.485885e+01, ..., 1.119886e+01, 1.121270e+01],\n        [3.528433e+01, 3.501910e+01, ..., 1.110936e+01, 1.112595e+01],\n        ...,\n        [5.159515e+01, 5.125692e+01, ..., 5.953558e+00, 6.546909e+00],\n        [5.167937e+01, 5.132092e+01, ..., 5.624361e+00, 6.212296e+00]]],\n      dtype=float32)\nCoordinates:\n  * x        (x) float64 4kB 2.375e+05 2.375e+05 2.376e+05 ... 2.5e+05 2.5e+05\n  * y        (y) float64 2kB 5.64e+05 5.64e+05 5.639e+05 ... 5.59e+05 5.59e+05\n    dx       float64 8B 25.0\n    dy       float64 8B -25.0\n  * layer    (layer) int32 52B 1 2 3 4 5 6 7 8 9 10 11 12 13\n    bottom   (layer, y, x) float32 5MB 6.329 6.329 6.329 ... -166.8 -166.8\n    top      (layer, y, x) float32 5MB 6.329 6.329 6.329 ... -88.66 -88.66xarray.DataArray'k'layer: 13y: 200x: 500nan nan nan nan nan nan nan ... 4.396 4.555 4.712 4.87 5.624 6.212array([[[         nan,          nan, ..., 1.920480e+00, 1.278839e+00],\n        [         nan,          nan, ..., 2.145113e+00, 1.355379e+00],\n        ...,\n        [6.763072e+00, 6.812381e+00, ...,          nan,          nan],\n        [6.414862e+00, 6.477612e+00, ...,          nan,          nan]],\n\n       [[         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan],\n        ...,\n        [         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan]],\n\n       ...,\n\n       [[1.272980e-02, 1.285313e-02, ...,          nan,          nan],\n        [1.277280e-02, 1.289399e-02, ...,          nan,          nan],\n        ...,\n        [         nan,          nan, ...,          nan,          nan],\n        [         nan,          nan, ...,          nan,          nan]],\n\n       [[3.516399e+01, 3.485885e+01, ..., 1.119886e+01, 1.121270e+01],\n        [3.528433e+01, 3.501910e+01, ..., 1.110936e+01, 1.112595e+01],\n        ...,\n        [5.159515e+01, 5.125692e+01, ..., 5.953558e+00, 6.546909e+00],\n        [5.167937e+01, 5.132092e+01, ..., 5.624361e+00, 6.212296e+00]]],\n      dtype=float32)Coordinates: (7)x(x)float642.375e+05 2.375e+05 ... 2.5e+05array([237512.5, 237537.5, 237562.5, ..., 249937.5, 249962.5, 249987.5])y(y)float645.64e+05 5.64e+05 ... 5.59e+05array([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5, 563737.5, 563712.5, 563687.5, 563662.5,\n       563637.5, 563612.5, 563587.5, 563562.5, 563537.5, 563512.5, 563487.5,\n       563462.5, 563437.5, 563412.5, 563387.5, 563362.5, 563337.5, 563312.5,\n       563287.5, 563262.5, 563237.5, 563212.5, 563187.5, 563162.5, 563137.5,\n       563112.5, 563087.5, 563062.5, 563037.5, 563012.5, 562987.5, 562962.5,\n       562937.5, 562912.5, 562887.5, 562862.5, 562837.5, 562812.5, 562787.5,\n       562762.5, 562737.5, 562712.5, 562687.5, 562662.5, 562637.5, 562612.5,\n       562587.5, 562562.5, 562537.5, 562512.5, 562487.5, 562462.5, 562437.5,\n       562412.5, 562387.5, 562362.5, 562337.5, 562312.5, 562287.5, 562262.5,\n       562237.5, 562212.5, 562187.5, 562162.5, 562137.5, 562112.5, 562087.5,\n       562062.5, 562037.5, 562012.5, 561987.5, 561962.5, 561937.5, 561912.5,\n       561887.5, 561862.5, 561837.5, 561812.5, 561787.5, 561762.5, 561737.5,\n       561712.5, 561687.5, 561662.5, 561637.5, 561612.5, 561587.5, 561562.5,\n       561537.5, 561512.5, 561487.5, 561462.5, 561437.5, 561412.5, 561387.5,\n       561362.5, 561337.5, 561312.5, 561287.5, 561262.5, 561237.5, 561212.5,\n       561187.5, 561162.5, 561137.5, 561112.5, 561087.5, 561062.5, 561037.5,\n       561012.5, 560987.5, 560962.5, 560937.5, 560912.5, 560887.5, 560862.5,\n       560837.5, 560812.5, 560787.5, 560762.5, 560737.5, 560712.5, 560687.5,\n       560662.5, 560637.5, 560612.5, 560587.5, 560562.5, 560537.5, 560512.5,\n       560487.5, 560462.5, 560437.5, 560412.5, 560387.5, 560362.5, 560337.5,\n       560312.5, 560287.5, 560262.5, 560237.5, 560212.5, 560187.5, 560162.5,\n       560137.5, 560112.5, 560087.5, 560062.5, 560037.5, 560012.5, 559987.5,\n       559962.5, 559937.5, 559912.5, 559887.5, 559862.5, 559837.5, 559812.5,\n       559787.5, 559762.5, 559737.5, 559712.5, 559687.5, 559662.5, 559637.5,\n       559612.5, 559587.5, 559562.5, 559537.5, 559512.5, 559487.5, 559462.5,\n       559437.5, 559412.5, 559387.5, 559362.5, 559337.5, 559312.5, 559287.5,\n       559262.5, 559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5,\n       559087.5, 559062.5, 559037.5, 559012.5])dx()float6425.0array(25.)dy()float64-25.0array(-25.)layer(layer)int321 2 3 4 5 6 7 8 9 10 11 12 13array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int32)bottom(layer, y, x)float326.329 6.329 6.329 ... -166.8 -166.8array([[[   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        [   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        ...,\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984],\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984]],\n\n       [[   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        [   6.3288,    6.3288, ...,   -1.3848,   -1.3848],\n        ...,\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984],\n        [   8.1232,    8.1232, ...,    3.1984,    3.1984]],\n\n       ...,\n\n       [[ -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ],\n        [ -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ],\n        ...,\n        [-100.5972, -100.5972, ...,  -88.6608,  -88.6608],\n        [-100.5972, -100.5972, ...,  -88.6608,  -88.6608]],\n\n       [[-161.11  , -161.11  , ..., -187.276 , -187.276 ],\n        [-161.11  , -161.11  , ..., -187.276 , -187.276 ],\n        ...,\n        [-175.28  , -175.28  , ..., -166.763 , -166.763 ],\n        [-175.28  , -175.28  , ..., -166.763 , -166.763 ]]], dtype=float32)top(layer, y, x)float326.329 6.329 6.329 ... -88.66 -88.66array([[[   6.3288,    6.3288,    6.3288, ...,    2.5116,    2.5116,\n            2.5116],\n        [   6.3288,    6.3288,    6.3288, ...,    2.5116,    2.5116,\n            2.5116],\n        [   6.3288,    6.3288,    6.3288, ...,    2.5116,    2.5116,\n            2.5116],\n        ...,\n        [   9.4252,    9.4252,    9.4252, ...,    3.1984,    3.1984,\n            3.1984],\n        [   9.4252,    9.4252,    9.4252, ...,    3.1984,    3.1984,\n            3.1984],\n        [   9.4252,    9.4252,    9.4252, ...,    3.1984,    3.1984,\n            3.1984]],\n\n       [[   6.3288,    6.3288,    6.3288, ...,   -1.3848,   -1.3848,\n           -1.3848],\n        [   6.3288,    6.3288,    6.3288, ...,   -1.3848,   -1.3848,\n           -1.3848],\n        [   6.3288,    6.3288,    6.3288, ...,   -1.3848,   -1.3848,\n           -1.3848],\n...\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608],\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608],\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608]],\n\n       [[ -97.9576,  -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ,\n          -92.636 ],\n        [ -97.9576,  -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ,\n          -92.636 ],\n        [ -97.9576,  -97.9576,  -97.9576, ...,  -92.636 ,  -92.636 ,\n          -92.636 ],\n        ...,\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608],\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608],\n        [-100.5972, -100.5972, -100.5972, ...,  -88.6608,  -88.6608,\n          -88.6608]]], dtype=float32)Indexes: (3)xPandasIndexPandasIndex(Index([237512.5, 237537.5, 237562.5, 237587.5, 237612.5, 237637.5, 237662.5,\n       237687.5, 237712.5, 237737.5,\n       ...\n       249762.5, 249787.5, 249812.5, 249837.5, 249862.5, 249887.5, 249912.5,\n       249937.5, 249962.5, 249987.5],\n      dtype='float64', name='x', length=500))yPandasIndexPandasIndex(Index([563987.5, 563962.5, 563937.5, 563912.5, 563887.5, 563862.5, 563837.5,\n       563812.5, 563787.5, 563762.5,\n       ...\n       559237.5, 559212.5, 559187.5, 559162.5, 559137.5, 559112.5, 559087.5,\n       559062.5, 559037.5, 559012.5],\n      dtype='float64', name='y', length=200))layerPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int32', name='layer'))Attributes: (0)\n\n\nLet’s plot the top of our model, the DEM.\n\nlevels = compute_levels(DEM, 10)\nimod.visualize.plot_map(DEM, \"viridis\", levels, basemap=background_map)",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#plot-cross-section",
    "href": "tutorial_Hondsrug.html#plot-cross-section",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Plot cross-section",
    "text": "Plot cross-section\nThe geology is ready so the last element we need is the cross-section line. In the data set the Esri Shape “crosssection.shp” is available. We need the package geopandas to read the file into a GeoDataFrame object.\n\n\ncrossline = imod.data.hondsrug_crosssection(tmpdir / \"cross-section\")\n\nDownloading file 'hondsrug-crosssection.zip' from 'https://github.com/Deltares/imod-artifacts/raw/main/hondsrug-crosssection.zip' to '/home/runner/.cache/imod'.\nUnzipping contents of '/home/runner/.cache/imod/hondsrug-crosssection.zip' to '/tmp/tmpbxoi1ass/cross-section'\n\n\nWe can plot our DEM again and add our cross-section line as an overlay to our function plot_map.\n\n# define overlay\noverlays = [{\"gdf\": crossline, \"edgecolor\": \"black\",  \"linewidth\":3}]\n# Plot\nimod.visualize.plot_map(DEM, \"viridis\", levels, overlays, basemap=background_map)\n\n\n\n\n\n\n\n\nIn the next cell we call the function cross_section_linestring together with our geology dataset and the geometry of our line. The result is a 2D DataArray “cross_k” with k-values along the line for all layers. We can plot this DataArray with the visualization function cross_section.\n\ncross_k = imod.select.cross_section_linestring(geology, crossline.geometry[0])\nlevels = np.arange(0.0, 30.0, 5)\ncolors = \"viridis\"\nimod.visualize.cross_section(cross_k, colors, levels)\n\n\n\n\n\n\n\n\nWith the package shapely you can easily make new geometries by hand for displaying other cross-sections. The next example is a new line from North to South over the area. You can play around with lines, colors and levels.\n\nfrom shapely.geometry import LineString\n\ngeometry = LineString([[244000,563000],[244000 ,559000]])\ncross_k = imod.select.cross_section_linestring(geology, geometry)\nimod.visualize.cross_section(cross_k, colors, levels)",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "tutorial_Hondsrug.html#tips",
    "href": "tutorial_Hondsrug.html#tips",
    "title": "MODFLOW 6 model for the Hondsrug",
    "section": "Tips",
    "text": "Tips\n\nYou can use the resample method to go from daily recharge to monthly recharge.\nThe table with aliases for frequencies can be found here.\nFollow the consequent steps you did previously on your dataset to construct a Recharge package accepted by iMOD Python.\nYou have to create a new time discretization for your simulation, as the original simulation has yearly stress periods. You can use the create_time_discretization method for this.",
    "crumbs": [
      "Tutorials",
      "MODFLOW 6 model for the Hondsrug"
    ]
  },
  {
    "objectID": "practical_parallel.html",
    "href": "practical_parallel.html",
    "title": " Parallel MODFLOW",
    "section": "",
    "text": "Especially if you're running on Windows, you might get (rather cryptic) errors in the vein off:\nUnable to start the local smpd manager\nError while connecting to host, No connection could be made because the\ntarget machine actively refused it.\nA possible cause is that the path to the smpd.exe, which is a parallel process manager, isn't the right one for the MPI version you're using. The MODFLOW models are generally running with a version of MPICHI2 (https://www.mpich.org/). It's not uncommon, however, to have multiple implementations of MPI installed.\nTo check, run:\nwhere smpd\nWhich e.g. returns:\nC:\\Program Files (x86)\\Common Files\\Intel\\Shared Libraries\\redist\\ia32_win\\mpirt\\smpd.exe c:\\Program\nFiles\\MPICH2\\bin\\smpd.exe\nHere, there's two versions installed: the Intel version, and the MPICH2 version. In this case, the Intel version is on top, and which generally be called first. Then, when trying to run the model, it's expecting the MPICH2 version instead, and it won't run.\nTo address this, you can run:\nc:\\Program Files\\MPICH2\\bin\\smpd.exe -install\nThis should promote it to the top of the list when you run where again.\nOr, just remove it from your PATH if possible. Now, if you run mpiexec.exe, it'll use the right version of smpd.exe."
  },
  {
    "objectID": "practical_parallel.html#smpd-errors",
    "href": "practical_parallel.html#smpd-errors",
    "title": " Parallel MODFLOW",
    "section": "",
    "text": "Especially if you're running on Windows, you might get (rather cryptic) errors in the vein off:\nUnable to start the local smpd manager\nError while connecting to host, No connection could be made because the\ntarget machine actively refused it.\nA possible cause is that the path to the smpd.exe, which is a parallel process manager, isn't the right one for the MPI version you're using. The MODFLOW models are generally running with a version of MPICHI2 (https://www.mpich.org/). It's not uncommon, however, to have multiple implementations of MPI installed.\nTo check, run:\nwhere smpd\nWhich e.g. returns:\nC:\\Program Files (x86)\\Common Files\\Intel\\Shared Libraries\\redist\\ia32_win\\mpirt\\smpd.exe c:\\Program\nFiles\\MPICH2\\bin\\smpd.exe\nHere, there's two versions installed: the Intel version, and the MPICH2 version. In this case, the Intel version is on top, and which generally be called first. Then, when trying to run the model, it's expecting the MPICH2 version instead, and it won't run.\nTo address this, you can run:\nc:\\Program Files\\MPICH2\\bin\\smpd.exe -install\nThis should promote it to the top of the list when you run where again.\nOr, just remove it from your PATH if possible. Now, if you run mpiexec.exe, it'll use the right version of smpd.exe."
  },
  {
    "objectID": "practical_git_dvc.html",
    "href": "practical_git_dvc.html",
    "title": " Version control your projects",
    "section": "",
    "text": "Since scripting becomes increasingly important in hydrological projects, the rules of software development also start to apply to us. This has the downside that it requires extra effort from us, hydrologists, to learn new tools, but the upside is that there already is a wealth of properly tested tools and documentation available from the software development world. Having reproducible code is one of these important things, for which version control systems have been developed. It is very useful to use these systems in hydrological projects, since they provide the following advantages:\n\nYou keep track of the history of a project. In this way you keep a journal of decisions made in a project.\nIf you mess up something, you can always revert to a previous state.\nIt allows for collaborative development, where individuals can create their own branch to safely work on new developments and later merge their changes.\n\nThis document describes how to use Git and DVC. If you are running into issues, Stackoverflow has a lot of information available (&gt;145,000 questions at 02-03-2023), since Git is so commonly used today.\n\n\nToday (03-2023), Git is the most commonly used version control system for code. Code development is usually shared on platforms such as Github or Gitlab.\nOne of the main differences between Git and older systems such as Subversion is that Git is a distributed version control system, whereas Subversion is a centralized system. In subversion, there is no history of changes on the machine, only on the central server. So therefore, to do any version control, the user has to be connected to a server. With Git a repository on a server (called remote) is first cloned to the user's local machine. This repository includes the full history of changes. The user can then make his/her changes, after which he/she can push these back to the remote, but does not have to. Because it is more indirect, and the availability of widely used platforms such as Github, the distributed nature of Git allows for smooth development between different organizations as well as open-source code development. Furthermore, you can develop code offline.\nDue to its background in software engineering, Git is only useful for versioning scripts and textfiles, and not for large files. For versioning larger files we use DVC.\n\n\n\nDVC stands for Data Version Control and it does exactly that. It is built on top of Git and so it uses very similar commands, which can be both easy and confusing at the same time. DVC ensures your large files themselves are not tracked by Git. Instead, it keeps the large files in its own cache and writes simple text files, which store the unique \"version code\" (a hash), each time you commit to DVC. These textfiles then have to be committed to Git. This may seem a bit cumbersome, as you have to commit data first to DVC, and then its version code to Git, but this allows the user to utilize the full potential of both Github as well as Cloud Storages (Like Amazon S3, Google Cloud, Microsoft Azure etc.). The version history is all stored in Git and can be pushed to Github or Gitlab, but the data itself can be stored on different platforms more specialized in handling large files."
  },
  {
    "objectID": "practical_git_dvc.html#introduction",
    "href": "practical_git_dvc.html#introduction",
    "title": " Version control your projects",
    "section": "",
    "text": "Since scripting becomes increasingly important in hydrological projects, the rules of software development also start to apply to us. This has the downside that it requires extra effort from us, hydrologists, to learn new tools, but the upside is that there already is a wealth of properly tested tools and documentation available from the software development world. Having reproducible code is one of these important things, for which version control systems have been developed. It is very useful to use these systems in hydrological projects, since they provide the following advantages:\n\nYou keep track of the history of a project. In this way you keep a journal of decisions made in a project.\nIf you mess up something, you can always revert to a previous state.\nIt allows for collaborative development, where individuals can create their own branch to safely work on new developments and later merge their changes.\n\nThis document describes how to use Git and DVC. If you are running into issues, Stackoverflow has a lot of information available (&gt;145,000 questions at 02-03-2023), since Git is so commonly used today.\n\n\nToday (03-2023), Git is the most commonly used version control system for code. Code development is usually shared on platforms such as Github or Gitlab.\nOne of the main differences between Git and older systems such as Subversion is that Git is a distributed version control system, whereas Subversion is a centralized system. In subversion, there is no history of changes on the machine, only on the central server. So therefore, to do any version control, the user has to be connected to a server. With Git a repository on a server (called remote) is first cloned to the user's local machine. This repository includes the full history of changes. The user can then make his/her changes, after which he/she can push these back to the remote, but does not have to. Because it is more indirect, and the availability of widely used platforms such as Github, the distributed nature of Git allows for smooth development between different organizations as well as open-source code development. Furthermore, you can develop code offline.\nDue to its background in software engineering, Git is only useful for versioning scripts and textfiles, and not for large files. For versioning larger files we use DVC.\n\n\n\nDVC stands for Data Version Control and it does exactly that. It is built on top of Git and so it uses very similar commands, which can be both easy and confusing at the same time. DVC ensures your large files themselves are not tracked by Git. Instead, it keeps the large files in its own cache and writes simple text files, which store the unique \"version code\" (a hash), each time you commit to DVC. These textfiles then have to be committed to Git. This may seem a bit cumbersome, as you have to commit data first to DVC, and then its version code to Git, but this allows the user to utilize the full potential of both Github as well as Cloud Storages (Like Amazon S3, Google Cloud, Microsoft Azure etc.). The version history is all stored in Git and can be pushed to Github or Gitlab, but the data itself can be stored on different platforms more specialized in handling large files."
  },
  {
    "objectID": "practical_git_dvc.html#installation",
    "href": "practical_git_dvc.html#installation",
    "title": " Version control your projects",
    "section": "Installation",
    "text": "Installation\nFirst install Git from this link. If installing on Windows it is useful to make sure Git is added to the %PATH% variable during installation. To test if the installation works, open a command line or shell window and test if the following command works:\nIf this works, install DVC from this link."
  },
  {
    "objectID": "practical_git_dvc.html#software-to-use-git-and-dvc",
    "href": "practical_git_dvc.html#software-to-use-git-and-dvc",
    "title": " Version control your projects",
    "section": "Software to use Git and DVC",
    "text": "Software to use Git and DVC\nYou can run git from the regular Windows command line, but the Windows installation also comes with MinGW (Minimalist GNU for Windows) which can be useful.\n\nMinGW\nMinGW allows you to use Linux commands, as well as other cool stuff (e.g. compiling Fortran 90 with gfortran for free). Note that in it you have to specify paths with Linux-style forward slashes / instead of Windows style backward slashes \\.\nWe recommend defining a button for MinGW in Total Commander by clicking:\nConfiguration &gt; Button Bar &gt; Add\nAnd then specify the path to git-bash.exe under \"Command\", e.g. C:\\\\Program Files\\\\Git\\\\Git\\\\git-bash.exe\n\n\n\n\n\n\nNote\n\n\n\nDepending on your system configuration, you might need to add under \"Parameters\": --login -i\n\n\n\n\nVSCode\nVScode has integrated Git support as well. This is very useful when you are mainly coding, but since you cannot call DVC, less when you are changing model data. This documentation describes how to use it."
  },
  {
    "objectID": "practical_git_dvc.html#tutorial",
    "href": "practical_git_dvc.html#tutorial",
    "title": " Version control your projects",
    "section": "Tutorial",
    "text": "Tutorial\nThere are already several tutorials online available on Git as well as DVC. For Git, this is a useful no-nonsense guide. For DVC, there is this bit more involved tutorial. However, because we want this document to be a bit more than a pointer to other tutorials, here's a quick guide that will describe your typical workflow.\n\nStarting a repository\nYou can start you own repository by changing to the directory first and then initializing git. Open your terminal of choice (e.g. Powershell, cmd, bash) and run the following commands\n&gt; cd path/to/folder \n&gt; git init\nThis will create a hidden .git folder.\nTo then initialize dvc:\n&gt; dvc init\nThis will create a hidden .dvc folder as well as a .dvc/.gitignore file, which will tell Git to automatically ignore parts of the .dvc folder, for example the .dvc/cache folder, where DVC stores all versions of data files. We want Git to ignore these, as we do not want Git to keep track of Gigabytes of data!\n\n\n\n\n\n\nNote\n\n\n\nTo show hidden files and folders (very useful), you can configure Total Commander by clicking:\nConfiguration &gt; Options &gt; Display &gt; \"Show hidden files\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is convenient for later to add the file extensions of files you want to keep in dvc in the .gitignore file, e.g. *.idf. Or you could add your data folder (e.g. data) to this file to exclude everything in it by specifying data/.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis recipe allows you to kickstart your project, creating already a smart folder structure, a readme and a .gitignore file.\n\n\n\n\nChecking the status\nOne of the first things you should do once you have started your repository, is checking its status.\nChange directories into the repo and call:\n&gt; git status\nThis will show in red the files that are untracked by Git and have to be added still. And in green the files that are staged but have not been committed yet.\nIn order to check if any data files changed in DVC, in a similar way you call:\n&gt; dvc status\n\n\nChecking differences\nIf you have modified one or multiple files, you can view lines you have changed per file with:\n&gt; git diff\nThis will show in green the lines that are new, or different, in the new version of the file. And in red the lines as they were in the old version, or now have been removed.\n\n\nAdding textfiles\nSo you have checked the status and will probably have seen that there is a .dvc/.gitignore file that is already staged (this was added by DVC). What DVC has done for us is the following:\n&gt; git add .dvc/.gitignore\nThis will stage the .gitignore file. This means you have selected a change to be added to a commit. If you want to include a script or other textfile in version control, you have to stage it yourself by calling the git add command.\n\n\n\n\n\n\nWarning\n\n\n\nStaging a script does not mean you have added it to version control yet! A file is only added to version control after you have committed your changes (see next section).\n\n\n\n\nCommitting changes\nBefore your files are added to version control, you have to commit them first. A commit can be seen as a \"snapshot\" of a project that is added to the version control and is therefore \"safe\".\nEach commit should be followed by a message that specifies what you have changed. It is very important that these messages are short and informative, as they form your \"journal entries\" and will make searching your version history a lot easier.\nIn our example, you can commit the added .gitignore file to your version control by calling:\n&gt; git commit -m \"Added file extensions to be ignored by Git.\"\nThe -m option allows you to specify a string that will be your commit message.\nBut what if you accidentally made an error in your message? You can then change it using:\n&gt; git commit --amend\nThis will open up a text editor where you can alter your commit message.\n\n\n\n\n\n\nNote\n\n\n\nThe Windows installation of Git comes with a common Linux text editor called Vim. It is possible your Git is configured to automatically open Vim. Vim is very powerful, but has a steep learning curve. Especially confusing for beginners is closing Vim\nSo to close Vim: First press ESC, then press the colon :. To save your changes, you can type x, or to discard them you can type q!. Finish by pressing Enter.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAfter committing data, do not naively rename files or move them around. Instead, you should use Git for that. See @section_moving.\n\n\n\n\nMoving/renaming scripts\nBe careful moving scripts around after they have been committed to Git. Despite having the same filename, Git does not necessarily understand this: It sees a file being deleted and other file being created.\nSo in order to safely move or rename committed files, don't copy+paste committed files in your Windows Explorer, but instead let Git do it for you:\n&gt; git mv script.py src/script.py\nThe same holds for renaming:\n&gt; git mv script.py renamed_script.py\n\n\nAdding and committing data files\nWe now know how to add textfiles, but not how to add large binary files, your data. For this we use DVC, to add data in data version control, e.g. all files in the folder data/rivers, you can add the folder:\n&gt; dvc add data/rivers\nThis creates a unique version code (hash) for all files in the folder and adds the data to the cache in the .dvc directory. The hash of the data is stored in textfile named data/rivers.dvc.\nWe have however not included the data in the version log yet... DVC lets Git take care of keeping the version log, so that both code changes as well as data changes are in the same log.\nIt does this by creating .dvc files with the hashes and we are expected to add these to our git repository. We therefore have to run the following commands to fully include the added data to our version control:\n&gt; git add -f data/rivers.dvc \n&gt; git commit -m \"Added river data\"\nWe added the -f option to the add command, just in case you added the data folder to your .gitignore file. This forces git to still add the rivers.dvc file.\nTo summarize, the data backups are stored in the .dvc folder, the log of changes in the .git folder. This allows us to send the data separately to a data cloud oriented to handling large data files (Google Cloud, Amazon S3, Azure etc.), and to send the .git folder to Github or Gitlab to have a nicely browsable version history.\n\n\nUpdating data\nThe commands to add changes made in the data are the same as to add new data:\n&gt; dvc add data/rivers \n&gt; git add -f data/rivers.dvc \n&gt; git commit -m \"Changed river data\"\n\n\nMoving data\nYou can safely move data to a different location in your repo with DVC by calling:\n&gt; dvc move heads.nc data/heads.nc \n&gt; git add data/heads.nc.dvc \n&gt; git commit -m \"Moved heads to data folder\"\n\n\nViewing the version history\nTo view the results of your hard work of carefully maintaining version control, you can call:\n&gt; git log\nThis shows the version history in text form. This is useful for a quick lookup of the last commits, but if you want to go back a lot more becomes cumbersome. There are quite some graphical user interfaces available to view the version history, one of which is already included with your windows installation. You can start it by calling:\n&gt; gitk\nThis is a very light-weight interface, and more fancy ones exist. Furthermore, when pushing to a remote (see @pushing_to_remote), Github and Gitlab have very good interfaces to view the commit history as well.\n\n\nReverting and resetting commits\nSay you added a commit that was not going to be used, and want to go back. Git provides multiple options to do this safely, and some to do this not so safely.\nSay you want to revert the repository back to a previous state, but want to keep the changes you made after that state. You can revert the last commit you made with:\n&gt; git revert HEAD\nHEAD is the hash of the last commit you made. You can lookup these hashes by calling git log. Say this last hash currently is j1c13377c6d4adfhcc69c6ac7b51e919b15a65c4 We could do the same by calling:\n&gt; git revert j1c13377c6d4adfhcc69c6ac7b51e919b15a65c4\nIf you now call git log again, you can see that the revert of this specific commit is also stored as a new commit. You can always revert the revert as well, if you suddenly decide you actually needed those changes.\nSometimes you commit something which in hindsight is so stupid, you neither want to bother other people with it, nor yourself again. In this case you can reset the repository to a previous state. Say you want to reset to the state before your last commit (basically undoing the last commit), you can call:\n&gt; git reset --hard HEAD~1\nHEAD~1 is the hash of the second last commit. In this way all commits after the second last commit are deleted, so be careful.\n\n\n\n\n\n\nNote\n\n\n\nNote that for git revert we refer to the commit we want to undo, whereas for git reset we refer to the commit before this, because git reset wants to know the state we want to reset to.\n\n\nIf you are also resetting/reverting data changes added to DVC, the data referred to in the last git commit still has to be put in your workspace. To do this call:\n&gt; dvc checkout\nThis will make DVC check all data referred to in the .dvc files again, recalculating hashes, which is a slow process. If you know which files are changed (e.g. 'heads.nc'), you can speed up things considerably by referring to the specific files:\n&gt; dvc checkout heads.nc\n\n\nPushing to remote\nUp to now you have learned how to safely store scripts and data locally, but what if your hard-drive crashes? Or if you accidentally shift+delete your whole repository? In those cases you wished you also stored your repository somewhere else! That's why Git, as well as DVC, allow you to push your repository to a remote.\nThis has two benefits:\n\nYour repository is safely stored somewhere else\nYour colleagues can also access your repository and collaborate on Gitlab/Github.\n\nWe first have to configure Git to know the location of your remote and give it a name. A commonly used name for remote repo is \"origin\".\n&gt; git remote add origin &lt;https://github.com/username/repo.git&gt;\nYou can list the remotes you have added with:\n&gt; git remote -v\nAfter you have added your remote, you can push your code to the remote by calling:\n&gt; git push\nDVC behaves very similar, except that the location of the DVC remote is stored in a file named .dvc/config that has to be added to Git. Say we want to add my google drive to a remote named \"google-drive\":\n&gt; dvc remote add google-drive gdrive://some-hash-number-here \n&gt; git add .dvc/config\n&gt; git commit -m \"Added google-drive as dvc remote\"\nYou can then push to google-drive by calling:\n&gt; dvc push\n\n\nCloning an existing repository\nIt is also possible to easily create a local copy of an existing repository. You can tell git to clone a remote repository into the current directory with:\n&gt; git clone &lt;http-address&gt;\nFor example, to clone the California model repository, you can call:\n&gt; git clone &lt;https://gitlab.com/deltares/imod/california_model.git&gt;\n\n\n\n\n\n\nNote\n\n\n\nThis might require a Gitlab account with 2 factor authorization.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYour organization might have strict security settings and you might run into: SSL certificate problem: self signed certificate in certificate chain github. You can follow these instructions to fix this."
  },
  {
    "objectID": "practical_git_dvc.html#further-reading",
    "href": "practical_git_dvc.html#further-reading",
    "title": " Version control your projects",
    "section": "Further reading",
    "text": "Further reading\nFor Git commands, you can also take a look at this useful cheat sheet ."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "iMOD Suite Documentation",
    "section": "",
    "text": "The iMOD Suite offers different modules which support modelling with MODFLOW 6 (including unstructured meshes):\n\niMOD Viewer: The iMOD Viewer consist of a standalone 3D viewer and a QGIS plugin. The iMOD QGIS Plugin QGIS plugin allows visualisation of model input and output with tools for cross-sections, timeseries and link to the 3D viewer. It supports structured NetCDF, UGRID and IPF files. And the iMOD 3D Viewer for interactive 3D visualisation of unstructured input and output. Supports UGRID file format and IPF borelog files.\niMOD Python: A Python package to support MODFLOW groundwater modeling. It makes it easy to go from your raw data to a fully defined MODFLOW model, with the aim to make this workflow reproducible.\niMOD Coupler: Software that couples MODFLOW 6 to other computational cores. It currently supports a coupling to MetaSWAP, but additional computational cores are planned in the future.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Introduction\n\n\nLearn what’s included.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n iMOD Viewer\n\n\nVisualization of unstructured grids in GIS and 3D.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n iMOD Python\n\n\nBuild large groundwater models with scripts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n iMOD Coupler\n\n\nApplication for coupling hydrological kernels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Tutorials\n\n\nLearn how to use the iMOD Suite\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Practical Tips\n\n\nUseful tips to use the iMOD Suite with other tools.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html",
    "href": "coupler_ribamod_preprocessing.html",
    "title": "Pre-processing",
    "section": "",
    "text": "This document describes how to setup coupled Ribasim-MODFLOW 6 simulations.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#the-primod-python-package",
    "href": "coupler_ribamod_preprocessing.html#the-primod-python-package",
    "title": "Pre-processing",
    "section": "The primod Python package",
    "text": "The primod Python package\nTo aid in setting up coupled models, we have created the primod Python package. It takes both models, derives the exchange relationships between both, and writes:\n\nthe Ribasim model\nthe MODFLOW 6 simulation\nthe exchange files\nthe iMOD coupler configuration file\n\nThe derivation of exchange connections between the models is automatic, and based on the spatial information provided for both models.\nAs primod is a Python package, both models must be represented in Python:\n\nThe MODFLOW 6 simulation is represented by the Modflow6Simulation class of the imod Python package.\nThe Ribasim model is represented by the Model class of the ribasim Python package.\nThe combination of both models is represented by the primod RibaMod class.\n\nBoth Python packages support reading a model from a TOML file and associated files.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#abbreviated-example",
    "href": "coupler_ribamod_preprocessing.html#abbreviated-example",
    "title": "Pre-processing",
    "section": "Abbreviated example",
    "text": "Abbreviated example\nThe following abbreviated example:\n\nReads a Ribasim model\nReads a MODFLOW 6 simulation\nReads a basin definition associated with the Ribasim model\nDefines a driver coupling: which river and drainage packages are coupled\nSets up a coupled model\nWrites the coupled model\n\nimport ribasim\nimport geopandas as gpd\nimport imod\nimport primod\n\n\nribasim_model = ribasim.Model.read(\"ribasim/ribasim.toml\")\nmf6_simulation = imod.mf6.Modflow6Simulation.from_file(\"modflow/GWF_1.toml\")\nbasin_definition = gpd.read_file(\"ribasim_network.gpkg\", layer=\"basin_areas\")\n\ndriver_coupling_active = primod.RibaModActiveDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_packages=[\"riv-1\"],\n    basin_definition=basin_definition,\n)\ndriver_coupling_passve = primod.RibaModPassiveDriverCoupling(\n    mf6_model=\"GWF_1\",\n    mf6_packages=[\"drn-1\", \"drn-2\"],\n    basin_definition=basin_definition,\n)\n\nribamod_model = primod.RibaMod(\n    ribasim_model=ribasim_model,\n    mf6_simulation=mf6sim,\n    coupling_list=[driver_coupling_active, driver_coupling_passive],\n)\n\nribamod_model.write(\n   directory=\"coupled-ribamod-simulation\",\n   modflow6_dll=r\"c:\\bin\\imod_coupler\\modflow6\\libmf6.dll\",\n   ribasim_dll=r\"c:\\bin\\imod_coupler\\ribasim\\bin\\libribasim.dll\",\n   ribasim_dll_dependency=r\"c:\\bin\\imod_coupler\\ribasim\\bin\",\n)",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#requirements",
    "href": "coupler_ribamod_preprocessing.html#requirements",
    "title": "Pre-processing",
    "section": "Requirements",
    "text": "Requirements\n\nThe start and end times of the Ribasim and MODFLOW 6 simulations must align. primod will raise an error otherwise.\nSpatial extents of both models need not coincide. Part of the Ribasim basins may be located outside of the MODFLOW 6 simulation window. Uncoupled basins will proceed with the regular drainage and irrigation terms define in the Basin / Static or Basin / Time tables.\nSimilarly, not every River and Drainage boundary needs to be linked with Ribasim. Boundaries outside of any basin polygon will simply use the regular file input.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#exchange-derivation",
    "href": "coupler_ribamod_preprocessing.html#exchange-derivation",
    "title": "Pre-processing",
    "section": "Exchange derivation",
    "text": "Exchange derivation\nThe exchanges are derived based on spatial overlap of Ribasim basins and the grid-based River and Drainage representation. For an active coupling, the x and y locations of the subgrid elements is used to link each actively coupled MODFLOW 6 boundary with a subgrid element.\n\nPassive coupling\nThe derivation of exchanges proceeds in the following steps:\n\nRasterize the basin definition polygons (provided as a geopandas.GeoDataFrame) to the MODFLOW 6 model grid.\nOverlay the conductance on the rasterized basin definition, and derive for each boundary the basin index.\nIdentify the indices of the coupled MODFLOW 6 boundaries.\nStore the basin indices and boundary indices in a table.\n\n\n\nActive coupling\nThe derivation of active coupling exchanges proceeds largely the same, but also locates the nearest subgrid elements:\n\nRasterize the basin definition polygons (provided as a geopandas.GeoDataFrame) to the MODFLOW 6 model grid.\nOverlay the conductance on the rasterized basin definition, and derive for each boundary the basin index.\nIdentify the indices of the coupled MODFLOW 6 boundaries.\nUsing the meta_x and meta_y columns in the Ribasim Basin / subgrid table, find the nearest subgrid element for each MODFLOW 6 boundary.\nStore the basin indices, boundary indices, subgrid indices in a table.\n\nNB. The subgrid In a passive coupling, only drainage package are expected on the MODFLOW 6 side. In this type of coupling, the occurrence of a river package is not allowed and triggers a fatal error during preprocessing.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#modifications-to-the-ribasim-model",
    "href": "coupler_ribamod_preprocessing.html#modifications-to-the-ribasim-model",
    "title": "Pre-processing",
    "section": "Modifications to the Ribasim model",
    "text": "Modifications to the Ribasim model\nThe primod.RibaMod class makes the following alteration to the Ribasim input before writing the Ribasim model: for basins that are coupled to MODFLOW 6, the infiltration and drainage columns are set to NaN / Null (nodata) in the Basin / Static or Basin / Time tables.\nThis ensures that Ribasim does not overwrite the exchange flows while running coupled with MODFLOW 6.\nConceptually, it also means that when a basin is coupled, it should generally located inside of the MODFLOW 6 model; after all, when half of the basin is located outside of the MODFLOW 6 model, it will not receive drainage or lose water to infiltration in that half.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler_ribamod_preprocessing.html#modifications-to-the-modflow-6-simulation",
    "href": "coupler_ribamod_preprocessing.html#modifications-to-the-modflow-6-simulation",
    "title": "Pre-processing",
    "section": "Modifications to the MODFLOW 6 simulation",
    "text": "Modifications to the MODFLOW 6 simulation\nCurrently, no modifications are made in the MODFLOW 6 input.\n\nConsistency between MODFLOW 6 and Ribasim subgrid\nDuring the coupling, water levels should not be set below the bed elevation of the boundary. For drainage packages, this is the drainage elevation provided in the MODFLOW 6 input; for river packages, this is the bottom elevation provided in the MODFLOW 6 input.\nThere is potential for inconsistency here, as Ribasim also describes a bed elevation: the lowest level of the subgrid piecewise interpolation table:\n\nIn case the MODFLOW 6 bed elevation is higher than the subgrid elevation, infiltration will stop before the Ribasim basin is empty.\nIn case the MODFLOW 6 bed elevation is lower than the subgrid elevation, infiltration will proceed even when the Ribasim basin is empty.\n\nThe second is a more pressing problem, as it will results in a discrepancy between the water balances of both models. However, this problem is detected in the preprocessing stage and triggers a fatal error.",
    "crumbs": [
      "iMOD Coupler",
      "Ribasim - MODFLOW 6",
      "Pre-processing"
    ]
  },
  {
    "objectID": "coupler.html",
    "href": "coupler.html",
    "title": " iMOD Coupler",
    "section": "",
    "text": "Deltares have worked together with the USGS to create the MODFLOW API, based on the Basic Model Interface (BMI) with some extensions. The first version of this functionality became available with the release of MODFLOW 6.2.0. BMI is a set of standard control and query functions that, when added to a model code, make that model both easier to learn and easier to couple with other software elements. Furthermore, the BMI makes it possible to control MODFLOW 6 execution from scripting languages using bindings for the BMI.\nWe have also developed xmipy, a Python package with bindings for the API, which allow you to run and update (at runtime) a MODFLOW 6 model from Python. This allows coupling MODFLOW 6 to other computational cores. One of its first applications is a coupling of MODFLOW 6 to MetaSWAP, as part of the iMOD Coupler package. Other applications can be found in this paper.",
    "crumbs": [
      "iMOD Coupler",
      "{{< fa solid plug >}} iMOD Coupler"
    ]
  },
  {
    "objectID": "coupler.html#coupling-to-modflow-6",
    "href": "coupler.html#coupling-to-modflow-6",
    "title": " iMOD Coupler",
    "section": "",
    "text": "Deltares have worked together with the USGS to create the MODFLOW API, based on the Basic Model Interface (BMI) with some extensions. The first version of this functionality became available with the release of MODFLOW 6.2.0. BMI is a set of standard control and query functions that, when added to a model code, make that model both easier to learn and easier to couple with other software elements. Furthermore, the BMI makes it possible to control MODFLOW 6 execution from scripting languages using bindings for the BMI.\nWe have also developed xmipy, a Python package with bindings for the API, which allow you to run and update (at runtime) a MODFLOW 6 model from Python. This allows coupling MODFLOW 6 to other computational cores. One of its first applications is a coupling of MODFLOW 6 to MetaSWAP, as part of the iMOD Coupler package. Other applications can be found in this paper.",
    "crumbs": [
      "iMOD Coupler",
      "{{< fa solid plug >}} iMOD Coupler"
    ]
  },
  {
    "objectID": "coupler.html#links",
    "href": "coupler.html#links",
    "title": " iMOD Coupler",
    "section": "Links",
    "text": "Links\nThe iMOD Coupler can be found on: https://github.com/Deltares/imod_coupler\nThe latest release together with the binaries can be found on: https://github.com/Deltares/imod_coupler/releases/latest/\nThe xmipy library can be found on: https://github.com/Deltares/xmipy",
    "crumbs": [
      "iMOD Coupler",
      "{{< fa solid plug >}} iMOD Coupler"
    ]
  },
  {
    "objectID": "coupler.html#known-issues",
    "href": "coupler.html#known-issues",
    "title": " iMOD Coupler",
    "section": "Known Issues",
    "text": "Known Issues\n\niMOD v5.2 release\nThe MetaSWAP and Modflow6 libraries provided with iMOD 5.2 for imod_coupler were not statically linked. This could result in the following error:\nFileNotFoundError: '''Could not find module \"\\path\\to\\MetaSWAP.dll\" (or one\nof its dependencies). Try using the full path with constructor syntax.'''\nThis is caused by not having the Intel redistrutable libraries on the system. These can be downloaded from this page. Make sure to choose the correct platform and the version for 'Parallel Studio XE 2020'.",
    "crumbs": [
      "iMOD Coupler",
      "{{< fa solid plug >}} iMOD Coupler"
    ]
  },
  {
    "objectID": "viewer_install.html",
    "href": "viewer_install.html",
    "title": "Install iMOD Viewer",
    "section": "",
    "text": "For the complete iMOD viewer (QGIS plugin and 3D viewer) can be installed using the Deltares installer. A working QGIS is needed before installing the iMOD viewer. It is also possible to install the QGIS plugin using the QGIS plugin repository. This installation is without the 3D viewer.\nThe different ways to install the QGIS plugin are described in Section 3.1, Section 3.2, and Section 3.3. Each of these, however, require the user to install QGIS. To install the QGIS plugin, we recommend running the iMOD Viewer installer (Section 3.1), which will both install the iMOD 3D viewer, as well as the iMOD QGIS plugin.",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer"
    ]
  },
  {
    "objectID": "viewer_install.html#description",
    "href": "viewer_install.html#description",
    "title": "Install iMOD Viewer",
    "section": "",
    "text": "For the complete iMOD viewer (QGIS plugin and 3D viewer) can be installed using the Deltares installer. A working QGIS is needed before installing the iMOD viewer. It is also possible to install the QGIS plugin using the QGIS plugin repository. This installation is without the 3D viewer.\nThe different ways to install the QGIS plugin are described in Section 3.1, Section 3.2, and Section 3.3. Each of these, however, require the user to install QGIS. To install the QGIS plugin, we recommend running the iMOD Viewer installer (Section 3.1), which will both install the iMOD 3D viewer, as well as the iMOD QGIS plugin.",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer"
    ]
  },
  {
    "objectID": "viewer_install.html#sec-install_QGIS",
    "href": "viewer_install.html#sec-install_QGIS",
    "title": "Install iMOD Viewer",
    "section": "2 Installing QGIS",
    "text": "2 Installing QGIS\nYou can download the standalone QGIS setup [on the QGIS website] (https://qgis.org/en/site/forusers/download.html). We recommend downloading a QGIS version &gt;= 3.28 here. After downloading the QGIS setup, run it.\nThis installs a user installation of QGIS, which is sufficient in most cases. For a system wide installation, see Section 4.",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer"
    ]
  },
  {
    "objectID": "viewer_install.html#installing-the-imod-viewer",
    "href": "viewer_install.html#installing-the-imod-viewer",
    "title": "Install iMOD Viewer",
    "section": "3 Installing the iMOD Viewer",
    "text": "3 Installing the iMOD Viewer\nThe different options to install the iMOD Viewer are listed below. The iMOD Viewer consists of the iMOD QGIS plugin and iMOD 3D viewer.\n\n3.1 (Option 1) Install with the Deltares setup\nRun the .msi you can download on the Deltares download portal.\nFollow the installation instructions for the viewer install, and make sure to do a Complete install.\n\n\n3.2 (Option 2) Installing from the QGIS plugin repository\nIn QGIS, navigate to Plugins &gt; Manage and Install Plugins &gt; All. In the search bar, type: “iMOD”. Select the iMOD plugin, and click “Install”.\nThis does not install the iMOD 3D Viewer; so for 3D viewing functionality, follow the instructions in Section 3.1, but instead select a Minimal install.\n\n\n3.3 (Option 3) Manually download and copy the iMOD QGIS plugin\nDownload the iMOD QGIS plugin code from the [Github page](https://github.com/Deltares/imod-qgis]\nUnpack the zip files, and copy the imodqgis folder to your QGIS plugin directory. This is probably located in your Appdata folder. In windows it is something such as: c:\\Users\\%USER%\\AppData\\Roaming\\QGIS\\QGIS3\\profiles\\default\\python\\plugins\nIf you cannot find the folder, follow [these instructions] (https://gis.stackexchange.com/a/274312&gt;).\nIn QGIS, make sure under Plugins &gt; Manage and Install Plugins &gt; Installed that the checkbox iMOD is checked.",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer"
    ]
  },
  {
    "objectID": "viewer_install.html#sec-system-wide",
    "href": "viewer_install.html#sec-system-wide",
    "title": "Install iMOD Viewer",
    "section": "4 Advanced: Installing the QGIS plugin system-wide",
    "text": "4 Advanced: Installing the QGIS plugin system-wide\nThere are cases where a system-wide QGIS installation is required, for example on computational servers, where multiple users need to use the software. Requiring each user to install the plugin themselves can be a burden.\nThis requires the following steps:\n\nInstalling the OSGeo4W QGIS installation\nPutting the plugin files in the right folder.\n\n\n4.1 Installing the OSGeo4W QGIS installation\n\nDownload the OSGeo4W installer from the QGIS website &lt;https://qgis.org/en/site/forusers/download.html&gt;_\nRight-click osgeo4w-setup.exe and click Run as administrator\nAt the starting screen, choose Advanced Install\nIn the Choose Installation Type screen, choose Install from Internet if you have access to the internet, this will download the files to a folder called something like: %APPDATA%\\Local\\Temp\\http%3a%2f%2fdownload.osgeo.org%2fosgeo4w%2fv2%2f\\\nYou can use this folder to Install from Local Directory later (for example on a restricted server)\nIn Choose Installation Directory check All Users\nIn “Select Local Package Directory”, you can leave the default options\nIf you previously checked “Install from Internet”:\n\nin the Select Connection Type, choose Direct Connection\nin Choose Download Sites, choose http://download.osgeo.org\n\nIn the Select Packages screen, make sure the following components are installed:\n\nunder Desktop, qgis: QGIS Desktop.\nunder Libs, python3-pandas\n\nA component will be installed if there is a version number in the “New” column (If Skip change this by clicking the cell with Skip in it).\nAfter downloading an installing, check Finish\n\n\n\n\n\n\n\nTip\n\n\n\nMaximize the screen to see the package names\n\n\n\n\n\nThe Select packages screen enlarged. If you click Skip, a version number should appear in the column New.\n\n\n\n\n4.2 Putting the plugin files in the right folder\nDownload the iMOD QGIS plugin code from the Github page\nUnpack the zip files, and copy the imodqgis folder to your QGIS plugin directory. This is probably located in your Appdata folder. In windows it is something such as: c:\\OSGeo4W\\apps\\qgis\\python\\plugins\\imodqgis",
    "crumbs": [
      "iMOD Viewer",
      "Install iMOD Viewer"
    ]
  }
]